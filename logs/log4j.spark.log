21/04/10 00:10:30 INFO SparkContext: Invoking stop() from shutdown hook
21/04/10 00:10:30 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
21/04/10 00:10:30 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/04/10 00:10:30 INFO MemoryStore: MemoryStore cleared
21/04/10 00:10:30 INFO BlockManager: BlockManager stopped
21/04/10 00:10:30 INFO BlockManagerMaster: BlockManagerMaster stopped
21/04/10 00:10:30 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/04/10 00:10:30 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\lizha\AppData\Local\spark\spark-2.4.3-bin-hadoop2.7\tmp\local\spark-fd59562e-417b-44f8-be2b-458c02c3de67\userFiles-cf15b3bb-9f81-4b40-8fd6-98e08b6335ff
java.io.IOException: Failed to delete: C:\Users\lizha\AppData\Local\spark\spark-2.4.3-bin-hadoop2.7\tmp\local\spark-fd59562e-417b-44f8-be2b-458c02c3de67\userFiles-cf15b3bb-9f81-4b40-8fd6-98e08b6335ff\sparklyr-2.4-2.11.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:144)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:128)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:91)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1062)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:103)
	at org.apache.spark.SparkContext$$anonfun$stop$11.apply$mcV$sp(SparkContext.scala:1974)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1340)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1973)
	at org.apache.spark.SparkContext$$anonfun$2.apply$mcV$sp(SparkContext.scala:575)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1945)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
21/04/10 00:10:30 INFO SparkContext: Successfully stopped SparkContext
21/04/10 00:10:30 INFO ShutdownHookManager: Shutdown hook called
21/04/10 00:10:30 INFO ShutdownHookManager: Deleting directory C:\Users\lizha\AppData\Local\Temp\spark-30ee4c4c-225b-439d-b33f-dff3a28ba9db
21/04/10 00:10:30 INFO ShutdownHookManager: Deleting directory C:\Users\lizha\AppData\Local\spark\spark-2.4.3-bin-hadoop2.7\tmp\local\spark-fd59562e-417b-44f8-be2b-458c02c3de67\userFiles-cf15b3bb-9f81-4b40-8fd6-98e08b6335ff
21/04/10 00:10:30 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\lizha\AppData\Local\spark\spark-2.4.3-bin-hadoop2.7\tmp\local\spark-fd59562e-417b-44f8-be2b-458c02c3de67\userFiles-cf15b3bb-9f81-4b40-8fd6-98e08b6335ff
java.io.IOException: Failed to delete: C:\Users\lizha\AppData\Local\spark\spark-2.4.3-bin-hadoop2.7\tmp\local\spark-fd59562e-417b-44f8-be2b-458c02c3de67\userFiles-cf15b3bb-9f81-4b40-8fd6-98e08b6335ff\sparklyr-2.4-2.11.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:144)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:128)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:91)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1062)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1945)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
21/04/10 00:10:30 INFO ShutdownHookManager: Deleting directory C:\Users\lizha\AppData\Local\spark\spark-2.4.3-bin-hadoop2.7\tmp\local\spark-fd59562e-417b-44f8-be2b-458c02c3de67
21/04/10 00:10:30 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\lizha\AppData\Local\spark\spark-2.4.3-bin-hadoop2.7\tmp\local\spark-fd59562e-417b-44f8-be2b-458c02c3de67
java.io.IOException: Failed to delete: C:\Users\lizha\AppData\Local\spark\spark-2.4.3-bin-hadoop2.7\tmp\local\spark-fd59562e-417b-44f8-be2b-458c02c3de67\userFiles-cf15b3bb-9f81-4b40-8fd6-98e08b6335ff\sparklyr-2.4-2.11.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:144)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:128)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:128)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:91)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1062)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1945)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
21/04/10 11:44:59 INFO SparkContext: Running Spark version 2.4.3
21/04/10 11:44:59 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
21/04/10 11:44:59 INFO SparkContext: Submitted application: sparklyr
21/04/10 11:44:59 INFO SecurityManager: Changing view acls to: lizha
21/04/10 11:44:59 INFO SecurityManager: Changing modify acls to: lizha
21/04/10 11:44:59 INFO SecurityManager: Changing view acls groups to: 
21/04/10 11:44:59 INFO SecurityManager: Changing modify acls groups to: 
21/04/10 11:44:59 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(lizha); groups with view permissions: Set(); users  with modify permissions: Set(lizha); groups with modify permissions: Set()
21/04/10 11:44:59 INFO Utils: Successfully started service 'sparkDriver' on port 64165.
21/04/10 11:44:59 INFO SparkEnv: Registering MapOutputTracker
21/04/10 11:44:59 INFO SparkEnv: Registering BlockManagerMaster
21/04/10 11:44:59 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/04/10 11:44:59 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/04/10 11:44:59 INFO DiskBlockManager: Created local directory at C:\Users\lizha\AppData\Local\spark\spark-2.4.3-bin-hadoop2.7\tmp\local\blockmgr-869d3eba-c849-4c0a-a56b-faed166bdab0
21/04/10 11:44:59 INFO MemoryStore: MemoryStore started with capacity 912.3 MB
21/04/10 11:44:59 INFO SparkEnv: Registering OutputCommitCoordinator
21/04/10 11:44:59 WARN Utils: The configured local directories are not expected to be URIs; however, got suspicious values [C:/Users/lizha/AppData/Local/spark/spark-2.4.3-bin-hadoop2.7/tmp/local]. Please check your configured local directories.
21/04/10 11:44:59 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/04/10 11:44:59 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
21/04/10 11:44:59 INFO SparkContext: Added JAR file:/E:/OneDrive/Documents/R/win-library/4.0/sparklyr/java/sparklyr-2.4-2.11.jar at spark://127.0.0.1:64165/jars/sparklyr-2.4-2.11.jar with timestamp 1618073099892
21/04/10 11:44:59 INFO Executor: Starting executor ID driver on host localhost
21/04/10 11:44:59 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 64206.
21/04/10 11:44:59 INFO NettyBlockTransferService: Server created on 127.0.0.1:64206
21/04/10 11:44:59 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/04/10 11:44:59 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 64206, None)
21/04/10 11:44:59 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:64206 with 912.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 64206, None)
21/04/10 11:44:59 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 64206, None)
21/04/10 11:44:59 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 64206, None)
21/04/10 11:45:00 INFO SharedState: loading hive config file: file:/C:/Users/lizha/AppData/Local/spark/spark-2.4.3-bin-hadoop2.7/conf/hive-site.xml
21/04/10 11:45:00 INFO SharedState: Setting hive.metastore.warehouse.dir ('C:/Users/lizha/AppData/Local/spark/spark-2.4.3-bin-hadoop2.7/tmp/hive') to the value of spark.sql.warehouse.dir ('C:/Users/lizha/AppData/Local/spark/spark-2.4.3-bin-hadoop2.7/tmp/hive').
21/04/10 11:45:00 INFO SharedState: Warehouse path is 'C:/Users/lizha/AppData/Local/spark/spark-2.4.3-bin-hadoop2.7/tmp/hive'.
21/04/10 11:45:00 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
21/04/10 11:45:01 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
21/04/10 11:45:02 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
21/04/10 11:45:02 INFO ObjectStore: ObjectStore, initialize called
21/04/10 11:45:02 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
21/04/10 11:45:02 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
21/04/10 11:45:03 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
21/04/10 11:45:03 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/04/10 11:45:03 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/04/10 11:45:04 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/04/10 11:45:04 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/04/10 11:45:04 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
21/04/10 11:45:04 INFO ObjectStore: Initialized ObjectStore
21/04/10 11:45:04 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
21/04/10 11:45:04 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
21/04/10 11:45:04 INFO HiveMetaStore: Added admin role in metastore
21/04/10 11:45:04 INFO HiveMetaStore: Added public role in metastore
21/04/10 11:45:04 INFO HiveMetaStore: No user is added in admin role, since config is empty
21/04/10 11:45:04 INFO HiveMetaStore: 0: get_all_databases
21/04/10 11:45:04 INFO audit: ugi=lizha	ip=unknown-ip-addr	cmd=get_all_databases	
21/04/10 11:45:04 INFO HiveMetaStore: 0: get_functions: db=default pat=*
21/04/10 11:45:04 INFO audit: ugi=lizha	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
21/04/10 11:45:04 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
21/04/10 11:45:04 INFO SessionState: Created local directory: C:/Users/lizha/AppData/Local/Temp/4f3add06-f952-459e-9b96-e5d8c69ba431_resources
21/04/10 11:45:04 INFO SessionState: Created HDFS directory: C:/Users/lizha/AppData/Local/spark/spark-2.4.3-bin-hadoop2.7/tmp/hive/lizha/4f3add06-f952-459e-9b96-e5d8c69ba431
21/04/10 11:45:04 INFO SessionState: Created local directory: C:/Users/lizha/AppData/Local/spark/spark-2.4.3-bin-hadoop2.7/tmp/hive/4f3add06-f952-459e-9b96-e5d8c69ba431
21/04/10 11:45:04 INFO SessionState: Created HDFS directory: C:/Users/lizha/AppData/Local/spark/spark-2.4.3-bin-hadoop2.7/tmp/hive/lizha/4f3add06-f952-459e-9b96-e5d8c69ba431/_tmp_space.db
21/04/10 11:45:04 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.2) is C:/Users/lizha/AppData/Local/spark/spark-2.4.3-bin-hadoop2.7/tmp/hive
21/04/10 11:45:04 INFO HiveMetaStore: 0: get_database: default
21/04/10 11:45:04 INFO audit: ugi=lizha	ip=unknown-ip-addr	cmd=get_database: default	
21/04/10 11:45:04 INFO HiveMetaStore: 0: get_database: global_temp
21/04/10 11:45:04 INFO audit: ugi=lizha	ip=unknown-ip-addr	cmd=get_database: global_temp	
21/04/10 11:45:04 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
21/04/10 11:45:04 INFO HiveMetaStore: 0: get_database: default
21/04/10 11:45:04 INFO audit: ugi=lizha	ip=unknown-ip-addr	cmd=get_database: default	
21/04/10 11:45:04 INFO HiveMetaStore: 0: get_database: default
21/04/10 11:45:04 INFO audit: ugi=lizha	ip=unknown-ip-addr	cmd=get_database: default	
21/04/10 11:45:04 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/04/10 11:45:04 INFO audit: ugi=lizha	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/04/10 11:45:04 INFO CodeGenerator: Code generated in 132.2148 ms
21/04/10 11:45:05 INFO CodeGenerator: Code generated in 15.0798 ms
21/04/10 11:45:05 INFO CodeGenerator: Code generated in 9.0387 ms
21/04/10 11:45:05 INFO SparkContext: Starting job: count at utils.scala:135
21/04/10 11:45:05 INFO DAGScheduler: Registering RDD 3 (count at utils.scala:135)
21/04/10 11:45:05 INFO DAGScheduler: Got job 0 (count at utils.scala:135) with 1 output partitions
21/04/10 11:45:05 INFO DAGScheduler: Final stage: ResultStage 1 (count at utils.scala:135)
21/04/10 11:45:05 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
21/04/10 11:45:05 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
21/04/10 11:45:05 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at count at utils.scala:135), which has no missing parents
21/04/10 11:45:05 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 7.9 KB, free 912.3 MB)
21/04/10 11:45:05 INFO ContextCleaner: Cleaned accumulator 1
21/04/10 11:45:05 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.2 KB, free 912.3 MB)
21/04/10 11:45:05 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:64206 (size: 4.2 KB, free: 912.3 MB)
21/04/10 11:45:05 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1161
21/04/10 11:45:05 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/04/10 11:45:05 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
21/04/10 11:45:05 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7882 bytes)
21/04/10 11:45:05 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
21/04/10 11:45:05 INFO Executor: Fetching spark://127.0.0.1:64165/jars/sparklyr-2.4-2.11.jar with timestamp 1618073099892
21/04/10 11:45:05 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:64165 after 13 ms (0 ms spent in bootstraps)
21/04/10 11:45:05 INFO Utils: Fetching spark://127.0.0.1:64165/jars/sparklyr-2.4-2.11.jar to C:\Users\lizha\AppData\Local\spark\spark-2.4.3-bin-hadoop2.7\tmp\local\spark-b42ec8ae-c7fb-49a7-8d1a-c0aa1078a961\userFiles-25723973-8343-4d7f-bb2a-bac549a965ef\fetchFileTemp6017551992177755041.tmp
21/04/10 11:45:05 INFO Executor: Adding file:/C:/Users/lizha/AppData/Local/spark/spark-2.4.3-bin-hadoop2.7/tmp/local/spark-b42ec8ae-c7fb-49a7-8d1a-c0aa1078a961/userFiles-25723973-8343-4d7f-bb2a-bac549a965ef/sparklyr-2.4-2.11.jar to class loader
21/04/10 11:45:05 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1499 bytes result sent to driver
21/04/10 11:45:05 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 199 ms on localhost (executor driver) (1/1)
21/04/10 11:45:05 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
21/04/10 11:45:05 INFO DAGScheduler: ShuffleMapStage 0 (count at utils.scala:135) finished in 0.404 s
21/04/10 11:45:05 INFO DAGScheduler: looking for newly runnable stages
21/04/10 11:45:05 INFO DAGScheduler: running: Set()
21/04/10 11:45:05 INFO DAGScheduler: waiting: Set(ResultStage 1)
21/04/10 11:45:05 INFO DAGScheduler: failed: Set()
21/04/10 11:45:05 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[6] at count at utils.scala:135), which has no missing parents
21/04/10 11:45:05 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 7.1 KB, free 912.3 MB)
21/04/10 11:45:05 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.3 MB)
21/04/10 11:45:05 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:64206 (size: 3.8 KB, free: 912.3 MB)
21/04/10 11:45:05 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1161
21/04/10 11:45:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/04/10 11:45:05 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
21/04/10 11:45:05 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, ANY, 7767 bytes)
21/04/10 11:45:05 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
21/04/10 11:45:05 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/04/10 11:45:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
21/04/10 11:45:05 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1732 bytes result sent to driver
21/04/10 11:45:05 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 33 ms on localhost (executor driver) (1/1)
21/04/10 11:45:05 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/04/10 11:45:05 INFO DAGScheduler: ResultStage 1 (count at utils.scala:135) finished in 0.041 s
21/04/10 11:45:05 INFO DAGScheduler: Job 0 finished: count at utils.scala:135, took 0.492246 s
21/04/10 11:45:08 INFO HiveMetaStore: 0: get_database: default
21/04/10 11:45:08 INFO audit: ugi=lizha	ip=unknown-ip-addr	cmd=get_database: default	
21/04/10 11:45:08 INFO HiveMetaStore: 0: get_database: default
21/04/10 11:45:08 INFO audit: ugi=lizha	ip=unknown-ip-addr	cmd=get_database: default	
21/04/10 11:45:08 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/04/10 11:45:08 INFO audit: ugi=lizha	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/04/10 11:45:08 INFO SparkContext: Starting job: collect at utils.scala:61
21/04/10 11:45:08 INFO DAGScheduler: Got job 1 (collect at utils.scala:61) with 1 output partitions
21/04/10 11:45:08 INFO DAGScheduler: Final stage: ResultStage 2 (collect at utils.scala:61)
21/04/10 11:45:08 INFO DAGScheduler: Parents of final stage: List()
21/04/10 11:45:08 INFO DAGScheduler: Missing parents: List()
21/04/10 11:45:08 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[11] at map at utils.scala:54), which has no missing parents
21/04/10 11:45:08 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 6.0 KB, free 912.3 MB)
21/04/10 11:45:08 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.4 KB, free 912.3 MB)
21/04/10 11:45:08 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:64206 (size: 3.4 KB, free: 912.3 MB)
21/04/10 11:45:08 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1161
21/04/10 11:45:08 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[11] at map at utils.scala:54) (first 15 tasks are for partitions Vector(0))
21/04/10 11:45:08 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
21/04/10 11:45:08 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 7893 bytes)
21/04/10 11:45:08 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
21/04/10 11:45:08 INFO CodeGenerator: Code generated in 5.7013 ms
21/04/10 11:45:08 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 970 bytes result sent to driver
21/04/10 11:45:08 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 12 ms on localhost (executor driver) (1/1)
21/04/10 11:45:08 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
21/04/10 11:45:08 INFO DAGScheduler: ResultStage 2 (collect at utils.scala:61) finished in 0.017 s
21/04/10 11:45:08 INFO DAGScheduler: Job 1 finished: collect at utils.scala:61, took 0.019746 s
21/04/10 11:45:08 INFO CodeGenerator: Code generated in 9.0372 ms
21/04/10 11:45:08 INFO CodeGenerator: Code generated in 7.6148 ms
21/04/10 11:45:08 INFO SparkContext: Starting job: collect at utils.scala:135
21/04/10 11:45:08 INFO DAGScheduler: Got job 2 (collect at utils.scala:135) with 1 output partitions
21/04/10 11:45:08 INFO DAGScheduler: Final stage: ResultStage 3 (collect at utils.scala:135)
21/04/10 11:45:08 INFO DAGScheduler: Parents of final stage: List()
21/04/10 11:45:08 INFO DAGScheduler: Missing parents: List()
21/04/10 11:45:08 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[16] at collect at utils.scala:135), which has no missing parents
21/04/10 11:45:08 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 6.5 KB, free 912.3 MB)
21/04/10 11:45:08 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.3 KB, free 912.3 MB)
21/04/10 11:45:08 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:64206 (size: 3.3 KB, free: 912.3 MB)
21/04/10 11:45:08 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1161
21/04/10 11:45:08 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[16] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/04/10 11:45:08 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
21/04/10 11:45:08 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 8080 bytes)
21/04/10 11:45:08 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
21/04/10 11:45:08 INFO CodeGenerator: Code generated in 4.3997 ms
21/04/10 11:45:08 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1243 bytes result sent to driver
21/04/10 11:45:08 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 15 ms on localhost (executor driver) (1/1)
21/04/10 11:45:08 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
21/04/10 11:45:08 INFO DAGScheduler: ResultStage 3 (collect at utils.scala:135) finished in 0.019 s
21/04/10 11:45:08 INFO DAGScheduler: Job 2 finished: collect at utils.scala:135, took 0.021091 s
21/04/10 11:45:08 INFO SparkContext: Starting job: count at utils.scala:135
21/04/10 11:45:08 INFO DAGScheduler: Registering RDD 19 (count at utils.scala:135)
21/04/10 11:45:08 INFO DAGScheduler: Got job 3 (count at utils.scala:135) with 1 output partitions
21/04/10 11:45:08 INFO DAGScheduler: Final stage: ResultStage 5 (count at utils.scala:135)
21/04/10 11:45:08 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
21/04/10 11:45:08 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 4)
21/04/10 11:45:08 INFO DAGScheduler: Submitting ShuffleMapStage 4 (MapPartitionsRDD[19] at count at utils.scala:135), which has no missing parents
21/04/10 11:45:08 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 8.4 KB, free 912.3 MB)
21/04/10 11:45:08 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 4.5 KB, free 912.2 MB)
21/04/10 11:45:08 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:64206 (size: 4.5 KB, free: 912.3 MB)
21/04/10 11:45:08 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1161
21/04/10 11:45:08 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[19] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/04/10 11:45:08 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
21/04/10 11:45:08 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 8069 bytes)
21/04/10 11:45:08 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
21/04/10 11:45:08 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1413 bytes result sent to driver
21/04/10 11:45:08 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 7 ms on localhost (executor driver) (1/1)
21/04/10 11:45:08 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
21/04/10 11:45:08 INFO DAGScheduler: ShuffleMapStage 4 (count at utils.scala:135) finished in 0.012 s
21/04/10 11:45:08 INFO DAGScheduler: looking for newly runnable stages
21/04/10 11:45:08 INFO DAGScheduler: running: Set()
21/04/10 11:45:08 INFO DAGScheduler: waiting: Set(ResultStage 5)
21/04/10 11:45:08 INFO DAGScheduler: failed: Set()
21/04/10 11:45:08 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[22] at count at utils.scala:135), which has no missing parents
21/04/10 11:45:08 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.1 KB, free 912.2 MB)
21/04/10 11:45:08 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.2 MB)
21/04/10 11:45:08 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:64206 (size: 3.8 KB, free: 912.3 MB)
21/04/10 11:45:08 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1161
21/04/10 11:45:08 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[22] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/04/10 11:45:08 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
21/04/10 11:45:08 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, ANY, 7767 bytes)
21/04/10 11:45:08 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
21/04/10 11:45:08 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/04/10 11:45:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/04/10 11:45:08 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1739 bytes result sent to driver
21/04/10 11:45:08 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 5 ms on localhost (executor driver) (1/1)
21/04/10 11:45:08 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
21/04/10 11:45:08 INFO DAGScheduler: ResultStage 5 (count at utils.scala:135) finished in 0.010 s
21/04/10 11:45:08 INFO DAGScheduler: Job 3 finished: count at utils.scala:135, took 0.023972 s
21/04/10 11:45:09 INFO SparkContext: Starting job: collect at utils.scala:135
21/04/10 11:45:09 INFO DAGScheduler: Got job 4 (collect at utils.scala:135) with 1 output partitions
21/04/10 11:45:09 INFO DAGScheduler: Final stage: ResultStage 6 (collect at utils.scala:135)
21/04/10 11:45:09 INFO DAGScheduler: Parents of final stage: List()
21/04/10 11:45:09 INFO DAGScheduler: Missing parents: List()
21/04/10 11:45:09 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[25] at collect at utils.scala:135), which has no missing parents
21/04/10 11:45:09 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 6.5 KB, free 912.2 MB)
21/04/10 11:45:09 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.3 KB, free 912.2 MB)
21/04/10 11:45:09 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:64206 (size: 3.3 KB, free: 912.3 MB)
21/04/10 11:45:09 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1161
21/04/10 11:45:09 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[25] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/04/10 11:45:09 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
21/04/10 11:45:09 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, PROCESS_LOCAL, 8080 bytes)
21/04/10 11:45:09 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
21/04/10 11:45:09 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 1200 bytes result sent to driver
21/04/10 11:45:09 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 3 ms on localhost (executor driver) (1/1)
21/04/10 11:45:09 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
21/04/10 11:45:09 INFO DAGScheduler: ResultStage 6 (collect at utils.scala:135) finished in 0.006 s
21/04/10 11:45:09 INFO DAGScheduler: Job 4 finished: collect at utils.scala:135, took 0.007199 s
21/04/10 11:45:09 INFO SparkContext: Starting job: count at utils.scala:135
21/04/10 11:45:09 INFO DAGScheduler: Registering RDD 28 (count at utils.scala:135)
21/04/10 11:45:09 INFO DAGScheduler: Got job 5 (count at utils.scala:135) with 1 output partitions
21/04/10 11:45:09 INFO DAGScheduler: Final stage: ResultStage 8 (count at utils.scala:135)
21/04/10 11:45:09 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
21/04/10 11:45:09 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 7)
21/04/10 11:45:09 INFO DAGScheduler: Submitting ShuffleMapStage 7 (MapPartitionsRDD[28] at count at utils.scala:135), which has no missing parents
21/04/10 11:45:09 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 8.4 KB, free 912.2 MB)
21/04/10 11:45:09 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 4.5 KB, free 912.2 MB)
21/04/10 11:45:09 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:64206 (size: 4.5 KB, free: 912.3 MB)
21/04/10 11:45:09 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1161
21/04/10 11:45:09 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[28] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/04/10 11:45:09 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
21/04/10 11:45:09 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7, localhost, executor driver, partition 0, PROCESS_LOCAL, 8069 bytes)
21/04/10 11:45:09 INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
21/04/10 11:45:09 INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 1456 bytes result sent to driver
21/04/10 11:45:09 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 6 ms on localhost (executor driver) (1/1)
21/04/10 11:45:09 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
21/04/10 11:45:09 INFO DAGScheduler: ShuffleMapStage 7 (count at utils.scala:135) finished in 0.011 s
21/04/10 11:45:09 INFO DAGScheduler: looking for newly runnable stages
21/04/10 11:45:09 INFO DAGScheduler: running: Set()
21/04/10 11:45:09 INFO DAGScheduler: waiting: Set(ResultStage 8)
21/04/10 11:45:09 INFO DAGScheduler: failed: Set()
21/04/10 11:45:09 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[31] at count at utils.scala:135), which has no missing parents
21/04/10 11:45:09 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 7.1 KB, free 912.2 MB)
21/04/10 11:45:09 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.2 MB)
21/04/10 11:45:09 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:64206 (size: 3.8 KB, free: 912.3 MB)
21/04/10 11:45:09 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1161
21/04/10 11:45:09 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[31] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/04/10 11:45:09 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
21/04/10 11:45:09 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8, localhost, executor driver, partition 0, ANY, 7767 bytes)
21/04/10 11:45:09 INFO Executor: Running task 0.0 in stage 8.0 (TID 8)
21/04/10 11:45:09 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/04/10 11:45:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/04/10 11:45:09 INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 1696 bytes result sent to driver
21/04/10 11:45:09 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 4 ms on localhost (executor driver) (1/1)
21/04/10 11:45:09 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
21/04/10 11:45:09 INFO DAGScheduler: ResultStage 8 (count at utils.scala:135) finished in 0.008 s
21/04/10 11:45:09 INFO DAGScheduler: Job 5 finished: count at utils.scala:135, took 0.021271 s
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 77
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 244
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 216
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 105
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 79
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 194
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 269
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 151
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 169
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 111
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 118
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 183
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 166
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 224
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 248
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 130
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 200
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 209
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 88
21/04/10 11:45:09 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:64206 in memory (size: 4.5 KB, free: 912.3 MB)
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 257
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 237
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 161
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 193
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 132
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 272
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 191
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 99
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 138
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 70
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 179
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 196
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 127
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 93
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 210
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 131
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 98
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 195
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 263
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 87
21/04/10 11:45:09 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 127.0.0.1:64206 in memory (size: 3.4 KB, free: 912.3 MB)
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 96
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 73
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 94
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 89
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 231
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 199
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 103
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 236
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 68
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 214
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 186
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 181
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 173
21/04/10 11:45:09 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 127.0.0.1:64206 in memory (size: 3.8 KB, free: 912.3 MB)
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 106
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 203
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 259
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 156
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 226
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 134
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 164
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 121
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 208
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 223
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 122
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 90
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 220
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 242
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 176
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 239
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 240
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 256
21/04/10 11:45:09 INFO ContextCleaner: Cleaned shuffle 2
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 102
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 152
21/04/10 11:45:09 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 127.0.0.1:64206 in memory (size: 3.8 KB, free: 912.3 MB)
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 235
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 81
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 133
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 136
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 113
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 171
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 212
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 146
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 273
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 232
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 110
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 160
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 198
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 69
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 174
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 217
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 95
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 197
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 155
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 192
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 137
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 86
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 123
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 213
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 109
21/04/10 11:45:09 INFO ContextCleaner: Cleaned shuffle 1
21/04/10 11:45:09 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:64206 in memory (size: 3.3 KB, free: 912.3 MB)
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 225
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 135
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 250
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 265
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 116
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 201
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 270
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 163
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 255
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 229
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 114
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 249
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 222
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 84
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 149
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 233
21/04/10 11:45:09 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 127.0.0.1:64206 in memory (size: 4.5 KB, free: 912.3 MB)
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 261
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 117
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 157
21/04/10 11:45:09 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:64206 in memory (size: 3.3 KB, free: 912.3 MB)
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 187
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 158
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 227
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 168
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 274
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 128
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 97
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 67
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 276
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 253
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 141
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 66
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 140
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 238
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 101
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 159
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 202
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 139
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 147
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 230
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 148
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 241
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 262
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 107
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 218
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 251
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 144
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 75
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 175
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 145
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 182
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 190
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 170
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 92
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 207
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 108
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 72
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 177
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 83
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 245
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 129
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 189
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 228
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 153
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 275
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 258
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 206
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 76
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 85
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 126
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 154
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 266
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 268
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 124
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 267
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 119
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 167
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 205
21/04/10 11:45:09 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 127.0.0.1:64206 in memory (size: 3.8 KB, free: 912.3 MB)
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 204
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 74
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 78
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 246
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 260
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 178
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 252
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 115
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 219
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 172
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 120
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 271
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 162
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 80
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 142
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 254
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 221
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 188
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 143
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 234
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 82
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 211
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 247
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 125
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 91
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 100
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 180
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 243
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 264
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 215
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 185
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 104
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 150
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 71
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 112
21/04/10 11:45:09 INFO ContextCleaner: Cleaned accumulator 165
21/04/10 11:45:09 INFO CodeGenerator: Code generated in 5.5419 ms
21/04/10 11:45:09 INFO CodeGenerator: Code generated in 27.7726 ms
21/04/10 11:45:09 INFO SparkContext: Starting job: first at LinearRegression.scala:321
21/04/10 11:45:09 INFO DAGScheduler: Got job 6 (first at LinearRegression.scala:321) with 1 output partitions
21/04/10 11:45:09 INFO DAGScheduler: Final stage: ResultStage 9 (first at LinearRegression.scala:321)
21/04/10 11:45:09 INFO DAGScheduler: Parents of final stage: List()
21/04/10 11:45:09 INFO DAGScheduler: Missing parents: List()
21/04/10 11:45:09 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[38] at first at LinearRegression.scala:321), which has no missing parents
21/04/10 11:45:09 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 32.3 KB, free 912.3 MB)
21/04/10 11:45:09 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 12.5 KB, free 912.2 MB)
21/04/10 11:45:09 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:64206 (size: 12.5 KB, free: 912.3 MB)
21/04/10 11:45:09 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1161
21/04/10 11:45:09 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[38] at first at LinearRegression.scala:321) (first 15 tasks are for partitions Vector(0))
21/04/10 11:45:09 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
21/04/10 11:45:09 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 9, localhost, executor driver, partition 0, PROCESS_LOCAL, 11627 bytes)
21/04/10 11:45:09 INFO Executor: Running task 0.0 in stage 9.0 (TID 9)
21/04/10 11:45:09 INFO CodeGenerator: Code generated in 8.8138 ms
21/04/10 11:45:09 INFO MemoryStore: Block rdd_33_0 stored as values in memory (estimated size 4.2 KB, free 912.2 MB)
21/04/10 11:45:09 INFO BlockManagerInfo: Added rdd_33_0 in memory on 127.0.0.1:64206 (size: 4.2 KB, free: 912.3 MB)
21/04/10 11:45:09 INFO CodeGenerator: Code generated in 2.8612 ms
21/04/10 11:45:09 INFO Executor: 1 block locks were not released by TID = 9:
[rdd_33_0]
21/04/10 11:45:09 INFO Executor: Finished task 0.0 in stage 9.0 (TID 9). 1286 bytes result sent to driver
21/04/10 11:45:09 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 9) in 83 ms on localhost (executor driver) (1/1)
21/04/10 11:45:09 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
21/04/10 11:45:09 INFO DAGScheduler: ResultStage 9 (first at LinearRegression.scala:321) finished in 0.093 s
21/04/10 11:45:09 INFO DAGScheduler: Job 6 finished: first at LinearRegression.scala:321, took 0.098264 s
21/04/10 11:45:10 INFO CodeGenerator: Code generated in 15.5263 ms
21/04/10 11:45:10 INFO Instrumentation: [23195470] Stage class: LinearRegression
21/04/10 11:45:10 INFO Instrumentation: [23195470] Stage uid: linear_regression__1ee0beb6_c478_4ee3_a728_ca1699bd7840
21/04/10 11:45:10 INFO CodeGenerator: Code generated in 16.8632 ms
21/04/10 11:45:10 INFO Instrumentation: [23195470] training: numPartitions=1 storageLevel=StorageLevel(1 replicas)
21/04/10 11:45:10 INFO Instrumentation: [23195470] {"elasticNetParam":0.0,"featuresCol":"features","fitIntercept":true,"solver":"auto","labelCol":"label","predictionCol":"prediction","standardization":true,"loss":"squaredError","regParam":0.0,"tol":1.0E-6,"maxIter":100}
21/04/10 11:45:10 INFO Instrumentation: [23195470] {"numFeatures":1}
21/04/10 11:45:10 WARN Instrumentation: [23195470] regParam is zero, which might cause numerical instability and overfitting.
21/04/10 11:45:10 INFO SparkContext: Starting job: treeAggregate at WeightedLeastSquares.scala:105
21/04/10 11:45:10 INFO DAGScheduler: Got job 7 (treeAggregate at WeightedLeastSquares.scala:105) with 1 output partitions
21/04/10 11:45:10 INFO DAGScheduler: Final stage: ResultStage 10 (treeAggregate at WeightedLeastSquares.scala:105)
21/04/10 11:45:10 INFO DAGScheduler: Parents of final stage: List()
21/04/10 11:45:10 INFO DAGScheduler: Missing parents: List()
21/04/10 11:45:10 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[50] at treeAggregate at WeightedLeastSquares.scala:105), which has no missing parents
21/04/10 11:45:10 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 35.9 KB, free 912.2 MB)
21/04/10 11:45:10 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 14.2 KB, free 912.2 MB)
21/04/10 11:45:10 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:64206 (size: 14.2 KB, free: 912.3 MB)
21/04/10 11:45:10 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1161
21/04/10 11:45:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[50] at treeAggregate at WeightedLeastSquares.scala:105) (first 15 tasks are for partitions Vector(0))
21/04/10 11:45:10 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
21/04/10 11:45:10 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 10, localhost, executor driver, partition 0, PROCESS_LOCAL, 11627 bytes)
21/04/10 11:45:10 INFO Executor: Running task 0.0 in stage 10.0 (TID 10)
21/04/10 11:45:10 INFO BlockManager: Found block rdd_33_0 locally
21/04/10 11:45:10 INFO CodeGenerator: Code generated in 5.5644 ms
21/04/10 11:45:10 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
21/04/10 11:45:10 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS
21/04/10 11:45:10 INFO Executor: Finished task 0.0 in stage 10.0 (TID 10). 1719 bytes result sent to driver
21/04/10 11:45:10 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 10) in 30 ms on localhost (executor driver) (1/1)
21/04/10 11:45:10 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
21/04/10 11:45:10 INFO DAGScheduler: ResultStage 10 (treeAggregate at WeightedLeastSquares.scala:105) finished in 0.036 s
21/04/10 11:45:10 INFO DAGScheduler: Job 7 finished: treeAggregate at WeightedLeastSquares.scala:105, took 0.037618 s
21/04/10 11:45:10 INFO Instrumentation: [23195470] Number of instances: 32.
21/04/10 11:45:10 WARN LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeSystemLAPACK
21/04/10 11:45:10 WARN LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeRefLAPACK
21/04/10 11:45:10 INFO CodeGenerator: Code generated in 9.6697 ms
21/04/10 11:45:10 INFO SparkContext: Starting job: treeAggregate at RegressionMetrics.scala:57
21/04/10 11:45:10 INFO DAGScheduler: Got job 8 (treeAggregate at RegressionMetrics.scala:57) with 1 output partitions
21/04/10 11:45:10 INFO DAGScheduler: Final stage: ResultStage 11 (treeAggregate at RegressionMetrics.scala:57)
21/04/10 11:45:10 INFO DAGScheduler: Parents of final stage: List()
21/04/10 11:45:10 INFO DAGScheduler: Missing parents: List()
21/04/10 11:45:10 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[58] at treeAggregate at RegressionMetrics.scala:57), which has no missing parents
21/04/10 11:45:10 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 37.4 KB, free 912.2 MB)
21/04/10 11:45:10 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 16.1 KB, free 912.1 MB)
21/04/10 11:45:10 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:64206 (size: 16.1 KB, free: 912.3 MB)
21/04/10 11:45:10 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1161
21/04/10 11:45:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[58] at treeAggregate at RegressionMetrics.scala:57) (first 15 tasks are for partitions Vector(0))
21/04/10 11:45:10 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks
21/04/10 11:45:10 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 11, localhost, executor driver, partition 0, PROCESS_LOCAL, 11627 bytes)
21/04/10 11:45:10 INFO Executor: Running task 0.0 in stage 11.0 (TID 11)
21/04/10 11:45:10 INFO BlockManager: Found block rdd_33_0 locally
21/04/10 11:45:10 INFO CodeGenerator: Code generated in 6.2648 ms
21/04/10 11:45:10 INFO Executor: Finished task 0.0 in stage 11.0 (TID 11). 1869 bytes result sent to driver
21/04/10 11:45:10 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 11) in 26 ms on localhost (executor driver) (1/1)
21/04/10 11:45:10 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
21/04/10 11:45:10 INFO DAGScheduler: ResultStage 11 (treeAggregate at RegressionMetrics.scala:57) finished in 0.030 s
21/04/10 11:45:10 INFO DAGScheduler: Job 8 finished: treeAggregate at RegressionMetrics.scala:57, took 0.031608 s
21/04/10 11:45:10 INFO SparkContext: Starting job: sum at RegressionMetrics.scala:71
21/04/10 11:45:10 INFO DAGScheduler: Got job 9 (sum at RegressionMetrics.scala:71) with 1 output partitions
21/04/10 11:45:10 INFO DAGScheduler: Final stage: ResultStage 12 (sum at RegressionMetrics.scala:71)
21/04/10 11:45:10 INFO DAGScheduler: Parents of final stage: List()
21/04/10 11:45:10 INFO DAGScheduler: Missing parents: List()
21/04/10 11:45:10 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[59] at map at RegressionMetrics.scala:69), which has no missing parents
21/04/10 11:45:10 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 36.5 KB, free 912.1 MB)
21/04/10 11:45:10 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 15.8 KB, free 912.1 MB)
21/04/10 11:45:10 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:64206 (size: 15.8 KB, free: 912.2 MB)
21/04/10 11:45:10 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1161
21/04/10 11:45:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[59] at map at RegressionMetrics.scala:69) (first 15 tasks are for partitions Vector(0))
21/04/10 11:45:10 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
21/04/10 11:45:10 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 12, localhost, executor driver, partition 0, PROCESS_LOCAL, 11627 bytes)
21/04/10 11:45:10 INFO Executor: Running task 0.0 in stage 12.0 (TID 12)
21/04/10 11:45:10 INFO BlockManager: Found block rdd_33_0 locally
21/04/10 11:45:10 INFO Executor: Finished task 0.0 in stage 12.0 (TID 12). 1343 bytes result sent to driver
21/04/10 11:45:10 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 12) in 9 ms on localhost (executor driver) (1/1)
21/04/10 11:45:10 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
21/04/10 11:45:10 INFO DAGScheduler: ResultStage 12 (sum at RegressionMetrics.scala:71) finished in 0.014 s
21/04/10 11:45:10 INFO DAGScheduler: Job 9 finished: sum at RegressionMetrics.scala:71, took 0.015406 s
21/04/10 11:45:10 INFO CodeGenerator: Code generated in 9.0501 ms
21/04/10 11:45:10 INFO SparkContext: Starting job: count at LinearRegression.scala:952
21/04/10 11:45:10 INFO DAGScheduler: Registering RDD 63 (count at LinearRegression.scala:952)
21/04/10 11:45:10 INFO DAGScheduler: Got job 10 (count at LinearRegression.scala:952) with 1 output partitions
21/04/10 11:45:10 INFO DAGScheduler: Final stage: ResultStage 14 (count at LinearRegression.scala:952)
21/04/10 11:45:10 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 13)
21/04/10 11:45:10 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 13)
21/04/10 11:45:10 INFO DAGScheduler: Submitting ShuffleMapStage 13 (MapPartitionsRDD[63] at count at LinearRegression.scala:952), which has no missing parents
21/04/10 11:45:10 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 24.2 KB, free 912.1 MB)
21/04/10 11:45:10 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 10.8 KB, free 912.1 MB)
21/04/10 11:45:10 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 127.0.0.1:64206 (size: 10.8 KB, free: 912.2 MB)
21/04/10 11:45:10 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1161
21/04/10 11:45:10 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[63] at count at LinearRegression.scala:952) (first 15 tasks are for partitions Vector(0))
21/04/10 11:45:10 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
21/04/10 11:45:10 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 13, localhost, executor driver, partition 0, PROCESS_LOCAL, 11616 bytes)
21/04/10 11:45:10 INFO Executor: Running task 0.0 in stage 13.0 (TID 13)
21/04/10 11:45:10 INFO BlockManager: Found block rdd_33_0 locally
21/04/10 11:45:10 INFO Executor: Finished task 0.0 in stage 13.0 (TID 13). 2018 bytes result sent to driver
21/04/10 11:45:10 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 13) in 12 ms on localhost (executor driver) (1/1)
21/04/10 11:45:10 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
21/04/10 11:45:10 INFO DAGScheduler: ShuffleMapStage 13 (count at LinearRegression.scala:952) finished in 0.019 s
21/04/10 11:45:10 INFO DAGScheduler: looking for newly runnable stages
21/04/10 11:45:10 INFO DAGScheduler: running: Set()
21/04/10 11:45:10 INFO DAGScheduler: waiting: Set(ResultStage 14)
21/04/10 11:45:10 INFO DAGScheduler: failed: Set()
21/04/10 11:45:10 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[66] at count at LinearRegression.scala:952), which has no missing parents
21/04/10 11:45:10 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 7.1 KB, free 912.0 MB)
21/04/10 11:45:10 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.0 MB)
21/04/10 11:45:10 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 127.0.0.1:64206 (size: 3.8 KB, free: 912.2 MB)
21/04/10 11:45:10 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1161
21/04/10 11:45:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[66] at count at LinearRegression.scala:952) (first 15 tasks are for partitions Vector(0))
21/04/10 11:45:10 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
21/04/10 11:45:10 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 14, localhost, executor driver, partition 0, ANY, 7767 bytes)
21/04/10 11:45:10 INFO Executor: Running task 0.0 in stage 14.0 (TID 14)
21/04/10 11:45:10 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/04/10 11:45:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/04/10 11:45:10 INFO Executor: Finished task 0.0 in stage 14.0 (TID 14). 1653 bytes result sent to driver
21/04/10 11:45:10 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 14) in 5 ms on localhost (executor driver) (1/1)
21/04/10 11:45:10 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
21/04/10 11:45:10 INFO DAGScheduler: ResultStage 14 (count at LinearRegression.scala:952) finished in 0.009 s
21/04/10 11:45:10 INFO DAGScheduler: Job 10 finished: count at LinearRegression.scala:952, took 0.031476 s
21/04/10 11:45:10 INFO CodeGenerator: Code generated in 4.8607 ms
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 357
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 408
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 410
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 346
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 348
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 440
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 392
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 315
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 379
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 454
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 419
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 417
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 363
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 383
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 279
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 374
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 319
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 399
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 334
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 428
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 443
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 416
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 311
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 398
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 367
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 447
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 344
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 405
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 376
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 327
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 333
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 444
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 448
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 407
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 312
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 324
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 330
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 439
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 305
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 288
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 336
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 426
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 292
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 442
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 453
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 369
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 306
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 390
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 406
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 402
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 430
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 284
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 295
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 318
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 380
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 359
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 340
21/04/10 11:45:10 INFO CodeGenerator: Code generated in 16.3984 ms
21/04/10 11:45:10 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 127.0.0.1:64206 in memory (size: 10.8 KB, free: 912.2 MB)
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 421
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 397
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 437
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 452
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 388
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 424
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 293
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 299
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 449
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 282
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 278
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 425
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 323
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 434
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 404
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 433
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 385
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 341
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 445
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 431
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 436
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 302
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 294
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 332
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 304
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 377
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 314
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 420
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 353
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 370
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 375
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 350
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 329
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 395
21/04/10 11:45:10 INFO ContextCleaner: Cleaned shuffle 3
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 317
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 373
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 401
21/04/10 11:45:10 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 127.0.0.1:64206 in memory (size: 16.1 KB, free: 912.2 MB)
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 331
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 415
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 307
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 277
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 364
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 432
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 427
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 356
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 355
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 403
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 325
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 283
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 387
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 361
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 358
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 297
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 360
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 455
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 384
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 438
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 291
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 313
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 394
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 396
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 429
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 389
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 300
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 371
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 345
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 366
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 435
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 382
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 381
21/04/10 11:45:10 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 127.0.0.1:64206 in memory (size: 12.5 KB, free: 912.3 MB)
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 322
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 441
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 308
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 414
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 320
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 400
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 287
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 365
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 362
21/04/10 11:45:10 INFO SparkContext: Starting job: collect at utils.scala:135
21/04/10 11:45:10 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 127.0.0.1:64206 in memory (size: 3.8 KB, free: 912.3 MB)
21/04/10 11:45:10 INFO DAGScheduler: Got job 11 (collect at utils.scala:135) with 1 output partitions
21/04/10 11:45:10 INFO DAGScheduler: Final stage: ResultStage 15 (collect at utils.scala:135)
21/04/10 11:45:10 INFO DAGScheduler: Parents of final stage: List()
21/04/10 11:45:10 INFO DAGScheduler: Missing parents: List()
21/04/10 11:45:10 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[69] at collect at utils.scala:135), which has no missing parents
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 413
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 423
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 296
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 286
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 321
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 328
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 409
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 391
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 378
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 316
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 411
21/04/10 11:45:10 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 6.6 KB, free 912.2 MB)
21/04/10 11:45:10 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 127.0.0.1:64206 in memory (size: 14.2 KB, free: 912.3 MB)
21/04/10 11:45:10 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 3.3 KB, free 912.2 MB)
21/04/10 11:45:10 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 127.0.0.1:64206 (size: 3.3 KB, free: 912.3 MB)
21/04/10 11:45:10 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1161
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 343
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 354
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 352
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 368
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 290
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 326
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 386
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 347
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 342
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 298
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 372
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 309
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 310
21/04/10 11:45:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[69] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/04/10 11:45:10 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks
21/04/10 11:45:10 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 127.0.0.1:64206 in memory (size: 15.8 KB, free: 912.3 MB)
21/04/10 11:45:10 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 15, localhost, executor driver, partition 0, PROCESS_LOCAL, 8080 bytes)
21/04/10 11:45:10 INFO Executor: Running task 0.0 in stage 15.0 (TID 15)
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 418
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 303
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 446
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 450
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 281
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 393
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 422
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 289
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 285
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 351
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 412
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 451
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 335
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 301
21/04/10 11:45:10 INFO ContextCleaner: Cleaned accumulator 349
21/04/10 11:45:10 INFO Executor: Finished task 0.0 in stage 15.0 (TID 15). 1157 bytes result sent to driver
21/04/10 11:45:10 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 15) in 5 ms on localhost (executor driver) (1/1)
21/04/10 11:45:10 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
21/04/10 11:45:10 INFO DAGScheduler: ResultStage 15 (collect at utils.scala:135) finished in 0.009 s
21/04/10 11:45:10 INFO DAGScheduler: Job 11 finished: collect at utils.scala:135, took 0.010383 s
21/04/10 11:45:10 INFO SparkContext: Starting job: count at utils.scala:135
21/04/10 11:45:10 INFO DAGScheduler: Registering RDD 72 (count at utils.scala:135)
21/04/10 11:45:10 INFO DAGScheduler: Got job 12 (count at utils.scala:135) with 1 output partitions
21/04/10 11:45:10 INFO DAGScheduler: Final stage: ResultStage 17 (count at utils.scala:135)
21/04/10 11:45:10 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 16)
21/04/10 11:45:10 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 16)
21/04/10 11:45:10 INFO DAGScheduler: Submitting ShuffleMapStage 16 (MapPartitionsRDD[72] at count at utils.scala:135), which has no missing parents
21/04/10 11:45:10 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 8.4 KB, free 912.3 MB)
21/04/10 11:45:10 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 4.5 KB, free 912.3 MB)
21/04/10 11:45:10 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 127.0.0.1:64206 (size: 4.5 KB, free: 912.3 MB)
21/04/10 11:45:10 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1161
21/04/10 11:45:10 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 16 (MapPartitionsRDD[72] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/04/10 11:45:10 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks
21/04/10 11:45:10 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 16, localhost, executor driver, partition 0, PROCESS_LOCAL, 8069 bytes)
21/04/10 11:45:10 INFO Executor: Running task 0.0 in stage 16.0 (TID 16)
21/04/10 11:45:10 INFO Executor: Finished task 0.0 in stage 16.0 (TID 16). 1413 bytes result sent to driver
21/04/10 11:45:10 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 16) in 5 ms on localhost (executor driver) (1/1)
21/04/10 11:45:10 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
21/04/10 11:45:10 INFO DAGScheduler: ShuffleMapStage 16 (count at utils.scala:135) finished in 0.008 s
21/04/10 11:45:10 INFO DAGScheduler: looking for newly runnable stages
21/04/10 11:45:10 INFO DAGScheduler: running: Set()
21/04/10 11:45:10 INFO DAGScheduler: waiting: Set(ResultStage 17)
21/04/10 11:45:10 INFO DAGScheduler: failed: Set()
21/04/10 11:45:10 INFO DAGScheduler: Submitting ResultStage 17 (MapPartitionsRDD[75] at count at utils.scala:135), which has no missing parents
21/04/10 11:45:10 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 7.1 KB, free 912.3 MB)
21/04/10 11:45:10 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.3 MB)
21/04/10 11:45:10 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 127.0.0.1:64206 (size: 3.8 KB, free: 912.3 MB)
21/04/10 11:45:10 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1161
21/04/10 11:45:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 17 (MapPartitionsRDD[75] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/04/10 11:45:10 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks
21/04/10 11:45:10 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 17, localhost, executor driver, partition 0, ANY, 7767 bytes)
21/04/10 11:45:10 INFO Executor: Running task 0.0 in stage 17.0 (TID 17)
21/04/10 11:45:10 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/04/10 11:45:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/04/10 11:45:10 INFO Executor: Finished task 0.0 in stage 17.0 (TID 17). 1696 bytes result sent to driver
21/04/10 11:45:10 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 17) in 3 ms on localhost (executor driver) (1/1)
21/04/10 11:45:10 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
21/04/10 11:45:10 INFO DAGScheduler: ResultStage 17 (count at utils.scala:135) finished in 0.006 s
21/04/10 11:45:10 INFO DAGScheduler: Job 12 finished: count at utils.scala:135, took 0.015792 s
21/04/10 11:45:11 INFO CodeGenerator: Code generated in 4.787 ms
21/04/10 11:45:11 INFO CodeGenerator: Code generated in 4.5456 ms
21/04/10 11:45:11 INFO SparkContext: Starting job: collect at utils.scala:135
21/04/10 11:45:11 INFO DAGScheduler: Got job 13 (collect at utils.scala:135) with 1 output partitions
21/04/10 11:45:11 INFO DAGScheduler: Final stage: ResultStage 18 (collect at utils.scala:135)
21/04/10 11:45:11 INFO DAGScheduler: Parents of final stage: List()
21/04/10 11:45:11 INFO DAGScheduler: Missing parents: List()
21/04/10 11:45:11 INFO DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[78] at collect at utils.scala:135), which has no missing parents
21/04/10 11:45:11 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 6.6 KB, free 912.2 MB)
21/04/10 11:45:11 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 3.3 KB, free 912.2 MB)
21/04/10 11:45:11 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 127.0.0.1:64206 (size: 3.3 KB, free: 912.3 MB)
21/04/10 11:45:11 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1161
21/04/10 11:45:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 18 (MapPartitionsRDD[78] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/04/10 11:45:11 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks
21/04/10 11:45:11 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 18, localhost, executor driver, partition 0, PROCESS_LOCAL, 8080 bytes)
21/04/10 11:45:11 INFO Executor: Running task 0.0 in stage 18.0 (TID 18)
21/04/10 11:45:11 INFO Executor: Finished task 0.0 in stage 18.0 (TID 18). 1200 bytes result sent to driver
21/04/10 11:45:11 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 18) in 4 ms on localhost (executor driver) (1/1)
21/04/10 11:45:11 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
21/04/10 11:45:11 INFO DAGScheduler: ResultStage 18 (collect at utils.scala:135) finished in 0.007 s
21/04/10 11:45:11 INFO DAGScheduler: Job 13 finished: collect at utils.scala:135, took 0.007848 s
21/04/10 11:45:11 INFO SparkContext: Starting job: count at utils.scala:135
21/04/10 11:45:11 INFO DAGScheduler: Registering RDD 81 (count at utils.scala:135)
21/04/10 11:45:11 INFO DAGScheduler: Got job 14 (count at utils.scala:135) with 1 output partitions
21/04/10 11:45:11 INFO DAGScheduler: Final stage: ResultStage 20 (count at utils.scala:135)
21/04/10 11:45:11 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 19)
21/04/10 11:45:11 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 19)
21/04/10 11:45:11 INFO DAGScheduler: Submitting ShuffleMapStage 19 (MapPartitionsRDD[81] at count at utils.scala:135), which has no missing parents
21/04/10 11:45:11 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 8.4 KB, free 912.2 MB)
21/04/10 11:45:11 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 4.5 KB, free 912.2 MB)
21/04/10 11:45:11 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 127.0.0.1:64206 (size: 4.5 KB, free: 912.3 MB)
21/04/10 11:45:11 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1161
21/04/10 11:45:11 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 19 (MapPartitionsRDD[81] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/04/10 11:45:11 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks
21/04/10 11:45:11 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 19, localhost, executor driver, partition 0, PROCESS_LOCAL, 8069 bytes)
21/04/10 11:45:11 INFO Executor: Running task 0.0 in stage 19.0 (TID 19)
21/04/10 11:45:11 INFO Executor: Finished task 0.0 in stage 19.0 (TID 19). 1456 bytes result sent to driver
21/04/10 11:45:11 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 19) in 5 ms on localhost (executor driver) (1/1)
21/04/10 11:45:11 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
21/04/10 11:45:11 INFO DAGScheduler: ShuffleMapStage 19 (count at utils.scala:135) finished in 0.010 s
21/04/10 11:45:11 INFO DAGScheduler: looking for newly runnable stages
21/04/10 11:45:11 INFO DAGScheduler: running: Set()
21/04/10 11:45:11 INFO DAGScheduler: waiting: Set(ResultStage 20)
21/04/10 11:45:11 INFO DAGScheduler: failed: Set()
21/04/10 11:45:11 INFO DAGScheduler: Submitting ResultStage 20 (MapPartitionsRDD[84] at count at utils.scala:135), which has no missing parents
21/04/10 11:45:11 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 7.1 KB, free 912.2 MB)
21/04/10 11:45:11 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.2 MB)
21/04/10 11:45:11 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 127.0.0.1:64206 (size: 3.8 KB, free: 912.3 MB)
21/04/10 11:45:11 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1161
21/04/10 11:45:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 20 (MapPartitionsRDD[84] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/04/10 11:45:11 INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks
21/04/10 11:45:11 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 20, localhost, executor driver, partition 0, ANY, 7767 bytes)
21/04/10 11:45:11 INFO Executor: Running task 0.0 in stage 20.0 (TID 20)
21/04/10 11:45:11 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/04/10 11:45:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/04/10 11:45:11 INFO Executor: Finished task 0.0 in stage 20.0 (TID 20). 1653 bytes result sent to driver
21/04/10 11:45:11 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 20) in 3 ms on localhost (executor driver) (1/1)
21/04/10 11:45:11 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
21/04/10 11:45:11 INFO DAGScheduler: ResultStage 20 (count at utils.scala:135) finished in 0.006 s
21/04/10 11:45:11 INFO DAGScheduler: Job 14 finished: count at utils.scala:135, took 0.017477 s
21/04/10 11:45:11 INFO SparkContext: Starting job: collect at utils.scala:135
21/04/10 11:45:11 INFO DAGScheduler: Got job 15 (collect at utils.scala:135) with 1 output partitions
21/04/10 11:45:11 INFO DAGScheduler: Final stage: ResultStage 21 (collect at utils.scala:135)
21/04/10 11:45:11 INFO DAGScheduler: Parents of final stage: List()
21/04/10 11:45:11 INFO DAGScheduler: Missing parents: List()
21/04/10 11:45:11 INFO DAGScheduler: Submitting ResultStage 21 (MapPartitionsRDD[87] at collect at utils.scala:135), which has no missing parents
21/04/10 11:45:11 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 6.6 KB, free 912.2 MB)
21/04/10 11:45:11 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 3.3 KB, free 912.2 MB)
21/04/10 11:45:11 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 127.0.0.1:64206 (size: 3.3 KB, free: 912.3 MB)
21/04/10 11:45:11 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1161
21/04/10 11:45:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 21 (MapPartitionsRDD[87] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/04/10 11:45:11 INFO TaskSchedulerImpl: Adding task set 21.0 with 1 tasks
21/04/10 11:45:11 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 21, localhost, executor driver, partition 0, PROCESS_LOCAL, 8080 bytes)
21/04/10 11:45:11 INFO Executor: Running task 0.0 in stage 21.0 (TID 21)
21/04/10 11:45:11 INFO Executor: Finished task 0.0 in stage 21.0 (TID 21). 1200 bytes result sent to driver
21/04/10 11:45:11 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 21) in 3 ms on localhost (executor driver) (1/1)
21/04/10 11:45:11 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
21/04/10 11:45:11 INFO DAGScheduler: ResultStage 21 (collect at utils.scala:135) finished in 0.005 s
21/04/10 11:45:11 INFO DAGScheduler: Job 15 finished: collect at utils.scala:135, took 0.005977 s
21/04/10 11:45:11 INFO SparkContext: Starting job: count at utils.scala:135
21/04/10 11:45:11 INFO DAGScheduler: Registering RDD 90 (count at utils.scala:135)
21/04/10 11:45:11 INFO DAGScheduler: Got job 16 (count at utils.scala:135) with 1 output partitions
21/04/10 11:45:11 INFO DAGScheduler: Final stage: ResultStage 23 (count at utils.scala:135)
21/04/10 11:45:11 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 22)
21/04/10 11:45:11 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 22)
21/04/10 11:45:11 INFO DAGScheduler: Submitting ShuffleMapStage 22 (MapPartitionsRDD[90] at count at utils.scala:135), which has no missing parents
21/04/10 11:45:11 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 8.4 KB, free 912.2 MB)
21/04/10 11:45:11 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 4.5 KB, free 912.2 MB)
21/04/10 11:45:11 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 127.0.0.1:64206 (size: 4.5 KB, free: 912.3 MB)
21/04/10 11:45:11 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1161
21/04/10 11:45:11 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 22 (MapPartitionsRDD[90] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/04/10 11:45:11 INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks
21/04/10 11:45:11 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 22, localhost, executor driver, partition 0, PROCESS_LOCAL, 8069 bytes)
21/04/10 11:45:11 INFO Executor: Running task 0.0 in stage 22.0 (TID 22)
21/04/10 11:45:11 INFO Executor: Finished task 0.0 in stage 22.0 (TID 22). 1370 bytes result sent to driver
21/04/10 11:45:11 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 22) in 4 ms on localhost (executor driver) (1/1)
21/04/10 11:45:11 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
21/04/10 11:45:11 INFO DAGScheduler: ShuffleMapStage 22 (count at utils.scala:135) finished in 0.008 s
21/04/10 11:45:11 INFO DAGScheduler: looking for newly runnable stages
21/04/10 11:45:11 INFO DAGScheduler: running: Set()
21/04/10 11:45:11 INFO DAGScheduler: waiting: Set(ResultStage 23)
21/04/10 11:45:11 INFO DAGScheduler: failed: Set()
21/04/10 11:45:11 INFO DAGScheduler: Submitting ResultStage 23 (MapPartitionsRDD[93] at count at utils.scala:135), which has no missing parents
21/04/10 11:45:11 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 7.1 KB, free 912.2 MB)
21/04/10 11:45:11 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.2 MB)
21/04/10 11:45:11 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 127.0.0.1:64206 (size: 3.8 KB, free: 912.3 MB)
21/04/10 11:45:11 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1161
21/04/10 11:45:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 23 (MapPartitionsRDD[93] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/04/10 11:45:11 INFO TaskSchedulerImpl: Adding task set 23.0 with 1 tasks
21/04/10 11:45:11 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 23, localhost, executor driver, partition 0, ANY, 7767 bytes)
21/04/10 11:45:11 INFO Executor: Running task 0.0 in stage 23.0 (TID 23)
21/04/10 11:45:11 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/04/10 11:45:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/04/10 11:45:11 INFO Executor: Finished task 0.0 in stage 23.0 (TID 23). 1653 bytes result sent to driver
21/04/10 11:45:11 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 23) in 4 ms on localhost (executor driver) (1/1)
21/04/10 11:45:11 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool 
21/04/10 11:45:11 INFO DAGScheduler: ResultStage 23 (count at utils.scala:135) finished in 0.006 s
21/04/10 11:45:11 INFO DAGScheduler: Job 16 finished: count at utils.scala:135, took 0.015009 s
21/04/10 11:45:11 INFO SparkContext: Invoking stop() from shutdown hook
21/04/10 11:45:11 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
21/04/10 11:45:11 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/04/10 11:45:11 INFO MemoryStore: MemoryStore cleared
21/04/10 11:45:11 INFO BlockManager: BlockManager stopped
21/04/10 11:45:11 INFO BlockManagerMaster: BlockManagerMaster stopped
21/04/10 11:45:11 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/04/10 11:45:11 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\lizha\AppData\Local\spark\spark-2.4.3-bin-hadoop2.7\tmp\local\spark-b42ec8ae-c7fb-49a7-8d1a-c0aa1078a961\userFiles-25723973-8343-4d7f-bb2a-bac549a965ef
java.io.IOException: Failed to delete: C:\Users\lizha\AppData\Local\spark\spark-2.4.3-bin-hadoop2.7\tmp\local\spark-b42ec8ae-c7fb-49a7-8d1a-c0aa1078a961\userFiles-25723973-8343-4d7f-bb2a-bac549a965ef\sparklyr-2.4-2.11.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:144)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:128)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:91)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1062)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:103)
	at org.apache.spark.SparkContext$$anonfun$stop$11.apply$mcV$sp(SparkContext.scala:1974)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1340)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1973)
	at org.apache.spark.SparkContext$$anonfun$2.apply$mcV$sp(SparkContext.scala:575)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1945)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
21/04/10 11:45:11 INFO SparkContext: Successfully stopped SparkContext
21/04/10 11:45:11 INFO ShutdownHookManager: Shutdown hook called
21/04/10 11:45:11 INFO ShutdownHookManager: Deleting directory C:\Users\lizha\AppData\Local\Temp\spark-36f45187-6592-4fa1-a306-820f7feb8e6d
21/04/10 11:45:11 INFO ShutdownHookManager: Deleting directory C:\Users\lizha\AppData\Local\spark\spark-2.4.3-bin-hadoop2.7\tmp\local\spark-b42ec8ae-c7fb-49a7-8d1a-c0aa1078a961\userFiles-25723973-8343-4d7f-bb2a-bac549a965ef
21/04/10 11:45:11 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\lizha\AppData\Local\spark\spark-2.4.3-bin-hadoop2.7\tmp\local\spark-b42ec8ae-c7fb-49a7-8d1a-c0aa1078a961\userFiles-25723973-8343-4d7f-bb2a-bac549a965ef
java.io.IOException: Failed to delete: C:\Users\lizha\AppData\Local\spark\spark-2.4.3-bin-hadoop2.7\tmp\local\spark-b42ec8ae-c7fb-49a7-8d1a-c0aa1078a961\userFiles-25723973-8343-4d7f-bb2a-bac549a965ef\sparklyr-2.4-2.11.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:144)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:128)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:91)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1062)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1945)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
21/04/10 11:45:11 INFO ShutdownHookManager: Deleting directory C:\Users\lizha\AppData\Local\spark\spark-2.4.3-bin-hadoop2.7\tmp\local\spark-b42ec8ae-c7fb-49a7-8d1a-c0aa1078a961
21/04/10 11:45:11 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\lizha\AppData\Local\spark\spark-2.4.3-bin-hadoop2.7\tmp\local\spark-b42ec8ae-c7fb-49a7-8d1a-c0aa1078a961
java.io.IOException: Failed to delete: C:\Users\lizha\AppData\Local\spark\spark-2.4.3-bin-hadoop2.7\tmp\local\spark-b42ec8ae-c7fb-49a7-8d1a-c0aa1078a961\userFiles-25723973-8343-4d7f-bb2a-bac549a965ef\sparklyr-2.4-2.11.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:144)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:128)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:128)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:91)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1062)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1945)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
