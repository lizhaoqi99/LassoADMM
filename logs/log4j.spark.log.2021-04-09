21/04/09 23:26:17 INFO SparkContext: Running Spark version 2.4.3
21/04/09 23:26:17 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
21/04/09 23:26:17 INFO SparkContext: Submitted application: sparklyr
21/04/09 23:26:17 INFO SecurityManager: Changing view acls to: lizha
21/04/09 23:26:17 INFO SecurityManager: Changing modify acls to: lizha
21/04/09 23:26:17 INFO SecurityManager: Changing view acls groups to: 
21/04/09 23:26:17 INFO SecurityManager: Changing modify acls groups to: 
21/04/09 23:26:17 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(lizha); groups with view permissions: Set(); users  with modify permissions: Set(lizha); groups with modify permissions: Set()
21/04/09 23:26:17 INFO Utils: Successfully started service 'sparkDriver' on port 52351.
21/04/09 23:26:17 INFO SparkEnv: Registering MapOutputTracker
21/04/09 23:26:17 INFO SparkEnv: Registering BlockManagerMaster
21/04/09 23:26:17 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/04/09 23:26:17 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/04/09 23:26:17 INFO DiskBlockManager: Created local directory at C:\Users\lizha\AppData\Local\spark\spark-2.4.3-bin-hadoop2.7\tmp\local\blockmgr-79b17bab-9d19-4e80-9a0e-40d0cee78c85
21/04/09 23:26:17 INFO MemoryStore: MemoryStore started with capacity 912.3 MB
21/04/09 23:26:17 INFO SparkEnv: Registering OutputCommitCoordinator
21/04/09 23:26:17 WARN Utils: The configured local directories are not expected to be URIs; however, got suspicious values [C:/Users/lizha/AppData/Local/spark/spark-2.4.3-bin-hadoop2.7/tmp/local]. Please check your configured local directories.
21/04/09 23:26:17 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/04/09 23:26:17 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
21/04/09 23:26:17 INFO SparkContext: Added JAR file:/E:/OneDrive/Documents/R/win-library/4.0/sparklyr/java/sparklyr-2.4-2.11.jar at spark://127.0.0.1:52351/jars/sparklyr-2.4-2.11.jar with timestamp 1618028777765
21/04/09 23:26:17 INFO Executor: Starting executor ID driver on host localhost
21/04/09 23:26:17 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52393.
21/04/09 23:26:17 INFO NettyBlockTransferService: Server created on 127.0.0.1:52393
21/04/09 23:26:17 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/04/09 23:26:17 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 52393, None)
21/04/09 23:26:17 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:52393 with 912.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 52393, None)
21/04/09 23:26:17 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 52393, None)
21/04/09 23:26:17 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 52393, None)
21/04/09 23:26:18 INFO SharedState: loading hive config file: file:/C:/Users/lizha/AppData/Local/spark/spark-2.4.3-bin-hadoop2.7/conf/hive-site.xml
21/04/09 23:26:18 INFO SharedState: Setting hive.metastore.warehouse.dir ('C:/Users/lizha/AppData/Local/spark/spark-2.4.3-bin-hadoop2.7/tmp/hive') to the value of spark.sql.warehouse.dir ('C:/Users/lizha/AppData/Local/spark/spark-2.4.3-bin-hadoop2.7/tmp/hive').
21/04/09 23:26:18 INFO SharedState: Warehouse path is 'C:/Users/lizha/AppData/Local/spark/spark-2.4.3-bin-hadoop2.7/tmp/hive'.
21/04/09 23:26:18 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
21/04/09 23:26:20 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
21/04/09 23:26:20 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
21/04/09 23:26:20 INFO ObjectStore: ObjectStore, initialize called
21/04/09 23:26:20 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
21/04/09 23:26:20 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
21/04/09 23:26:21 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
21/04/09 23:26:22 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/04/09 23:26:22 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/04/09 23:26:22 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/04/09 23:26:22 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/04/09 23:26:22 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
21/04/09 23:26:22 INFO ObjectStore: Initialized ObjectStore
21/04/09 23:26:22 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
21/04/09 23:26:22 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
21/04/09 23:26:23 INFO HiveMetaStore: Added admin role in metastore
21/04/09 23:26:23 INFO HiveMetaStore: Added public role in metastore
21/04/09 23:26:23 INFO HiveMetaStore: No user is added in admin role, since config is empty
21/04/09 23:26:23 INFO HiveMetaStore: 0: get_all_databases
21/04/09 23:26:23 INFO audit: ugi=lizha	ip=unknown-ip-addr	cmd=get_all_databases	
21/04/09 23:26:23 INFO HiveMetaStore: 0: get_functions: db=default pat=*
21/04/09 23:26:23 INFO audit: ugi=lizha	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
21/04/09 23:26:23 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
21/04/09 23:26:23 INFO SessionState: Created local directory: C:/Users/lizha/AppData/Local/Temp/6f112c57-a653-49dc-91d5-9748bff7da7b_resources
21/04/09 23:26:23 INFO SessionState: Created HDFS directory: C:/Users/lizha/AppData/Local/spark/spark-2.4.3-bin-hadoop2.7/tmp/hive/lizha/6f112c57-a653-49dc-91d5-9748bff7da7b
21/04/09 23:26:23 INFO SessionState: Created local directory: C:/Users/lizha/AppData/Local/spark/spark-2.4.3-bin-hadoop2.7/tmp/hive/6f112c57-a653-49dc-91d5-9748bff7da7b
21/04/09 23:26:23 INFO SessionState: Created HDFS directory: C:/Users/lizha/AppData/Local/spark/spark-2.4.3-bin-hadoop2.7/tmp/hive/lizha/6f112c57-a653-49dc-91d5-9748bff7da7b/_tmp_space.db
21/04/09 23:26:23 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.2) is C:/Users/lizha/AppData/Local/spark/spark-2.4.3-bin-hadoop2.7/tmp/hive
21/04/09 23:26:23 INFO HiveMetaStore: 0: get_database: default
21/04/09 23:26:23 INFO audit: ugi=lizha	ip=unknown-ip-addr	cmd=get_database: default	
21/04/09 23:26:23 INFO HiveMetaStore: 0: get_database: global_temp
21/04/09 23:26:23 INFO audit: ugi=lizha	ip=unknown-ip-addr	cmd=get_database: global_temp	
21/04/09 23:26:23 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
21/04/09 23:26:23 INFO HiveMetaStore: 0: get_database: default
21/04/09 23:26:23 INFO audit: ugi=lizha	ip=unknown-ip-addr	cmd=get_database: default	
21/04/09 23:26:23 INFO HiveMetaStore: 0: get_database: default
21/04/09 23:26:23 INFO audit: ugi=lizha	ip=unknown-ip-addr	cmd=get_database: default	
21/04/09 23:26:23 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/04/09 23:26:23 INFO audit: ugi=lizha	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/04/09 23:26:23 INFO CodeGenerator: Code generated in 152.9417 ms
21/04/09 23:26:23 INFO CodeGenerator: Code generated in 12.3424 ms
21/04/09 23:26:23 INFO CodeGenerator: Code generated in 7.6711 ms
21/04/09 23:26:24 INFO SparkContext: Starting job: count at utils.scala:135
21/04/09 23:26:24 INFO DAGScheduler: Registering RDD 3 (count at utils.scala:135)
21/04/09 23:26:24 INFO DAGScheduler: Got job 0 (count at utils.scala:135) with 1 output partitions
21/04/09 23:26:24 INFO DAGScheduler: Final stage: ResultStage 1 (count at utils.scala:135)
21/04/09 23:26:24 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
21/04/09 23:26:24 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
21/04/09 23:26:24 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at count at utils.scala:135), which has no missing parents
21/04/09 23:26:24 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 7.9 KB, free 912.3 MB)
21/04/09 23:26:24 INFO ContextCleaner: Cleaned accumulator 1
21/04/09 23:26:24 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.2 KB, free 912.3 MB)
21/04/09 23:26:24 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:52393 (size: 4.2 KB, free: 912.3 MB)
21/04/09 23:26:24 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1161
21/04/09 23:26:24 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/04/09 23:26:24 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
21/04/09 23:26:24 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7882 bytes)
21/04/09 23:26:24 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
21/04/09 23:26:24 INFO Executor: Fetching spark://127.0.0.1:52351/jars/sparklyr-2.4-2.11.jar with timestamp 1618028777765
21/04/09 23:26:24 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:52351 after 16 ms (0 ms spent in bootstraps)
21/04/09 23:26:24 INFO Utils: Fetching spark://127.0.0.1:52351/jars/sparklyr-2.4-2.11.jar to C:\Users\lizha\AppData\Local\spark\spark-2.4.3-bin-hadoop2.7\tmp\local\spark-69b65a42-6574-4178-a660-cf3124786cac\userFiles-eaf43e3c-117c-4348-a56c-a053795c249a\fetchFileTemp8418023863531790222.tmp
21/04/09 23:26:24 INFO Executor: Adding file:/C:/Users/lizha/AppData/Local/spark/spark-2.4.3-bin-hadoop2.7/tmp/local/spark-69b65a42-6574-4178-a660-cf3124786cac/userFiles-eaf43e3c-117c-4348-a56c-a053795c249a/sparklyr-2.4-2.11.jar to class loader
21/04/09 23:26:24 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1542 bytes result sent to driver
21/04/09 23:26:24 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 220 ms on localhost (executor driver) (1/1)
21/04/09 23:26:24 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
21/04/09 23:26:24 INFO DAGScheduler: ShuffleMapStage 0 (count at utils.scala:135) finished in 0.418 s
21/04/09 23:26:24 INFO DAGScheduler: looking for newly runnable stages
21/04/09 23:26:24 INFO DAGScheduler: running: Set()
21/04/09 23:26:24 INFO DAGScheduler: waiting: Set(ResultStage 1)
21/04/09 23:26:24 INFO DAGScheduler: failed: Set()
21/04/09 23:26:24 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[6] at count at utils.scala:135), which has no missing parents
21/04/09 23:26:24 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 7.1 KB, free 912.3 MB)
21/04/09 23:26:24 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.3 MB)
21/04/09 23:26:24 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:52393 (size: 3.8 KB, free: 912.3 MB)
21/04/09 23:26:24 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1161
21/04/09 23:26:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/04/09 23:26:24 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
21/04/09 23:26:24 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, ANY, 7767 bytes)
21/04/09 23:26:24 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
21/04/09 23:26:24 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/04/09 23:26:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
21/04/09 23:26:24 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1775 bytes result sent to driver
21/04/09 23:26:24 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 40 ms on localhost (executor driver) (1/1)
21/04/09 23:26:24 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/04/09 23:26:24 INFO DAGScheduler: ResultStage 1 (count at utils.scala:135) finished in 0.048 s
21/04/09 23:26:24 INFO DAGScheduler: Job 0 finished: count at utils.scala:135, took 0.529859 s
21/04/09 23:27:23 INFO HiveMetaStore: 0: get_database: default
21/04/09 23:27:23 INFO audit: ugi=lizha	ip=unknown-ip-addr	cmd=get_database: default	
21/04/09 23:27:23 INFO HiveMetaStore: 0: get_database: default
21/04/09 23:27:23 INFO audit: ugi=lizha	ip=unknown-ip-addr	cmd=get_database: default	
21/04/09 23:27:23 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/04/09 23:27:23 INFO audit: ugi=lizha	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/04/09 23:27:23 INFO SparkContext: Starting job: collect at utils.scala:61
21/04/09 23:27:23 INFO DAGScheduler: Got job 1 (collect at utils.scala:61) with 1 output partitions
21/04/09 23:27:23 INFO DAGScheduler: Final stage: ResultStage 2 (collect at utils.scala:61)
21/04/09 23:27:23 INFO DAGScheduler: Parents of final stage: List()
21/04/09 23:27:23 INFO DAGScheduler: Missing parents: List()
21/04/09 23:27:23 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[11] at map at utils.scala:54), which has no missing parents
21/04/09 23:27:23 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 6.0 KB, free 912.3 MB)
21/04/09 23:27:23 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.4 KB, free 912.3 MB)
21/04/09 23:27:23 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:52393 (size: 3.4 KB, free: 912.3 MB)
21/04/09 23:27:23 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1161
21/04/09 23:27:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[11] at map at utils.scala:54) (first 15 tasks are for partitions Vector(0))
21/04/09 23:27:23 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
21/04/09 23:27:23 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 7893 bytes)
21/04/09 23:27:23 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
21/04/09 23:27:23 INFO CodeGenerator: Code generated in 7.1012 ms
21/04/09 23:27:23 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 927 bytes result sent to driver
21/04/09 23:27:23 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 14 ms on localhost (executor driver) (1/1)
21/04/09 23:27:23 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
21/04/09 23:27:23 INFO DAGScheduler: ResultStage 2 (collect at utils.scala:61) finished in 0.019 s
21/04/09 23:27:23 INFO DAGScheduler: Job 1 finished: collect at utils.scala:61, took 0.021049 s
21/04/09 23:27:23 INFO FileSourceStrategy: Pruning directories with: 
21/04/09 23:27:23 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#26, None)) > 0)
21/04/09 23:27:23 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
21/04/09 23:27:23 INFO FileSourceScanExec: Pushed Filters: 
21/04/09 23:27:23 INFO CodeGenerator: Code generated in 4.6404 ms
21/04/09 23:27:23 INFO CodeGenerator: Code generated in 6.7511 ms
21/04/09 23:27:23 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 286.0 KB, free 912.0 MB)
21/04/09 23:27:23 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 24.2 KB, free 912.0 MB)
21/04/09 23:27:23 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:52393 (size: 24.2 KB, free: 912.3 MB)
21/04/09 23:27:23 INFO SparkContext: Created broadcast 3 from csv at NativeMethodAccessorImpl.java:0
21/04/09 23:27:23 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
21/04/09 23:27:23 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
21/04/09 23:27:23 INFO DAGScheduler: Got job 2 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/04/09 23:27:23 INFO DAGScheduler: Final stage: ResultStage 3 (csv at NativeMethodAccessorImpl.java:0)
21/04/09 23:27:23 INFO DAGScheduler: Parents of final stage: List()
21/04/09 23:27:23 INFO DAGScheduler: Missing parents: List()
21/04/09 23:27:23 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[15] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
21/04/09 23:27:23 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 8.8 KB, free 912.0 MB)
21/04/09 23:27:23 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 4.5 KB, free 912.0 MB)
21/04/09 23:27:23 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:52393 (size: 4.5 KB, free: 912.3 MB)
21/04/09 23:27:23 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1161
21/04/09 23:27:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[15] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/04/09 23:27:23 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
21/04/09 23:27:23 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 8346 bytes)
21/04/09 23:27:23 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
21/04/09 23:27:23 INFO FileScanRDD: Reading File path: file:///E:/OneDrive/WUSTL/Math%20Research/test/data-csv/letters1.csv, range: 0-30, partition values: [empty row]
21/04/09 23:27:23 INFO CodeGenerator: Code generated in 5.6555 ms
21/04/09 23:27:23 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1224 bytes result sent to driver
21/04/09 23:27:23 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 49 ms on localhost (executor driver) (1/1)
21/04/09 23:27:23 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
21/04/09 23:27:23 INFO DAGScheduler: ResultStage 3 (csv at NativeMethodAccessorImpl.java:0) finished in 0.056 s
21/04/09 23:27:23 INFO DAGScheduler: Job 2 finished: csv at NativeMethodAccessorImpl.java:0, took 0.059590 s
21/04/09 23:27:23 INFO FileSourceStrategy: Pruning directories with: 
21/04/09 23:27:23 INFO FileSourceStrategy: Post-Scan Filters: 
21/04/09 23:27:23 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
21/04/09 23:27:23 INFO FileSourceScanExec: Pushed Filters: 
21/04/09 23:27:23 INFO CodeGenerator: Code generated in 3.6247 ms
21/04/09 23:27:23 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 286.0 KB, free 911.7 MB)
21/04/09 23:27:23 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 24.2 KB, free 911.6 MB)
21/04/09 23:27:23 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:52393 (size: 24.2 KB, free: 912.2 MB)
21/04/09 23:27:23 INFO SparkContext: Created broadcast 5 from csv at NativeMethodAccessorImpl.java:0
21/04/09 23:27:23 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
21/04/09 23:27:23 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
21/04/09 23:27:23 INFO DAGScheduler: Got job 3 (csv at NativeMethodAccessorImpl.java:0) with 2 output partitions
21/04/09 23:27:23 INFO DAGScheduler: Final stage: ResultStage 4 (csv at NativeMethodAccessorImpl.java:0)
21/04/09 23:27:23 INFO DAGScheduler: Parents of final stage: List()
21/04/09 23:27:23 INFO DAGScheduler: Missing parents: List()
21/04/09 23:27:23 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[20] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
21/04/09 23:27:23 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 15.0 KB, free 911.6 MB)
21/04/09 23:27:23 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 8.6 KB, free 911.6 MB)
21/04/09 23:27:23 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:52393 (size: 8.6 KB, free: 912.2 MB)
21/04/09 23:27:23 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1161
21/04/09 23:27:23 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 4 (MapPartitionsRDD[20] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
21/04/09 23:27:23 INFO TaskSchedulerImpl: Adding task set 4.0 with 2 tasks
21/04/09 23:27:23 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 8346 bytes)
21/04/09 23:27:23 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 5, localhost, executor driver, partition 1, PROCESS_LOCAL, 8346 bytes)
21/04/09 23:27:23 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
21/04/09 23:27:23 INFO Executor: Running task 1.0 in stage 4.0 (TID 5)
21/04/09 23:27:23 INFO FileScanRDD: Reading File path: file:///E:/OneDrive/WUSTL/Math%20Research/test/data-csv/letters1.csv, range: 0-30, partition values: [empty row]
21/04/09 23:27:23 INFO FileScanRDD: Reading File path: file:///E:/OneDrive/WUSTL/Math%20Research/test/data-csv/letters2.csv, range: 0-30, partition values: [empty row]
21/04/09 23:27:23 INFO Executor: Finished task 1.0 in stage 4.0 (TID 5). 1481 bytes result sent to driver
21/04/09 23:27:23 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1481 bytes result sent to driver
21/04/09 23:27:23 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 5) in 23 ms on localhost (executor driver) (1/2)
21/04/09 23:27:23 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 23 ms on localhost (executor driver) (2/2)
21/04/09 23:27:23 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
21/04/09 23:27:23 INFO DAGScheduler: ResultStage 4 (csv at NativeMethodAccessorImpl.java:0) finished in 0.029 s
21/04/09 23:27:23 INFO DAGScheduler: Job 3 finished: csv at NativeMethodAccessorImpl.java:0, took 0.030351 s
21/04/09 23:27:24 INFO HiveMetaStore: 0: get_database: default
21/04/09 23:27:24 INFO audit: ugi=lizha	ip=unknown-ip-addr	cmd=get_database: default	
21/04/09 23:27:24 INFO HiveMetaStore: 0: get_database: default
21/04/09 23:27:24 INFO audit: ugi=lizha	ip=unknown-ip-addr	cmd=get_database: default	
21/04/09 23:27:24 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/04/09 23:27:24 INFO audit: ugi=lizha	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/04/09 23:27:24 INFO SparkContext: Starting job: count at utils.scala:135
21/04/09 23:27:24 INFO DAGScheduler: Registering RDD 24 (count at utils.scala:135)
21/04/09 23:27:24 INFO DAGScheduler: Got job 4 (count at utils.scala:135) with 1 output partitions
21/04/09 23:27:24 INFO DAGScheduler: Final stage: ResultStage 6 (count at utils.scala:135)
21/04/09 23:27:24 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
21/04/09 23:27:24 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 5)
21/04/09 23:27:24 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[24] at count at utils.scala:135), which has no missing parents
21/04/09 23:27:24 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 7.9 KB, free 911.6 MB)
21/04/09 23:27:24 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 4.2 KB, free 911.6 MB)
21/04/09 23:27:24 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:52393 (size: 4.2 KB, free: 912.2 MB)
21/04/09 23:27:24 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1161
21/04/09 23:27:24 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[24] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/04/09 23:27:24 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
21/04/09 23:27:24 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 6, localhost, executor driver, partition 0, PROCESS_LOCAL, 7882 bytes)
21/04/09 23:27:24 INFO Executor: Running task 0.0 in stage 5.0 (TID 6)
21/04/09 23:27:24 INFO Executor: Finished task 0.0 in stage 5.0 (TID 6). 1413 bytes result sent to driver
21/04/09 23:27:24 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 6) in 5 ms on localhost (executor driver) (1/1)
21/04/09 23:27:24 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
21/04/09 23:27:24 INFO DAGScheduler: ShuffleMapStage 5 (count at utils.scala:135) finished in 0.010 s
21/04/09 23:27:24 INFO DAGScheduler: looking for newly runnable stages
21/04/09 23:27:24 INFO DAGScheduler: running: Set()
21/04/09 23:27:24 INFO DAGScheduler: waiting: Set(ResultStage 6)
21/04/09 23:27:24 INFO DAGScheduler: failed: Set()
21/04/09 23:27:24 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[27] at count at utils.scala:135), which has no missing parents
21/04/09 23:27:24 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 7.1 KB, free 911.6 MB)
21/04/09 23:27:24 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 3.8 KB, free 911.6 MB)
21/04/09 23:27:24 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:52393 (size: 3.8 KB, free: 912.2 MB)
21/04/09 23:27:24 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1161
21/04/09 23:27:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[27] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/04/09 23:27:24 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
21/04/09 23:27:24 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 7, localhost, executor driver, partition 0, ANY, 7767 bytes)
21/04/09 23:27:24 INFO Executor: Running task 0.0 in stage 6.0 (TID 7)
21/04/09 23:27:24 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/04/09 23:27:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/04/09 23:27:24 INFO Executor: Finished task 0.0 in stage 6.0 (TID 7). 1646 bytes result sent to driver
21/04/09 23:27:24 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 7) in 3 ms on localhost (executor driver) (1/1)
21/04/09 23:27:24 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
21/04/09 23:27:24 INFO DAGScheduler: ResultStage 6 (count at utils.scala:135) finished in 0.008 s
21/04/09 23:27:24 INFO DAGScheduler: Job 4 finished: count at utils.scala:135, took 0.019937 s
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 82
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 103
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 130
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 146
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 166
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 115
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 77
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 155
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 194
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 190
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 174
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 147
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 120
21/04/09 23:27:24 INFO ContextCleaner: Cleaned shuffle 1
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 211
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 202
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 86
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 124
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 127
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 68
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 162
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 192
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 150
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 129
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 158
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 128
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 176
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 142
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 137
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 196
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 81
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 132
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 169
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 121
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 198
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 101
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 139
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 135
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 110
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 96
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 201
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 111
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 206
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 167
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 99
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 145
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 160
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 185
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 76
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 149
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 88
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 197
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 151
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 177
21/04/09 23:27:24 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:52393 in memory (size: 4.5 KB, free: 912.2 MB)
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 67
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 71
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 126
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 141
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 217
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 119
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 212
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 108
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 95
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 85
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 75
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 83
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 183
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 92
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 205
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 184
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 79
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 114
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 94
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 156
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 106
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 74
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 113
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 208
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 143
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 97
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 189
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 186
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 154
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 72
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 153
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 191
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 180
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 78
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 122
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 172
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 179
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 80
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 102
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 207
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 89
21/04/09 23:27:24 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 127.0.0.1:52393 in memory (size: 3.8 KB, free: 912.2 MB)
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 125
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 182
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 209
21/04/09 23:27:24 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 127.0.0.1:52393 in memory (size: 3.4 KB, free: 912.2 MB)
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 105
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 133
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 148
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 203
21/04/09 23:27:24 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 127.0.0.1:52393 in memory (size: 24.2 KB, free: 912.3 MB)
21/04/09 23:27:24 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:52393 in memory (size: 24.2 KB, free: 912.3 MB)
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 204
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 181
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 163
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 170
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 98
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 200
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 216
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 104
21/04/09 23:27:24 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 127.0.0.1:52393 in memory (size: 4.2 KB, free: 912.3 MB)
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 117
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 70
21/04/09 23:27:24 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:52393 in memory (size: 8.6 KB, free: 912.3 MB)
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 134
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 187
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 214
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 140
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 136
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 152
21/04/09 23:27:24 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 127.0.0.1:52393 in memory (size: 3.8 KB, free: 912.3 MB)
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 178
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 123
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 138
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 159
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 73
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 173
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 188
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 210
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 193
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 157
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 175
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 171
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 218
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 165
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 168
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 93
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 215
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 91
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 199
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 69
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 107
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 109
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 213
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 118
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 100
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 164
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 144
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 90
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 131
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 195
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 112
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 66
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 161
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 87
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 116
21/04/09 23:27:24 INFO ContextCleaner: Cleaned accumulator 84
21/04/09 23:27:24 INFO FileSourceStrategy: Pruning directories with: 
21/04/09 23:27:24 INFO FileSourceStrategy: Post-Scan Filters: 
21/04/09 23:27:24 INFO FileSourceStrategy: Output Data Schema: struct<x: string, y: int>
21/04/09 23:27:24 INFO FileSourceScanExec: Pushed Filters: 
21/04/09 23:27:24 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 286.0 KB, free 912.0 MB)
21/04/09 23:27:24 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 24.2 KB, free 912.0 MB)
21/04/09 23:27:24 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:52393 (size: 24.2 KB, free: 912.3 MB)
21/04/09 23:27:24 INFO SparkContext: Created broadcast 9 from sql at NativeMethodAccessorImpl.java:0
21/04/09 23:27:24 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
21/04/09 23:27:24 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
21/04/09 23:27:24 INFO DAGScheduler: Registering RDD 35 (sql at NativeMethodAccessorImpl.java:0)
21/04/09 23:27:24 INFO DAGScheduler: Got job 5 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/04/09 23:27:24 INFO DAGScheduler: Final stage: ResultStage 8 (sql at NativeMethodAccessorImpl.java:0)
21/04/09 23:27:24 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
21/04/09 23:27:24 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 7)
21/04/09 23:27:24 INFO DAGScheduler: Submitting ShuffleMapStage 7 (MapPartitionsRDD[35] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
21/04/09 23:27:24 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 20.2 KB, free 912.0 MB)
21/04/09 23:27:24 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 10.4 KB, free 912.0 MB)
21/04/09 23:27:24 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:52393 (size: 10.4 KB, free: 912.3 MB)
21/04/09 23:27:24 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1161
21/04/09 23:27:24 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[35] at sql at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
21/04/09 23:27:24 INFO TaskSchedulerImpl: Adding task set 7.0 with 2 tasks
21/04/09 23:27:24 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 8335 bytes)
21/04/09 23:27:24 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 9, localhost, executor driver, partition 1, PROCESS_LOCAL, 8335 bytes)
21/04/09 23:27:24 INFO Executor: Running task 1.0 in stage 7.0 (TID 9)
21/04/09 23:27:24 INFO Executor: Running task 0.0 in stage 7.0 (TID 8)
21/04/09 23:27:24 INFO FileScanRDD: Reading File path: file:///E:/OneDrive/WUSTL/Math%20Research/test/data-csv/letters1.csv, range: 0-30, partition values: [empty row]
21/04/09 23:27:24 INFO FileScanRDD: Reading File path: file:///E:/OneDrive/WUSTL/Math%20Research/test/data-csv/letters2.csv, range: 0-30, partition values: [empty row]
21/04/09 23:27:24 INFO CodeGenerator: Code generated in 5.5989 ms
21/04/09 23:27:24 INFO MemoryStore: Block rdd_30_1 stored as values in memory (estimated size 424.0 B, free 912.0 MB)
21/04/09 23:27:24 INFO BlockManagerInfo: Added rdd_30_1 in memory on 127.0.0.1:52393 (size: 424.0 B, free: 912.3 MB)
21/04/09 23:27:24 INFO MemoryStore: Block rdd_30_0 stored as values in memory (estimated size 424.0 B, free 912.0 MB)
21/04/09 23:27:24 INFO BlockManagerInfo: Added rdd_30_0 in memory on 127.0.0.1:52393 (size: 424.0 B, free: 912.3 MB)
21/04/09 23:27:24 INFO CodeGenerator: Code generated in 3.0486 ms
21/04/09 23:27:24 INFO CodeGenerator: Code generated in 10.6933 ms
21/04/09 23:27:24 INFO Executor: Finished task 1.0 in stage 7.0 (TID 9). 1871 bytes result sent to driver
21/04/09 23:27:24 INFO Executor: Finished task 0.0 in stage 7.0 (TID 8). 1828 bytes result sent to driver
21/04/09 23:27:24 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 9) in 89 ms on localhost (executor driver) (1/2)
21/04/09 23:27:24 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 8) in 89 ms on localhost (executor driver) (2/2)
21/04/09 23:27:24 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
21/04/09 23:27:24 INFO DAGScheduler: ShuffleMapStage 7 (sql at NativeMethodAccessorImpl.java:0) finished in 0.103 s
21/04/09 23:27:24 INFO DAGScheduler: looking for newly runnable stages
21/04/09 23:27:24 INFO DAGScheduler: running: Set()
21/04/09 23:27:24 INFO DAGScheduler: waiting: Set(ResultStage 8)
21/04/09 23:27:24 INFO DAGScheduler: failed: Set()
21/04/09 23:27:24 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[38] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
21/04/09 23:27:24 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 7.1 KB, free 911.9 MB)
21/04/09 23:27:24 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 3.8 KB, free 911.9 MB)
21/04/09 23:27:24 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:52393 (size: 3.8 KB, free: 912.3 MB)
21/04/09 23:27:24 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1161
21/04/09 23:27:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[38] at sql at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/04/09 23:27:24 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
21/04/09 23:27:24 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 10, localhost, executor driver, partition 0, ANY, 7767 bytes)
21/04/09 23:27:24 INFO Executor: Running task 0.0 in stage 8.0 (TID 10)
21/04/09 23:27:24 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks including 2 local blocks and 0 remote blocks
21/04/09 23:27:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/04/09 23:27:24 INFO Executor: Finished task 0.0 in stage 8.0 (TID 10). 1653 bytes result sent to driver
21/04/09 23:27:24 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 10) in 5 ms on localhost (executor driver) (1/1)
21/04/09 23:27:24 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
21/04/09 23:27:24 INFO DAGScheduler: ResultStage 8 (sql at NativeMethodAccessorImpl.java:0) finished in 0.008 s
21/04/09 23:27:24 INFO DAGScheduler: Job 5 finished: sql at NativeMethodAccessorImpl.java:0, took 0.115192 s
21/04/09 23:27:24 INFO CodeGenerator: Code generated in 5.2768 ms
21/04/09 23:27:24 INFO SparkContext: Starting job: collect at utils.scala:135
21/04/09 23:27:24 INFO DAGScheduler: Registering RDD 43 (collect at utils.scala:135)
21/04/09 23:27:24 INFO DAGScheduler: Got job 6 (collect at utils.scala:135) with 1 output partitions
21/04/09 23:27:24 INFO DAGScheduler: Final stage: ResultStage 10 (collect at utils.scala:135)
21/04/09 23:27:24 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)
21/04/09 23:27:24 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)
21/04/09 23:27:24 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[43] at collect at utils.scala:135), which has no missing parents
21/04/09 23:27:24 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 20.2 KB, free 911.9 MB)
21/04/09 23:27:24 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 10.5 KB, free 911.9 MB)
21/04/09 23:27:24 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:52393 (size: 10.5 KB, free: 912.2 MB)
21/04/09 23:27:24 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1161
21/04/09 23:27:24 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[43] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0, 1))
21/04/09 23:27:24 INFO TaskSchedulerImpl: Adding task set 9.0 with 2 tasks
21/04/09 23:27:24 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 11, localhost, executor driver, partition 0, PROCESS_LOCAL, 8335 bytes)
21/04/09 23:27:24 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 12, localhost, executor driver, partition 1, PROCESS_LOCAL, 8335 bytes)
21/04/09 23:27:24 INFO Executor: Running task 0.0 in stage 9.0 (TID 11)
21/04/09 23:27:24 INFO Executor: Running task 1.0 in stage 9.0 (TID 12)
21/04/09 23:27:24 INFO BlockManager: Found block rdd_30_1 locally
21/04/09 23:27:24 INFO BlockManager: Found block rdd_30_0 locally
21/04/09 23:27:24 INFO Executor: Finished task 1.0 in stage 9.0 (TID 12). 1785 bytes result sent to driver
21/04/09 23:27:24 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 12) in 9 ms on localhost (executor driver) (1/2)
21/04/09 23:27:24 INFO Executor: Finished task 0.0 in stage 9.0 (TID 11). 1785 bytes result sent to driver
21/04/09 23:27:24 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 11) in 12 ms on localhost (executor driver) (2/2)
21/04/09 23:27:24 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
21/04/09 23:27:24 INFO DAGScheduler: ShuffleMapStage 9 (collect at utils.scala:135) finished in 0.021 s
21/04/09 23:27:24 INFO DAGScheduler: looking for newly runnable stages
21/04/09 23:27:24 INFO DAGScheduler: running: Set()
21/04/09 23:27:24 INFO DAGScheduler: waiting: Set(ResultStage 10)
21/04/09 23:27:24 INFO DAGScheduler: failed: Set()
21/04/09 23:27:24 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[46] at collect at utils.scala:135), which has no missing parents
21/04/09 23:27:24 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 7.1 KB, free 911.9 MB)
21/04/09 23:27:24 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 3.8 KB, free 911.9 MB)
21/04/09 23:27:24 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 127.0.0.1:52393 (size: 3.8 KB, free: 912.2 MB)
21/04/09 23:27:24 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1161
21/04/09 23:27:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[46] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/04/09 23:27:24 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
21/04/09 23:27:24 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 13, localhost, executor driver, partition 0, ANY, 7767 bytes)
21/04/09 23:27:24 INFO Executor: Running task 0.0 in stage 10.0 (TID 13)
21/04/09 23:27:24 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks including 2 local blocks and 0 remote blocks
21/04/09 23:27:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/04/09 23:27:24 INFO Executor: Finished task 0.0 in stage 10.0 (TID 13). 1696 bytes result sent to driver
21/04/09 23:27:24 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 13) in 7 ms on localhost (executor driver) (1/1)
21/04/09 23:27:24 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
21/04/09 23:27:24 INFO DAGScheduler: ResultStage 10 (collect at utils.scala:135) finished in 0.012 s
21/04/09 23:27:24 INFO DAGScheduler: Job 6 finished: collect at utils.scala:135, took 0.036765 s
21/04/09 23:27:24 INFO CodeGenerator: Code generated in 10.6568 ms
21/04/09 23:27:24 INFO CodeGenerator: Code generated in 6.8674 ms
21/04/09 23:27:24 INFO SparkContext: Starting job: count at utils.scala:135
21/04/09 23:27:24 INFO DAGScheduler: Registering RDD 51 (count at utils.scala:135)
21/04/09 23:27:24 INFO DAGScheduler: Got job 7 (count at utils.scala:135) with 1 output partitions
21/04/09 23:27:24 INFO DAGScheduler: Final stage: ResultStage 12 (count at utils.scala:135)
21/04/09 23:27:24 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 11)
21/04/09 23:27:24 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 11)
21/04/09 23:27:24 INFO DAGScheduler: Submitting ShuffleMapStage 11 (MapPartitionsRDD[51] at count at utils.scala:135), which has no missing parents
21/04/09 23:27:24 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 19.6 KB, free 911.9 MB)
21/04/09 23:27:24 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 10.2 KB, free 911.9 MB)
21/04/09 23:27:24 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 127.0.0.1:52393 (size: 10.2 KB, free: 912.2 MB)
21/04/09 23:27:24 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1161
21/04/09 23:27:24 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[51] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0, 1))
21/04/09 23:27:24 INFO TaskSchedulerImpl: Adding task set 11.0 with 2 tasks
21/04/09 23:27:24 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 14, localhost, executor driver, partition 0, PROCESS_LOCAL, 8335 bytes)
21/04/09 23:27:24 INFO TaskSetManager: Starting task 1.0 in stage 11.0 (TID 15, localhost, executor driver, partition 1, PROCESS_LOCAL, 8335 bytes)
21/04/09 23:27:24 INFO Executor: Running task 1.0 in stage 11.0 (TID 15)
21/04/09 23:27:24 INFO Executor: Running task 0.0 in stage 11.0 (TID 14)
21/04/09 23:27:24 INFO BlockManager: Found block rdd_30_1 locally
21/04/09 23:27:24 INFO BlockManager: Found block rdd_30_0 locally
21/04/09 23:27:24 INFO Executor: Finished task 1.0 in stage 11.0 (TID 15). 1828 bytes result sent to driver
21/04/09 23:27:24 INFO Executor: Finished task 0.0 in stage 11.0 (TID 14). 1785 bytes result sent to driver
21/04/09 23:27:24 INFO TaskSetManager: Finished task 1.0 in stage 11.0 (TID 15) in 11 ms on localhost (executor driver) (1/2)
21/04/09 23:27:24 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 14) in 12 ms on localhost (executor driver) (2/2)
21/04/09 23:27:24 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
21/04/09 23:27:24 INFO DAGScheduler: ShuffleMapStage 11 (count at utils.scala:135) finished in 0.020 s
21/04/09 23:27:24 INFO DAGScheduler: looking for newly runnable stages
21/04/09 23:27:24 INFO DAGScheduler: running: Set()
21/04/09 23:27:24 INFO DAGScheduler: waiting: Set(ResultStage 12)
21/04/09 23:27:24 INFO DAGScheduler: failed: Set()
21/04/09 23:27:24 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[54] at count at utils.scala:135), which has no missing parents
21/04/09 23:27:24 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 9.1 KB, free 911.9 MB)
21/04/09 23:27:24 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 4.1 KB, free 911.9 MB)
21/04/09 23:27:24 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 127.0.0.1:52393 (size: 4.1 KB, free: 912.2 MB)
21/04/09 23:27:24 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1161
21/04/09 23:27:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[54] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/04/09 23:27:24 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
21/04/09 23:27:24 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 16, localhost, executor driver, partition 0, ANY, 7767 bytes)
21/04/09 23:27:24 INFO Executor: Running task 0.0 in stage 12.0 (TID 16)
21/04/09 23:27:24 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks including 2 local blocks and 0 remote blocks
21/04/09 23:27:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/04/09 23:27:24 INFO Executor: Finished task 0.0 in stage 12.0 (TID 16). 2055 bytes result sent to driver
21/04/09 23:27:24 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 16) in 7 ms on localhost (executor driver) (1/1)
21/04/09 23:27:24 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
21/04/09 23:27:24 INFO DAGScheduler: ResultStage 12 (count at utils.scala:135) finished in 0.013 s
21/04/09 23:27:24 INFO DAGScheduler: Job 7 finished: count at utils.scala:135, took 0.035960 s
21/04/09 23:27:24 INFO CodeGenerator: Code generated in 6.3844 ms
21/04/09 23:27:24 INFO CodeGenerator: Code generated in 5.8519 ms
21/04/09 23:27:24 INFO SparkContext: Starting job: collect at utils.scala:135
21/04/09 23:27:24 INFO DAGScheduler: Got job 8 (collect at utils.scala:135) with 1 output partitions
21/04/09 23:27:24 INFO DAGScheduler: Final stage: ResultStage 13 (collect at utils.scala:135)
21/04/09 23:27:24 INFO DAGScheduler: Parents of final stage: List()
21/04/09 23:27:24 INFO DAGScheduler: Missing parents: List()
21/04/09 23:27:24 INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[58] at collect at utils.scala:135), which has no missing parents
21/04/09 23:27:24 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 6.1 KB, free 911.9 MB)
21/04/09 23:27:24 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 3.2 KB, free 911.9 MB)
21/04/09 23:27:24 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 127.0.0.1:52393 (size: 3.2 KB, free: 912.2 MB)
21/04/09 23:27:24 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1161
21/04/09 23:27:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[58] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/04/09 23:27:24 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
21/04/09 23:27:24 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 17, localhost, executor driver, partition 0, PROCESS_LOCAL, 8080 bytes)
21/04/09 23:27:24 INFO Executor: Running task 0.0 in stage 13.0 (TID 17)
21/04/09 23:27:24 INFO CodeGenerator: Code generated in 4.1177 ms
21/04/09 23:27:24 INFO Executor: Finished task 0.0 in stage 13.0 (TID 17). 1200 bytes result sent to driver
21/04/09 23:27:24 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 17) in 15 ms on localhost (executor driver) (1/1)
21/04/09 23:27:24 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
21/04/09 23:27:24 INFO DAGScheduler: ResultStage 13 (collect at utils.scala:135) finished in 0.018 s
21/04/09 23:27:24 INFO DAGScheduler: Job 8 finished: collect at utils.scala:135, took 0.020269 s
21/04/09 23:27:24 INFO SparkContext: Starting job: count at utils.scala:135
21/04/09 23:27:24 INFO DAGScheduler: Registering RDD 61 (count at utils.scala:135)
21/04/09 23:27:24 INFO DAGScheduler: Got job 9 (count at utils.scala:135) with 1 output partitions
21/04/09 23:27:24 INFO DAGScheduler: Final stage: ResultStage 15 (count at utils.scala:135)
21/04/09 23:27:24 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 14)
21/04/09 23:27:24 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 14)
21/04/09 23:27:24 INFO DAGScheduler: Submitting ShuffleMapStage 14 (MapPartitionsRDD[61] at count at utils.scala:135), which has no missing parents
21/04/09 23:27:24 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 8.4 KB, free 911.8 MB)
21/04/09 23:27:24 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 4.5 KB, free 911.8 MB)
21/04/09 23:27:24 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 127.0.0.1:52393 (size: 4.5 KB, free: 912.2 MB)
21/04/09 23:27:24 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1161
21/04/09 23:27:24 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 14 (MapPartitionsRDD[61] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/04/09 23:27:24 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
21/04/09 23:27:24 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 18, localhost, executor driver, partition 0, PROCESS_LOCAL, 8069 bytes)
21/04/09 23:27:24 INFO Executor: Running task 0.0 in stage 14.0 (TID 18)
21/04/09 23:27:24 INFO Executor: Finished task 0.0 in stage 14.0 (TID 18). 1413 bytes result sent to driver
21/04/09 23:27:24 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 18) in 9 ms on localhost (executor driver) (1/1)
21/04/09 23:27:24 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
21/04/09 23:27:24 INFO DAGScheduler: ShuffleMapStage 14 (count at utils.scala:135) finished in 0.015 s
21/04/09 23:27:24 INFO DAGScheduler: looking for newly runnable stages
21/04/09 23:27:24 INFO DAGScheduler: running: Set()
21/04/09 23:27:24 INFO DAGScheduler: waiting: Set(ResultStage 15)
21/04/09 23:27:24 INFO DAGScheduler: failed: Set()
21/04/09 23:27:24 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[64] at count at utils.scala:135), which has no missing parents
21/04/09 23:27:24 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 7.1 KB, free 911.8 MB)
21/04/09 23:27:24 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 3.8 KB, free 911.8 MB)
21/04/09 23:27:24 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 127.0.0.1:52393 (size: 3.8 KB, free: 912.2 MB)
21/04/09 23:27:24 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1161
21/04/09 23:27:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[64] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/04/09 23:27:24 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks
21/04/09 23:27:24 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 19, localhost, executor driver, partition 0, ANY, 7767 bytes)
21/04/09 23:27:24 INFO Executor: Running task 0.0 in stage 15.0 (TID 19)
21/04/09 23:27:24 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/04/09 23:27:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/04/09 23:27:24 INFO Executor: Finished task 0.0 in stage 15.0 (TID 19). 1696 bytes result sent to driver
21/04/09 23:27:24 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 19) in 6 ms on localhost (executor driver) (1/1)
21/04/09 23:27:24 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
21/04/09 23:27:24 INFO DAGScheduler: ResultStage 15 (count at utils.scala:135) finished in 0.012 s
21/04/09 23:27:24 INFO DAGScheduler: Job 9 finished: count at utils.scala:135, took 0.029576 s
21/04/09 23:27:24 INFO CodeGenerator: Code generated in 4.6906 ms
21/04/09 23:27:24 INFO SparkContext: Starting job: collect at utils.scala:135
21/04/09 23:27:24 INFO DAGScheduler: Got job 10 (collect at utils.scala:135) with 1 output partitions
21/04/09 23:27:24 INFO DAGScheduler: Final stage: ResultStage 16 (collect at utils.scala:135)
21/04/09 23:27:24 INFO DAGScheduler: Parents of final stage: List()
21/04/09 23:27:24 INFO DAGScheduler: Missing parents: List()
21/04/09 23:27:24 INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[69] at collect at utils.scala:135), which has no missing parents
21/04/09 23:27:25 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 16.6 KB, free 911.8 MB)
21/04/09 23:27:25 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 9.1 KB, free 911.8 MB)
21/04/09 23:27:25 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 127.0.0.1:52393 (size: 9.1 KB, free: 912.2 MB)
21/04/09 23:27:25 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1161
21/04/09 23:27:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[69] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/04/09 23:27:25 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks
21/04/09 23:27:25 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 20, localhost, executor driver, partition 0, PROCESS_LOCAL, 8346 bytes)
21/04/09 23:27:25 INFO Executor: Running task 0.0 in stage 16.0 (TID 20)
21/04/09 23:27:25 INFO BlockManager: Found block rdd_30_0 locally
21/04/09 23:27:25 INFO CodeGenerator: Code generated in 10.4992 ms
21/04/09 23:27:25 INFO Executor: Finished task 0.0 in stage 16.0 (TID 20). 1432 bytes result sent to driver
21/04/09 23:27:25 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 20) in 21 ms on localhost (executor driver) (1/1)
21/04/09 23:27:25 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
21/04/09 23:27:25 INFO DAGScheduler: ResultStage 16 (collect at utils.scala:135) finished in 0.027 s
21/04/09 23:27:25 INFO DAGScheduler: Job 10 finished: collect at utils.scala:135, took 0.027927 s
21/04/09 23:27:25 INFO SparkContext: Starting job: collect at utils.scala:135
21/04/09 23:27:25 INFO DAGScheduler: Got job 11 (collect at utils.scala:135) with 1 output partitions
21/04/09 23:27:25 INFO DAGScheduler: Final stage: ResultStage 17 (collect at utils.scala:135)
21/04/09 23:27:25 INFO DAGScheduler: Parents of final stage: List()
21/04/09 23:27:25 INFO DAGScheduler: Missing parents: List()
21/04/09 23:27:25 INFO DAGScheduler: Submitting ResultStage 17 (MapPartitionsRDD[69] at collect at utils.scala:135), which has no missing parents
21/04/09 23:27:25 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 16.6 KB, free 911.8 MB)
21/04/09 23:27:25 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 9.1 KB, free 911.8 MB)
21/04/09 23:27:25 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 127.0.0.1:52393 (size: 9.1 KB, free: 912.2 MB)
21/04/09 23:27:25 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1161
21/04/09 23:27:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 17 (MapPartitionsRDD[69] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(1))
21/04/09 23:27:25 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks
21/04/09 23:27:25 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 21, localhost, executor driver, partition 1, PROCESS_LOCAL, 8346 bytes)
21/04/09 23:27:25 INFO Executor: Running task 0.0 in stage 17.0 (TID 21)
21/04/09 23:27:25 INFO BlockManager: Found block rdd_30_1 locally
21/04/09 23:27:25 INFO Executor: Finished task 0.0 in stage 17.0 (TID 21). 1346 bytes result sent to driver
21/04/09 23:27:25 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 21) in 3 ms on localhost (executor driver) (1/1)
21/04/09 23:27:25 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
21/04/09 23:27:25 INFO DAGScheduler: ResultStage 17 (collect at utils.scala:135) finished in 0.007 s
21/04/09 23:27:25 INFO DAGScheduler: Job 11 finished: collect at utils.scala:135, took 0.008872 s
21/04/09 23:27:25 INFO CodeGenerator: Code generated in 9.7282 ms
21/04/09 23:27:25 INFO CodeGenerator: Code generated in 3.7775 ms
21/04/09 23:27:25 INFO SparkContext: Starting job: count at utils.scala:135
21/04/09 23:27:25 INFO DAGScheduler: Registering RDD 74 (count at utils.scala:135)
21/04/09 23:27:25 INFO DAGScheduler: Got job 12 (count at utils.scala:135) with 1 output partitions
21/04/09 23:27:25 INFO DAGScheduler: Final stage: ResultStage 19 (count at utils.scala:135)
21/04/09 23:27:25 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 18)
21/04/09 23:27:25 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 18)
21/04/09 23:27:25 INFO DAGScheduler: Submitting ShuffleMapStage 18 (MapPartitionsRDD[74] at count at utils.scala:135), which has no missing parents
21/04/09 23:27:25 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 19.1 KB, free 911.8 MB)
21/04/09 23:27:25 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 10.0 KB, free 911.8 MB)
21/04/09 23:27:25 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 127.0.0.1:52393 (size: 10.0 KB, free: 912.2 MB)
21/04/09 23:27:25 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1161
21/04/09 23:27:25 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 18 (MapPartitionsRDD[74] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0, 1))
21/04/09 23:27:25 INFO TaskSchedulerImpl: Adding task set 18.0 with 2 tasks
21/04/09 23:27:25 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 22, localhost, executor driver, partition 0, PROCESS_LOCAL, 8335 bytes)
21/04/09 23:27:25 INFO TaskSetManager: Starting task 1.0 in stage 18.0 (TID 23, localhost, executor driver, partition 1, PROCESS_LOCAL, 8335 bytes)
21/04/09 23:27:25 INFO Executor: Running task 0.0 in stage 18.0 (TID 22)
21/04/09 23:27:25 INFO Executor: Running task 1.0 in stage 18.0 (TID 23)
21/04/09 23:27:25 INFO BlockManager: Found block rdd_30_1 locally
21/04/09 23:27:25 INFO BlockManager: Found block rdd_30_0 locally
21/04/09 23:27:25 INFO Executor: Finished task 1.0 in stage 18.0 (TID 23). 1627 bytes result sent to driver
21/04/09 23:27:25 INFO TaskSetManager: Finished task 1.0 in stage 18.0 (TID 23) in 7 ms on localhost (executor driver) (1/2)
21/04/09 23:27:25 INFO Executor: Finished task 0.0 in stage 18.0 (TID 22). 1670 bytes result sent to driver
21/04/09 23:27:25 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 22) in 7 ms on localhost (executor driver) (2/2)
21/04/09 23:27:25 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
21/04/09 23:27:25 INFO DAGScheduler: ShuffleMapStage 18 (count at utils.scala:135) finished in 0.011 s
21/04/09 23:27:25 INFO DAGScheduler: looking for newly runnable stages
21/04/09 23:27:25 INFO DAGScheduler: running: Set()
21/04/09 23:27:25 INFO DAGScheduler: waiting: Set(ResultStage 19)
21/04/09 23:27:25 INFO DAGScheduler: failed: Set()
21/04/09 23:27:25 INFO DAGScheduler: Submitting ResultStage 19 (MapPartitionsRDD[77] at count at utils.scala:135), which has no missing parents
21/04/09 23:27:25 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 8.6 KB, free 911.7 MB)
21/04/09 23:27:25 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 4.1 KB, free 911.7 MB)
21/04/09 23:27:25 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 127.0.0.1:52393 (size: 4.1 KB, free: 912.2 MB)
21/04/09 23:27:25 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1161
21/04/09 23:27:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[77] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/04/09 23:27:25 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks
21/04/09 23:27:25 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 24, localhost, executor driver, partition 0, ANY, 7767 bytes)
21/04/09 23:27:25 INFO Executor: Running task 0.0 in stage 19.0 (TID 24)
21/04/09 23:27:25 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks including 2 local blocks and 0 remote blocks
21/04/09 23:27:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/04/09 23:27:25 INFO Executor: Finished task 0.0 in stage 19.0 (TID 24). 1854 bytes result sent to driver
21/04/09 23:27:25 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 24) in 5 ms on localhost (executor driver) (1/1)
21/04/09 23:27:25 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
21/04/09 23:27:25 INFO DAGScheduler: ResultStage 19 (count at utils.scala:135) finished in 0.009 s
21/04/09 23:27:25 INFO DAGScheduler: Job 12 finished: count at utils.scala:135, took 0.022337 s
21/04/09 23:27:25 INFO HiveMetaStore: 0: get_database: default
21/04/09 23:27:25 INFO audit: ugi=lizha	ip=unknown-ip-addr	cmd=get_database: default	
21/04/09 23:27:25 INFO HiveMetaStore: 0: get_database: default
21/04/09 23:27:25 INFO audit: ugi=lizha	ip=unknown-ip-addr	cmd=get_database: default	
21/04/09 23:27:25 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/04/09 23:27:25 INFO audit: ugi=lizha	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/04/09 23:27:25 INFO CodeGenerator: Code generated in 3.5623 ms
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 380
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 403
21/04/09 23:27:25 INFO ContextCleaner: Cleaned shuffle 3
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 292
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 262
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 442
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 627
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 247
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 544
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 565
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 553
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 245
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 592
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 340
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 316
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 582
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 415
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 426
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 264
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 603
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 330
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 439
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 410
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 501
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 411
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 536
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 441
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 625
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 631
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 440
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 456
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 527
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 278
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 596
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 574
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 270
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 365
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 498
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 303
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 434
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 381
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 285
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 282
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 508
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 537
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 374
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 309
21/04/09 23:27:25 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 127.0.0.1:52393 in memory (size: 3.8 KB, free: 912.2 MB)
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 353
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 331
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 522
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 638
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 371
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 268
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 438
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 319
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 496
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 640
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 433
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 593
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 222
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 349
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 637
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 465
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 629
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 224
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 254
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 601
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 554
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 607
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 223
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 315
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 317
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 531
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 450
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 630
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 451
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 329
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 460
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 226
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 243
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 389
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 532
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 326
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 377
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 569
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 578
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 484
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 613
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 370
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 609
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 483
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 492
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 611
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 257
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 359
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 384
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 510
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 350
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 490
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 229
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 571
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 398
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 515
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 321
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 432
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 448
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 583
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 276
21/04/09 23:27:25 INFO ContextCleaner: Cleaned shuffle 2
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 473
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 275
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 573
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 560
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 235
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 562
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 344
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 242
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 472
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 293
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 478
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 485
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 628
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 480
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 520
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 360
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 402
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 258
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 444
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 521
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 361
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 295
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 357
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 586
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 459
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 228
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 256
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 604
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 624
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 306
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 280
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 248
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 470
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 556
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 379
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 523
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 506
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 325
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 394
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 341
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 543
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 328
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 621
21/04/09 23:27:25 INFO ContextCleaner: Cleaned shuffle 4
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 414
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 345
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 528
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 231
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 524
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 585
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 307
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 336
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 449
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 615
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 413
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 406
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 372
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 267
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 249
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 291
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 265
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 589
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 346
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 395
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 333
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 509
21/04/09 23:27:25 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 127.0.0.1:52393 in memory (size: 4.1 KB, free: 912.2 MB)
21/04/09 23:27:25 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 127.0.0.1:52393 in memory (size: 3.2 KB, free: 912.2 MB)
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 540
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 409
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 461
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 474
21/04/09 23:27:25 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 127.0.0.1:52393 in memory (size: 3.8 KB, free: 912.2 MB)
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 271
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 232
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 301
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 464
21/04/09 23:27:25 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 127.0.0.1:52393 in memory (size: 10.4 KB, free: 912.2 MB)
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 575
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 453
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 471
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 458
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 516
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 550
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 427
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 274
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 499
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 310
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 488
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 616
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 514
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 567
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 412
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 311
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 337
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 580
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 632
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 296
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 391
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 595
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 382
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 487
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 590
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 479
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 354
21/04/09 23:27:25 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 127.0.0.1:52393 in memory (size: 4.5 KB, free: 912.2 MB)
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 502
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 266
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 462
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 495
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 602
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 385
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 539
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 534
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 362
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 425
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 435
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 351
21/04/09 23:27:25 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 127.0.0.1:52393 in memory (size: 3.8 KB, free: 912.2 MB)
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 283
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 561
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 491
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 642
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 263
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 390
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 599
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 383
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 513
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 619
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 614
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 393
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 300
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 476
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 342
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 428
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 597
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 279
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 367
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 635
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 548
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 253
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 533
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 541
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 608
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 547
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 334
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 420
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 416
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 363
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 230
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 467
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 397
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 579
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 386
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 605
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 418
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 287
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 639
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 549
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 431
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 392
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 641
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 343
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 308
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 529
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 387
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 373
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 260
21/04/09 23:27:25 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 127.0.0.1:52393 in memory (size: 10.0 KB, free: 912.2 MB)
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 545
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 475
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 618
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 512
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 298
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 469
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 620
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 338
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 244
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 566
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 294
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 400
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 269
21/04/09 23:27:25 INFO SparkContext: Starting job: count at utils.scala:135
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 419
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 378
21/04/09 23:27:25 INFO DAGScheduler: Registering RDD 81 (count at utils.scala:135)
21/04/09 23:27:25 INFO DAGScheduler: Got job 13 (count at utils.scala:135) with 1 output partitions
21/04/09 23:27:25 INFO DAGScheduler: Final stage: ResultStage 21 (count at utils.scala:135)
21/04/09 23:27:25 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 20)
21/04/09 23:27:25 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 20)
21/04/09 23:27:25 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 127.0.0.1:52393 in memory (size: 9.1 KB, free: 912.2 MB)
21/04/09 23:27:25 INFO DAGScheduler: Submitting ShuffleMapStage 20 (MapPartitionsRDD[81] at count at utils.scala:135), which has no missing parents
21/04/09 23:27:25 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 7.9 KB, free 911.9 MB)
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 320
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 519
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 454
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 405
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 299
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 355
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 364
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 251
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 535
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 318
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 376
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 557
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 399
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 446
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 500
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 339
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 288
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 447
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 332
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 587
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 408
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 452
21/04/09 23:27:25 INFO ContextCleaner: Cleaned shuffle 5
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 468
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 423
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 322
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 486
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 542
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 538
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 305
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 445
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 324
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 600
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 221
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 401
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 610
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 477
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 563
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 617
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 634
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 417
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 250
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 220
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 493
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 225
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 352
21/04/09 23:27:25 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 4.2 KB, free 911.9 MB)
21/04/09 23:27:25 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 127.0.0.1:52393 (size: 4.2 KB, free: 912.2 MB)
21/04/09 23:27:25 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 127.0.0.1:52393 in memory (size: 9.1 KB, free: 912.2 MB)
21/04/09 23:27:25 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1161
21/04/09 23:27:25 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 20 (MapPartitionsRDD[81] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/04/09 23:27:25 INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 241
21/04/09 23:27:25 INFO ContextCleaner: Cleaned shuffle 6
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 313
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 429
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 457
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 396
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 588
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 272
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 314
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 633
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 505
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 369
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 507
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 482
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 358
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 598
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 327
21/04/09 23:27:25 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 25, localhost, executor driver, partition 0, PROCESS_LOCAL, 8017 bytes)
21/04/09 23:27:25 INFO Executor: Running task 0.0 in stage 20.0 (TID 25)
21/04/09 23:27:25 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 127.0.0.1:52393 in memory (size: 10.2 KB, free: 912.3 MB)
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 302
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 246
21/04/09 23:27:25 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 127.0.0.1:52393 in memory (size: 10.5 KB, free: 912.3 MB)
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 568
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 255
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 551
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 277
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 546
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 636
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 558
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 286
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 404
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 281
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 335
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 430
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 577
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 289
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 572
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 234
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 525
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 312
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 623
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 518
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 466
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 422
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 489
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 233
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 348
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 407
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 259
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 530
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 388
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 297
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 497
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 626
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 356
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 552
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 347
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 594
21/04/09 23:27:25 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 127.0.0.1:52393 in memory (size: 4.1 KB, free: 912.3 MB)
21/04/09 23:27:25 INFO Executor: Finished task 0.0 in stage 20.0 (TID 25). 1456 bytes result sent to driver
21/04/09 23:27:25 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 25) in 5 ms on localhost (executor driver) (1/1)
21/04/09 23:27:25 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 570
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 261
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 290
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 421
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 555
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 436
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 559
21/04/09 23:27:25 INFO DAGScheduler: ShuffleMapStage 20 (count at utils.scala:135) finished in 0.009 s
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 227
21/04/09 23:27:25 INFO DAGScheduler: looking for newly runnable stages
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 368
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 437
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 273
21/04/09 23:27:25 INFO DAGScheduler: running: Set()
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 366
21/04/09 23:27:25 INFO DAGScheduler: waiting: Set(ResultStage 21)
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 463
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 517
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 443
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 564
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 576
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 455
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 584
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 252
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 606
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 504
21/04/09 23:27:25 INFO DAGScheduler: failed: Set()
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 526
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 612
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 622
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 375
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 503
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 284
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 424
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 494
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 304
21/04/09 23:27:25 INFO DAGScheduler: Submitting ResultStage 21 (MapPartitionsRDD[84] at count at utils.scala:135), which has no missing parents
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 591
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 323
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 481
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 511
21/04/09 23:27:25 INFO ContextCleaner: Cleaned accumulator 581
21/04/09 23:27:25 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 7.1 KB, free 912.0 MB)
21/04/09 23:27:25 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.0 MB)
21/04/09 23:27:25 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 127.0.0.1:52393 (size: 3.8 KB, free: 912.3 MB)
21/04/09 23:27:25 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1161
21/04/09 23:27:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 21 (MapPartitionsRDD[84] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/04/09 23:27:25 INFO TaskSchedulerImpl: Adding task set 21.0 with 1 tasks
21/04/09 23:27:25 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 26, localhost, executor driver, partition 0, ANY, 7767 bytes)
21/04/09 23:27:25 INFO Executor: Running task 0.0 in stage 21.0 (TID 26)
21/04/09 23:27:25 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/04/09 23:27:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/04/09 23:27:25 INFO Executor: Finished task 0.0 in stage 21.0 (TID 26). 1653 bytes result sent to driver
21/04/09 23:27:25 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 26) in 3 ms on localhost (executor driver) (1/1)
21/04/09 23:27:25 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
21/04/09 23:27:25 INFO DAGScheduler: ResultStage 21 (count at utils.scala:135) finished in 0.006 s
21/04/09 23:27:25 INFO DAGScheduler: Job 13 finished: count at utils.scala:135, took 0.017299 s
21/04/09 23:40:20 INFO HiveMetaStore: 0: get_database: default
21/04/09 23:40:20 INFO audit: ugi=lizha	ip=unknown-ip-addr	cmd=get_database: default	
21/04/09 23:40:20 INFO HiveMetaStore: 0: get_database: default
21/04/09 23:40:20 INFO audit: ugi=lizha	ip=unknown-ip-addr	cmd=get_database: default	
21/04/09 23:40:20 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/04/09 23:40:20 INFO audit: ugi=lizha	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/04/09 23:40:20 INFO CodeGenerator: Code generated in 3.8448 ms
21/04/09 23:40:20 INFO SparkContext: Starting job: collect at utils.scala:61
21/04/09 23:40:20 INFO DAGScheduler: Got job 14 (collect at utils.scala:61) with 1 output partitions
21/04/09 23:40:20 INFO DAGScheduler: Final stage: ResultStage 22 (collect at utils.scala:61)
21/04/09 23:40:20 INFO DAGScheduler: Parents of final stage: List()
21/04/09 23:40:20 INFO DAGScheduler: Missing parents: List()
21/04/09 23:40:20 INFO DAGScheduler: Submitting ResultStage 22 (MapPartitionsRDD[89] at map at utils.scala:54), which has no missing parents
21/04/09 23:40:20 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 6.0 KB, free 912.0 MB)
21/04/09 23:40:20 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 3.4 KB, free 912.0 MB)
21/04/09 23:40:20 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 127.0.0.1:52393 (size: 3.4 KB, free: 912.3 MB)
21/04/09 23:40:20 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1161
21/04/09 23:40:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 22 (MapPartitionsRDD[89] at map at utils.scala:54) (first 15 tasks are for partitions Vector(0))
21/04/09 23:40:20 INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks
21/04/09 23:40:20 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 27, localhost, executor driver, partition 0, PROCESS_LOCAL, 8092 bytes)
21/04/09 23:40:20 INFO Executor: Running task 0.0 in stage 22.0 (TID 27)
21/04/09 23:40:20 INFO Executor: Finished task 0.0 in stage 22.0 (TID 27). 931 bytes result sent to driver
21/04/09 23:40:20 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 27) in 4 ms on localhost (executor driver) (1/1)
21/04/09 23:40:20 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
21/04/09 23:40:20 INFO DAGScheduler: ResultStage 22 (collect at utils.scala:61) finished in 0.008 s
21/04/09 23:40:20 INFO DAGScheduler: Job 14 finished: collect at utils.scala:61, took 0.008953 s
21/04/09 23:40:20 INFO FileSourceStrategy: Pruning directories with: 
21/04/09 23:40:20 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#212, None)) > 0)
21/04/09 23:40:20 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
21/04/09 23:40:20 INFO FileSourceScanExec: Pushed Filters: 
21/04/09 23:40:20 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 286.0 KB, free 911.7 MB)
21/04/09 23:40:20 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 24.2 KB, free 911.6 MB)
21/04/09 23:40:20 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 127.0.0.1:52393 (size: 24.2 KB, free: 912.2 MB)
21/04/09 23:40:20 INFO SparkContext: Created broadcast 26 from csv at NativeMethodAccessorImpl.java:0
21/04/09 23:40:20 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
21/04/09 23:40:20 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
21/04/09 23:40:20 INFO DAGScheduler: Got job 15 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/04/09 23:40:20 INFO DAGScheduler: Final stage: ResultStage 23 (csv at NativeMethodAccessorImpl.java:0)
21/04/09 23:40:20 INFO DAGScheduler: Parents of final stage: List()
21/04/09 23:40:20 INFO DAGScheduler: Missing parents: List()
21/04/09 23:40:20 INFO DAGScheduler: Submitting ResultStage 23 (MapPartitionsRDD[93] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
21/04/09 23:40:20 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 8.8 KB, free 911.6 MB)
21/04/09 23:40:20 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 4.5 KB, free 911.6 MB)
21/04/09 23:40:20 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 127.0.0.1:52393 (size: 4.5 KB, free: 912.2 MB)
21/04/09 23:40:20 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1161
21/04/09 23:40:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 23 (MapPartitionsRDD[93] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/04/09 23:40:20 INFO TaskSchedulerImpl: Adding task set 23.0 with 1 tasks
21/04/09 23:40:20 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 28, localhost, executor driver, partition 0, PROCESS_LOCAL, 8346 bytes)
21/04/09 23:40:20 INFO Executor: Running task 0.0 in stage 23.0 (TID 28)
21/04/09 23:40:20 INFO FileScanRDD: Reading File path: file:///E:/OneDrive/WUSTL/Math%20Research/test/data-csv/letters1.csv, range: 0-30, partition values: [empty row]
21/04/09 23:40:20 INFO Executor: Finished task 0.0 in stage 23.0 (TID 28). 1181 bytes result sent to driver
21/04/09 23:40:20 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 28) in 4 ms on localhost (executor driver) (1/1)
21/04/09 23:40:20 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool 
21/04/09 23:40:20 INFO DAGScheduler: ResultStage 23 (csv at NativeMethodAccessorImpl.java:0) finished in 0.008 s
21/04/09 23:40:20 INFO DAGScheduler: Job 15 finished: csv at NativeMethodAccessorImpl.java:0, took 0.008373 s
21/04/09 23:40:20 INFO FileSourceStrategy: Pruning directories with: 
21/04/09 23:40:20 INFO FileSourceStrategy: Post-Scan Filters: 
21/04/09 23:40:20 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
21/04/09 23:40:20 INFO FileSourceScanExec: Pushed Filters: 
21/04/09 23:40:20 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 286.0 KB, free 911.4 MB)
21/04/09 23:40:20 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 24.2 KB, free 911.3 MB)
21/04/09 23:40:20 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 127.0.0.1:52393 (size: 24.2 KB, free: 912.2 MB)
21/04/09 23:40:20 INFO SparkContext: Created broadcast 28 from csv at NativeMethodAccessorImpl.java:0
21/04/09 23:40:20 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
21/04/09 23:40:20 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
21/04/09 23:40:20 INFO DAGScheduler: Got job 16 (csv at NativeMethodAccessorImpl.java:0) with 2 output partitions
21/04/09 23:40:20 INFO DAGScheduler: Final stage: ResultStage 24 (csv at NativeMethodAccessorImpl.java:0)
21/04/09 23:40:20 INFO DAGScheduler: Parents of final stage: List()
21/04/09 23:40:20 INFO DAGScheduler: Missing parents: List()
21/04/09 23:40:20 INFO DAGScheduler: Submitting ResultStage 24 (MapPartitionsRDD[98] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
21/04/09 23:40:20 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 15.0 KB, free 911.3 MB)
21/04/09 23:40:20 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 8.7 KB, free 911.3 MB)
21/04/09 23:40:20 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 127.0.0.1:52393 (size: 8.7 KB, free: 912.2 MB)
21/04/09 23:40:20 INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1161
21/04/09 23:40:20 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 24 (MapPartitionsRDD[98] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
21/04/09 23:40:20 INFO TaskSchedulerImpl: Adding task set 24.0 with 2 tasks
21/04/09 23:40:20 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 29, localhost, executor driver, partition 0, PROCESS_LOCAL, 8346 bytes)
21/04/09 23:40:20 INFO TaskSetManager: Starting task 1.0 in stage 24.0 (TID 30, localhost, executor driver, partition 1, PROCESS_LOCAL, 8346 bytes)
21/04/09 23:40:20 INFO Executor: Running task 0.0 in stage 24.0 (TID 29)
21/04/09 23:40:20 INFO Executor: Running task 1.0 in stage 24.0 (TID 30)
21/04/09 23:40:20 INFO FileScanRDD: Reading File path: file:///E:/OneDrive/WUSTL/Math%20Research/test/data-csv/letters2.csv, range: 0-30, partition values: [empty row]
21/04/09 23:40:20 INFO FileScanRDD: Reading File path: file:///E:/OneDrive/WUSTL/Math%20Research/test/data-csv/letters1.csv, range: 0-30, partition values: [empty row]
21/04/09 23:40:20 INFO Executor: Finished task 1.0 in stage 24.0 (TID 30). 1438 bytes result sent to driver
21/04/09 23:40:20 INFO Executor: Finished task 0.0 in stage 24.0 (TID 29). 1438 bytes result sent to driver
21/04/09 23:40:20 INFO TaskSetManager: Finished task 1.0 in stage 24.0 (TID 30) in 6 ms on localhost (executor driver) (1/2)
21/04/09 23:40:20 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 29) in 7 ms on localhost (executor driver) (2/2)
21/04/09 23:40:20 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
21/04/09 23:40:20 INFO DAGScheduler: ResultStage 24 (csv at NativeMethodAccessorImpl.java:0) finished in 0.009 s
21/04/09 23:40:20 INFO DAGScheduler: Job 16 finished: csv at NativeMethodAccessorImpl.java:0, took 0.010060 s
21/04/09 23:40:21 INFO HiveMetaStore: 0: get_database: default
21/04/09 23:40:21 INFO audit: ugi=lizha	ip=unknown-ip-addr	cmd=get_database: default	
21/04/09 23:40:21 INFO HiveMetaStore: 0: get_database: default
21/04/09 23:40:21 INFO audit: ugi=lizha	ip=unknown-ip-addr	cmd=get_database: default	
21/04/09 23:40:21 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/04/09 23:40:21 INFO audit: ugi=lizha	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/04/09 23:40:21 INFO SparkContext: Starting job: count at utils.scala:135
21/04/09 23:40:21 INFO DAGScheduler: Registering RDD 102 (count at utils.scala:135)
21/04/09 23:40:21 INFO DAGScheduler: Got job 17 (count at utils.scala:135) with 1 output partitions
21/04/09 23:40:21 INFO DAGScheduler: Final stage: ResultStage 26 (count at utils.scala:135)
21/04/09 23:40:21 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 25)
21/04/09 23:40:21 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 25)
21/04/09 23:40:21 INFO DAGScheduler: Submitting ShuffleMapStage 25 (MapPartitionsRDD[102] at count at utils.scala:135), which has no missing parents
21/04/09 23:40:21 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 7.9 KB, free 911.3 MB)
21/04/09 23:40:21 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 4.2 KB, free 911.3 MB)
21/04/09 23:40:21 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 127.0.0.1:52393 (size: 4.2 KB, free: 912.2 MB)
21/04/09 23:40:21 INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1161
21/04/09 23:40:21 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 25 (MapPartitionsRDD[102] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/04/09 23:40:21 INFO TaskSchedulerImpl: Adding task set 25.0 with 1 tasks
21/04/09 23:40:21 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 31, localhost, executor driver, partition 0, PROCESS_LOCAL, 8017 bytes)
21/04/09 23:40:21 INFO Executor: Running task 0.0 in stage 25.0 (TID 31)
21/04/09 23:40:21 INFO Executor: Finished task 0.0 in stage 25.0 (TID 31). 1413 bytes result sent to driver
21/04/09 23:40:21 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 31) in 5 ms on localhost (executor driver) (1/1)
21/04/09 23:40:21 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool 
21/04/09 23:40:21 INFO DAGScheduler: ShuffleMapStage 25 (count at utils.scala:135) finished in 0.009 s
21/04/09 23:40:21 INFO DAGScheduler: looking for newly runnable stages
21/04/09 23:40:21 INFO DAGScheduler: running: Set()
21/04/09 23:40:21 INFO DAGScheduler: waiting: Set(ResultStage 26)
21/04/09 23:40:21 INFO DAGScheduler: failed: Set()
21/04/09 23:40:21 INFO DAGScheduler: Submitting ResultStage 26 (MapPartitionsRDD[105] at count at utils.scala:135), which has no missing parents
21/04/09 23:40:21 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 7.1 KB, free 911.3 MB)
21/04/09 23:40:21 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 3.8 KB, free 911.3 MB)
21/04/09 23:40:21 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 127.0.0.1:52393 (size: 3.8 KB, free: 912.2 MB)
21/04/09 23:40:21 INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1161
21/04/09 23:40:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 26 (MapPartitionsRDD[105] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/04/09 23:40:21 INFO TaskSchedulerImpl: Adding task set 26.0 with 1 tasks
21/04/09 23:40:21 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 32, localhost, executor driver, partition 0, ANY, 7767 bytes)
21/04/09 23:40:21 INFO Executor: Running task 0.0 in stage 26.0 (TID 32)
21/04/09 23:40:21 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/04/09 23:40:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/04/09 23:40:21 INFO Executor: Finished task 0.0 in stage 26.0 (TID 32). 1696 bytes result sent to driver
21/04/09 23:40:21 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 32) in 3 ms on localhost (executor driver) (1/1)
21/04/09 23:40:21 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool 
21/04/09 23:40:21 INFO DAGScheduler: ResultStage 26 (count at utils.scala:135) finished in 0.006 s
21/04/09 23:40:21 INFO DAGScheduler: Job 17 finished: count at utils.scala:135, took 0.016128 s
21/04/09 23:40:21 WARN CacheManager: Asked to cache already cached data.
21/04/09 23:40:21 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
21/04/09 23:40:21 INFO DAGScheduler: Registering RDD 110 (sql at NativeMethodAccessorImpl.java:0)
21/04/09 23:40:21 INFO DAGScheduler: Got job 18 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/04/09 23:40:21 INFO DAGScheduler: Final stage: ResultStage 28 (sql at NativeMethodAccessorImpl.java:0)
21/04/09 23:40:21 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 27)
21/04/09 23:40:21 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 27)
21/04/09 23:40:21 INFO DAGScheduler: Submitting ShuffleMapStage 27 (MapPartitionsRDD[110] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
21/04/09 23:40:21 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 20.2 KB, free 911.3 MB)
21/04/09 23:40:21 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 10.5 KB, free 911.3 MB)
21/04/09 23:40:21 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 127.0.0.1:52393 (size: 10.5 KB, free: 912.2 MB)
21/04/09 23:40:21 INFO SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:1161
21/04/09 23:40:21 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 27 (MapPartitionsRDD[110] at sql at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
21/04/09 23:40:21 INFO TaskSchedulerImpl: Adding task set 27.0 with 2 tasks
21/04/09 23:40:21 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 33, localhost, executor driver, partition 0, PROCESS_LOCAL, 8335 bytes)
21/04/09 23:40:21 INFO TaskSetManager: Starting task 1.0 in stage 27.0 (TID 34, localhost, executor driver, partition 1, PROCESS_LOCAL, 8335 bytes)
21/04/09 23:40:21 INFO Executor: Running task 0.0 in stage 27.0 (TID 33)
21/04/09 23:40:21 INFO Executor: Running task 1.0 in stage 27.0 (TID 34)
21/04/09 23:40:21 INFO BlockManager: Found block rdd_30_0 locally
21/04/09 23:40:21 INFO BlockManager: Found block rdd_30_1 locally
21/04/09 23:40:21 INFO Executor: Finished task 0.0 in stage 27.0 (TID 33). 1828 bytes result sent to driver
21/04/09 23:40:21 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 33) in 7 ms on localhost (executor driver) (1/2)
21/04/09 23:40:21 INFO Executor: Finished task 1.0 in stage 27.0 (TID 34). 1828 bytes result sent to driver
21/04/09 23:40:21 INFO TaskSetManager: Finished task 1.0 in stage 27.0 (TID 34) in 7 ms on localhost (executor driver) (2/2)
21/04/09 23:40:21 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool 
21/04/09 23:40:21 INFO DAGScheduler: ShuffleMapStage 27 (sql at NativeMethodAccessorImpl.java:0) finished in 0.012 s
21/04/09 23:40:21 INFO DAGScheduler: looking for newly runnable stages
21/04/09 23:40:21 INFO DAGScheduler: running: Set()
21/04/09 23:40:21 INFO DAGScheduler: waiting: Set(ResultStage 28)
21/04/09 23:40:21 INFO DAGScheduler: failed: Set()
21/04/09 23:40:21 INFO DAGScheduler: Submitting ResultStage 28 (MapPartitionsRDD[113] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
21/04/09 23:40:21 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 7.1 KB, free 911.3 MB)
21/04/09 23:40:21 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 3.8 KB, free 911.2 MB)
21/04/09 23:40:21 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 127.0.0.1:52393 (size: 3.8 KB, free: 912.2 MB)
21/04/09 23:40:21 INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:1161
21/04/09 23:40:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 28 (MapPartitionsRDD[113] at sql at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/04/09 23:40:21 INFO TaskSchedulerImpl: Adding task set 28.0 with 1 tasks
21/04/09 23:40:21 INFO TaskSetManager: Starting task 0.0 in stage 28.0 (TID 35, localhost, executor driver, partition 0, ANY, 7767 bytes)
21/04/09 23:40:21 INFO Executor: Running task 0.0 in stage 28.0 (TID 35)
21/04/09 23:40:21 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks including 2 local blocks and 0 remote blocks
21/04/09 23:40:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/04/09 23:40:21 INFO Executor: Finished task 0.0 in stage 28.0 (TID 35). 1696 bytes result sent to driver
21/04/09 23:40:21 INFO TaskSetManager: Finished task 0.0 in stage 28.0 (TID 35) in 4 ms on localhost (executor driver) (1/1)
21/04/09 23:40:21 INFO TaskSchedulerImpl: Removed TaskSet 28.0, whose tasks have all completed, from pool 
21/04/09 23:40:21 INFO DAGScheduler: ResultStage 28 (sql at NativeMethodAccessorImpl.java:0) finished in 0.007 s
21/04/09 23:40:21 INFO DAGScheduler: Job 18 finished: sql at NativeMethodAccessorImpl.java:0, took 0.021674 s
21/04/09 23:40:21 INFO SparkContext: Starting job: collect at utils.scala:135
21/04/09 23:40:21 INFO DAGScheduler: Registering RDD 118 (collect at utils.scala:135)
21/04/09 23:40:21 INFO DAGScheduler: Got job 19 (collect at utils.scala:135) with 1 output partitions
21/04/09 23:40:21 INFO DAGScheduler: Final stage: ResultStage 30 (collect at utils.scala:135)
21/04/09 23:40:21 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 29)
21/04/09 23:40:21 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 29)
21/04/09 23:40:21 INFO DAGScheduler: Submitting ShuffleMapStage 29 (MapPartitionsRDD[118] at collect at utils.scala:135), which has no missing parents
21/04/09 23:40:21 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 20.2 KB, free 911.2 MB)
21/04/09 23:40:21 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 10.5 KB, free 911.2 MB)
21/04/09 23:40:21 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 127.0.0.1:52393 (size: 10.5 KB, free: 912.2 MB)
21/04/09 23:40:21 INFO SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:1161
21/04/09 23:40:21 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 29 (MapPartitionsRDD[118] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0, 1))
21/04/09 23:40:21 INFO TaskSchedulerImpl: Adding task set 29.0 with 2 tasks
21/04/09 23:40:21 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 36, localhost, executor driver, partition 0, PROCESS_LOCAL, 8335 bytes)
21/04/09 23:40:21 INFO TaskSetManager: Starting task 1.0 in stage 29.0 (TID 37, localhost, executor driver, partition 1, PROCESS_LOCAL, 8335 bytes)
21/04/09 23:40:21 INFO Executor: Running task 1.0 in stage 29.0 (TID 37)
21/04/09 23:40:21 INFO Executor: Running task 0.0 in stage 29.0 (TID 36)
21/04/09 23:40:21 INFO BlockManager: Found block rdd_30_0 locally
21/04/09 23:40:21 INFO BlockManager: Found block rdd_30_1 locally
21/04/09 23:40:21 INFO Executor: Finished task 0.0 in stage 29.0 (TID 36). 1785 bytes result sent to driver
21/04/09 23:40:21 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 36) in 6 ms on localhost (executor driver) (1/2)
21/04/09 23:40:21 INFO Executor: Finished task 1.0 in stage 29.0 (TID 37). 1785 bytes result sent to driver
21/04/09 23:40:21 INFO TaskSetManager: Finished task 1.0 in stage 29.0 (TID 37) in 6 ms on localhost (executor driver) (2/2)
21/04/09 23:40:21 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool 
21/04/09 23:40:21 INFO DAGScheduler: ShuffleMapStage 29 (collect at utils.scala:135) finished in 0.010 s
21/04/09 23:40:21 INFO DAGScheduler: looking for newly runnable stages
21/04/09 23:40:21 INFO DAGScheduler: running: Set()
21/04/09 23:40:21 INFO DAGScheduler: waiting: Set(ResultStage 30)
21/04/09 23:40:21 INFO DAGScheduler: failed: Set()
21/04/09 23:40:21 INFO DAGScheduler: Submitting ResultStage 30 (MapPartitionsRDD[121] at collect at utils.scala:135), which has no missing parents
21/04/09 23:40:21 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 7.1 KB, free 911.2 MB)
21/04/09 23:40:21 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 3.8 KB, free 911.2 MB)
21/04/09 23:40:21 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 127.0.0.1:52393 (size: 3.8 KB, free: 912.2 MB)
21/04/09 23:40:21 INFO SparkContext: Created broadcast 35 from broadcast at DAGScheduler.scala:1161
21/04/09 23:40:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 30 (MapPartitionsRDD[121] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/04/09 23:40:21 INFO TaskSchedulerImpl: Adding task set 30.0 with 1 tasks
21/04/09 23:40:21 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 38, localhost, executor driver, partition 0, ANY, 7767 bytes)
21/04/09 23:40:21 INFO Executor: Running task 0.0 in stage 30.0 (TID 38)
21/04/09 23:40:21 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks including 2 local blocks and 0 remote blocks
21/04/09 23:40:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/04/09 23:40:21 INFO Executor: Finished task 0.0 in stage 30.0 (TID 38). 1653 bytes result sent to driver
21/04/09 23:40:21 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 38) in 4 ms on localhost (executor driver) (1/1)
21/04/09 23:40:21 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool 
21/04/09 23:40:21 INFO DAGScheduler: ResultStage 30 (collect at utils.scala:135) finished in 0.006 s
21/04/09 23:40:21 INFO DAGScheduler: Job 19 finished: collect at utils.scala:135, took 0.018825 s
21/04/09 23:40:21 INFO SparkContext: Starting job: count at utils.scala:135
21/04/09 23:40:21 INFO DAGScheduler: Registering RDD 126 (count at utils.scala:135)
21/04/09 23:40:21 INFO DAGScheduler: Got job 20 (count at utils.scala:135) with 1 output partitions
21/04/09 23:40:21 INFO DAGScheduler: Final stage: ResultStage 32 (count at utils.scala:135)
21/04/09 23:40:21 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 31)
21/04/09 23:40:21 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 31)
21/04/09 23:40:21 INFO DAGScheduler: Submitting ShuffleMapStage 31 (MapPartitionsRDD[126] at count at utils.scala:135), which has no missing parents
21/04/09 23:40:21 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 19.6 KB, free 911.2 MB)
21/04/09 23:40:21 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 10.3 KB, free 911.2 MB)
21/04/09 23:40:21 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 127.0.0.1:52393 (size: 10.3 KB, free: 912.2 MB)
21/04/09 23:40:21 INFO SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:1161
21/04/09 23:40:21 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 31 (MapPartitionsRDD[126] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0, 1))
21/04/09 23:40:21 INFO TaskSchedulerImpl: Adding task set 31.0 with 2 tasks
21/04/09 23:40:21 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 39, localhost, executor driver, partition 0, PROCESS_LOCAL, 8335 bytes)
21/04/09 23:40:21 INFO TaskSetManager: Starting task 1.0 in stage 31.0 (TID 40, localhost, executor driver, partition 1, PROCESS_LOCAL, 8335 bytes)
21/04/09 23:40:21 INFO Executor: Running task 0.0 in stage 31.0 (TID 39)
21/04/09 23:40:21 INFO Executor: Running task 1.0 in stage 31.0 (TID 40)
21/04/09 23:40:21 INFO BlockManager: Found block rdd_30_0 locally
21/04/09 23:40:21 INFO BlockManager: Found block rdd_30_1 locally
21/04/09 23:40:21 INFO Executor: Finished task 0.0 in stage 31.0 (TID 39). 1785 bytes result sent to driver
21/04/09 23:40:21 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 39) in 6 ms on localhost (executor driver) (1/2)
21/04/09 23:40:21 INFO Executor: Finished task 1.0 in stage 31.0 (TID 40). 1785 bytes result sent to driver
21/04/09 23:40:21 INFO TaskSetManager: Finished task 1.0 in stage 31.0 (TID 40) in 7 ms on localhost (executor driver) (2/2)
21/04/09 23:40:21 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool 
21/04/09 23:40:21 INFO DAGScheduler: ShuffleMapStage 31 (count at utils.scala:135) finished in 0.010 s
21/04/09 23:40:21 INFO DAGScheduler: looking for newly runnable stages
21/04/09 23:40:21 INFO DAGScheduler: running: Set()
21/04/09 23:40:21 INFO DAGScheduler: waiting: Set(ResultStage 32)
21/04/09 23:40:21 INFO DAGScheduler: failed: Set()
21/04/09 23:40:21 INFO DAGScheduler: Submitting ResultStage 32 (MapPartitionsRDD[129] at count at utils.scala:135), which has no missing parents
21/04/09 23:40:21 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 9.1 KB, free 911.2 MB)
21/04/09 23:40:21 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 4.1 KB, free 911.2 MB)
21/04/09 23:40:21 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 127.0.0.1:52393 (size: 4.1 KB, free: 912.2 MB)
21/04/09 23:40:21 INFO SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:1161
21/04/09 23:40:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 32 (MapPartitionsRDD[129] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/04/09 23:40:21 INFO TaskSchedulerImpl: Adding task set 32.0 with 1 tasks
21/04/09 23:40:21 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 41, localhost, executor driver, partition 0, ANY, 7767 bytes)
21/04/09 23:40:21 INFO Executor: Running task 0.0 in stage 32.0 (TID 41)
21/04/09 23:40:21 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks including 2 local blocks and 0 remote blocks
21/04/09 23:40:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/04/09 23:40:21 INFO Executor: Finished task 0.0 in stage 32.0 (TID 41). 1969 bytes result sent to driver
21/04/09 23:40:21 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 41) in 4 ms on localhost (executor driver) (1/1)
21/04/09 23:40:21 INFO DAGScheduler: ResultStage 32 (count at utils.scala:135) finished in 0.007 s
21/04/09 23:40:21 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool 
21/04/09 23:40:21 INFO DAGScheduler: Job 20 finished: count at utils.scala:135, took 0.019636 s
21/04/09 23:40:21 INFO SparkContext: Starting job: collect at utils.scala:135
21/04/09 23:40:21 INFO DAGScheduler: Got job 21 (collect at utils.scala:135) with 1 output partitions
21/04/09 23:40:21 INFO DAGScheduler: Final stage: ResultStage 33 (collect at utils.scala:135)
21/04/09 23:40:21 INFO DAGScheduler: Parents of final stage: List()
21/04/09 23:40:21 INFO DAGScheduler: Missing parents: List()
21/04/09 23:40:21 INFO DAGScheduler: Submitting ResultStage 33 (MapPartitionsRDD[132] at collect at utils.scala:135), which has no missing parents
21/04/09 23:40:21 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 6.1 KB, free 911.2 MB)
21/04/09 23:40:21 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 3.2 KB, free 911.2 MB)
21/04/09 23:40:21 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on 127.0.0.1:52393 (size: 3.2 KB, free: 912.1 MB)
21/04/09 23:40:21 INFO SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:1161
21/04/09 23:40:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 33 (MapPartitionsRDD[132] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/04/09 23:40:21 INFO TaskSchedulerImpl: Adding task set 33.0 with 1 tasks
21/04/09 23:40:21 INFO TaskSetManager: Starting task 0.0 in stage 33.0 (TID 42, localhost, executor driver, partition 0, PROCESS_LOCAL, 8080 bytes)
21/04/09 23:40:21 INFO Executor: Running task 0.0 in stage 33.0 (TID 42)
21/04/09 23:40:21 INFO Executor: Finished task 0.0 in stage 33.0 (TID 42). 1157 bytes result sent to driver
21/04/09 23:40:21 INFO TaskSetManager: Finished task 0.0 in stage 33.0 (TID 42) in 3 ms on localhost (executor driver) (1/1)
21/04/09 23:40:21 INFO TaskSchedulerImpl: Removed TaskSet 33.0, whose tasks have all completed, from pool 
21/04/09 23:40:21 INFO DAGScheduler: ResultStage 33 (collect at utils.scala:135) finished in 0.005 s
21/04/09 23:40:21 INFO DAGScheduler: Job 21 finished: collect at utils.scala:135, took 0.005973 s
21/04/09 23:40:21 INFO SparkContext: Starting job: count at utils.scala:135
21/04/09 23:40:21 INFO DAGScheduler: Registering RDD 135 (count at utils.scala:135)
21/04/09 23:40:21 INFO DAGScheduler: Got job 22 (count at utils.scala:135) with 1 output partitions
21/04/09 23:40:21 INFO DAGScheduler: Final stage: ResultStage 35 (count at utils.scala:135)
21/04/09 23:40:21 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 34)
21/04/09 23:40:21 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 34)
21/04/09 23:40:21 INFO DAGScheduler: Submitting ShuffleMapStage 34 (MapPartitionsRDD[135] at count at utils.scala:135), which has no missing parents
21/04/09 23:40:21 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 8.4 KB, free 911.1 MB)
21/04/09 23:40:21 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 4.5 KB, free 911.1 MB)
21/04/09 23:40:21 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on 127.0.0.1:52393 (size: 4.5 KB, free: 912.1 MB)
21/04/09 23:40:21 INFO SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:1161
21/04/09 23:40:21 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 34 (MapPartitionsRDD[135] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/04/09 23:40:21 INFO TaskSchedulerImpl: Adding task set 34.0 with 1 tasks
21/04/09 23:40:21 INFO TaskSetManager: Starting task 0.0 in stage 34.0 (TID 43, localhost, executor driver, partition 0, PROCESS_LOCAL, 8069 bytes)
21/04/09 23:40:21 INFO Executor: Running task 0.0 in stage 34.0 (TID 43)
21/04/09 23:40:21 INFO Executor: Finished task 0.0 in stage 34.0 (TID 43). 1413 bytes result sent to driver
21/04/09 23:40:21 INFO TaskSetManager: Finished task 0.0 in stage 34.0 (TID 43) in 4 ms on localhost (executor driver) (1/1)
21/04/09 23:40:21 INFO TaskSchedulerImpl: Removed TaskSet 34.0, whose tasks have all completed, from pool 
21/04/09 23:40:21 INFO DAGScheduler: ShuffleMapStage 34 (count at utils.scala:135) finished in 0.009 s
21/04/09 23:40:21 INFO DAGScheduler: looking for newly runnable stages
21/04/09 23:40:21 INFO DAGScheduler: running: Set()
21/04/09 23:40:21 INFO DAGScheduler: waiting: Set(ResultStage 35)
21/04/09 23:40:21 INFO DAGScheduler: failed: Set()
21/04/09 23:40:21 INFO DAGScheduler: Submitting ResultStage 35 (MapPartitionsRDD[138] at count at utils.scala:135), which has no missing parents
21/04/09 23:40:21 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 7.1 KB, free 911.1 MB)
21/04/09 23:40:21 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 3.8 KB, free 911.1 MB)
21/04/09 23:40:21 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on 127.0.0.1:52393 (size: 3.8 KB, free: 912.1 MB)
21/04/09 23:40:21 INFO SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:1161
21/04/09 23:40:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 35 (MapPartitionsRDD[138] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/04/09 23:40:21 INFO TaskSchedulerImpl: Adding task set 35.0 with 1 tasks
21/04/09 23:40:21 INFO TaskSetManager: Starting task 0.0 in stage 35.0 (TID 44, localhost, executor driver, partition 0, ANY, 7767 bytes)
21/04/09 23:40:21 INFO Executor: Running task 0.0 in stage 35.0 (TID 44)
21/04/09 23:40:21 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/04/09 23:40:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/04/09 23:40:21 INFO Executor: Finished task 0.0 in stage 35.0 (TID 44). 1696 bytes result sent to driver
21/04/09 23:40:21 INFO TaskSetManager: Finished task 0.0 in stage 35.0 (TID 44) in 4 ms on localhost (executor driver) (1/1)
21/04/09 23:40:21 INFO TaskSchedulerImpl: Removed TaskSet 35.0, whose tasks have all completed, from pool 
21/04/09 23:40:21 INFO DAGScheduler: ResultStage 35 (count at utils.scala:135) finished in 0.006 s
21/04/09 23:40:21 INFO DAGScheduler: Job 22 finished: count at utils.scala:135, took 0.015861 s
21/04/09 23:40:21 INFO SparkContext: Invoking stop() from shutdown hook
21/04/09 23:40:21 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
21/04/09 23:40:21 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/04/09 23:40:21 INFO MemoryStore: MemoryStore cleared
21/04/09 23:40:21 INFO BlockManager: BlockManager stopped
21/04/09 23:40:21 INFO BlockManagerMaster: BlockManagerMaster stopped
21/04/09 23:40:21 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/04/09 23:40:21 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\lizha\AppData\Local\spark\spark-2.4.3-bin-hadoop2.7\tmp\local\spark-69b65a42-6574-4178-a660-cf3124786cac\userFiles-eaf43e3c-117c-4348-a56c-a053795c249a
java.io.IOException: Failed to delete: C:\Users\lizha\AppData\Local\spark\spark-2.4.3-bin-hadoop2.7\tmp\local\spark-69b65a42-6574-4178-a660-cf3124786cac\userFiles-eaf43e3c-117c-4348-a56c-a053795c249a\sparklyr-2.4-2.11.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:144)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:128)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:91)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1062)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:103)
	at org.apache.spark.SparkContext$$anonfun$stop$11.apply$mcV$sp(SparkContext.scala:1974)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1340)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1973)
	at org.apache.spark.SparkContext$$anonfun$2.apply$mcV$sp(SparkContext.scala:575)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1945)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
21/04/09 23:40:21 INFO SparkContext: Successfully stopped SparkContext
21/04/09 23:40:21 INFO ShutdownHookManager: Shutdown hook called
21/04/09 23:40:21 INFO ShutdownHookManager: Deleting directory C:\Users\lizha\AppData\Local\spark\spark-2.4.3-bin-hadoop2.7\tmp\local\spark-69b65a42-6574-4178-a660-cf3124786cac\userFiles-eaf43e3c-117c-4348-a56c-a053795c249a
21/04/09 23:40:21 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\lizha\AppData\Local\spark\spark-2.4.3-bin-hadoop2.7\tmp\local\spark-69b65a42-6574-4178-a660-cf3124786cac\userFiles-eaf43e3c-117c-4348-a56c-a053795c249a
java.io.IOException: Failed to delete: C:\Users\lizha\AppData\Local\spark\spark-2.4.3-bin-hadoop2.7\tmp\local\spark-69b65a42-6574-4178-a660-cf3124786cac\userFiles-eaf43e3c-117c-4348-a56c-a053795c249a\sparklyr-2.4-2.11.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:144)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:128)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:91)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1062)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1945)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
21/04/09 23:40:21 INFO ShutdownHookManager: Deleting directory C:\Users\lizha\AppData\Local\Temp\spark-2bfc2e35-fb07-4643-b80c-42164ea8b041
21/04/09 23:40:21 INFO ShutdownHookManager: Deleting directory C:\Users\lizha\AppData\Local\spark\spark-2.4.3-bin-hadoop2.7\tmp\local\spark-69b65a42-6574-4178-a660-cf3124786cac
21/04/09 23:40:21 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\lizha\AppData\Local\spark\spark-2.4.3-bin-hadoop2.7\tmp\local\spark-69b65a42-6574-4178-a660-cf3124786cac
java.io.IOException: Failed to delete: C:\Users\lizha\AppData\Local\spark\spark-2.4.3-bin-hadoop2.7\tmp\local\spark-69b65a42-6574-4178-a660-cf3124786cac\userFiles-eaf43e3c-117c-4348-a56c-a053795c249a\sparklyr-2.4-2.11.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:144)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:128)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:128)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:91)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1062)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1945)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
21/04/09 23:49:16 INFO SparkContext: Running Spark version 2.4.3
21/04/09 23:49:16 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
21/04/09 23:49:16 INFO SparkContext: Submitted application: sparklyr
21/04/09 23:49:16 INFO SecurityManager: Changing view acls to: lizha
21/04/09 23:49:16 INFO SecurityManager: Changing modify acls to: lizha
21/04/09 23:49:16 INFO SecurityManager: Changing view acls groups to: 
21/04/09 23:49:16 INFO SecurityManager: Changing modify acls groups to: 
21/04/09 23:49:16 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(lizha); groups with view permissions: Set(); users  with modify permissions: Set(lizha); groups with modify permissions: Set()
21/04/09 23:49:16 INFO Utils: Successfully started service 'sparkDriver' on port 54092.
21/04/09 23:49:17 INFO SparkEnv: Registering MapOutputTracker
21/04/09 23:49:17 INFO SparkEnv: Registering BlockManagerMaster
21/04/09 23:49:17 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/04/09 23:49:17 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/04/09 23:49:17 INFO DiskBlockManager: Created local directory at C:\Users\lizha\AppData\Local\spark\spark-2.4.3-bin-hadoop2.7\tmp\local\blockmgr-c02208f9-e4ba-4790-98d8-533c3ef99da1
21/04/09 23:49:17 INFO MemoryStore: MemoryStore started with capacity 912.3 MB
21/04/09 23:49:17 INFO SparkEnv: Registering OutputCommitCoordinator
21/04/09 23:49:17 WARN Utils: The configured local directories are not expected to be URIs; however, got suspicious values [C:/Users/lizha/AppData/Local/spark/spark-2.4.3-bin-hadoop2.7/tmp/local]. Please check your configured local directories.
21/04/09 23:49:17 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/04/09 23:49:17 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
21/04/09 23:49:17 INFO SparkContext: Added JAR file:/E:/OneDrive/Documents/R/win-library/4.0/sparklyr/java/sparklyr-2.4-2.11.jar at spark://127.0.0.1:54092/jars/sparklyr-2.4-2.11.jar with timestamp 1618030157221
21/04/09 23:49:17 INFO Executor: Starting executor ID driver on host localhost
21/04/09 23:49:17 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54133.
21/04/09 23:49:17 INFO NettyBlockTransferService: Server created on 127.0.0.1:54133
21/04/09 23:49:17 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/04/09 23:49:17 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 54133, None)
21/04/09 23:49:17 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:54133 with 912.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 54133, None)
21/04/09 23:49:17 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 54133, None)
21/04/09 23:49:17 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 54133, None)
21/04/09 23:49:17 INFO SharedState: loading hive config file: file:/C:/Users/lizha/AppData/Local/spark/spark-2.4.3-bin-hadoop2.7/conf/hive-site.xml
21/04/09 23:49:17 INFO SharedState: Setting hive.metastore.warehouse.dir ('C:/Users/lizha/AppData/Local/spark/spark-2.4.3-bin-hadoop2.7/tmp/hive') to the value of spark.sql.warehouse.dir ('C:/Users/lizha/AppData/Local/spark/spark-2.4.3-bin-hadoop2.7/tmp/hive').
21/04/09 23:49:17 INFO SharedState: Warehouse path is 'C:/Users/lizha/AppData/Local/spark/spark-2.4.3-bin-hadoop2.7/tmp/hive'.
21/04/09 23:49:17 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
21/04/09 23:49:19 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
21/04/09 23:49:19 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
21/04/09 23:49:19 INFO ObjectStore: ObjectStore, initialize called
21/04/09 23:49:19 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
21/04/09 23:49:19 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
21/04/09 23:49:20 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
21/04/09 23:49:21 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/04/09 23:49:21 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/04/09 23:49:21 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/04/09 23:49:21 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/04/09 23:49:21 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
21/04/09 23:49:21 INFO ObjectStore: Initialized ObjectStore
21/04/09 23:49:21 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
21/04/09 23:49:21 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
21/04/09 23:49:21 INFO HiveMetaStore: Added admin role in metastore
21/04/09 23:49:21 INFO HiveMetaStore: Added public role in metastore
21/04/09 23:49:21 INFO HiveMetaStore: No user is added in admin role, since config is empty
21/04/09 23:49:21 INFO HiveMetaStore: 0: get_all_databases
21/04/09 23:49:21 INFO audit: ugi=lizha	ip=unknown-ip-addr	cmd=get_all_databases	
21/04/09 23:49:21 INFO HiveMetaStore: 0: get_functions: db=default pat=*
21/04/09 23:49:21 INFO audit: ugi=lizha	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
21/04/09 23:49:21 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
21/04/09 23:49:21 INFO SessionState: Created local directory: C:/Users/lizha/AppData/Local/Temp/8a6ca067-4ea9-48d0-855b-aab41db3d376_resources
21/04/09 23:49:21 INFO SessionState: Created HDFS directory: C:/Users/lizha/AppData/Local/spark/spark-2.4.3-bin-hadoop2.7/tmp/hive/lizha/8a6ca067-4ea9-48d0-855b-aab41db3d376
21/04/09 23:49:21 INFO SessionState: Created local directory: C:/Users/lizha/AppData/Local/spark/spark-2.4.3-bin-hadoop2.7/tmp/hive/8a6ca067-4ea9-48d0-855b-aab41db3d376
21/04/09 23:49:21 INFO SessionState: Created HDFS directory: C:/Users/lizha/AppData/Local/spark/spark-2.4.3-bin-hadoop2.7/tmp/hive/lizha/8a6ca067-4ea9-48d0-855b-aab41db3d376/_tmp_space.db
21/04/09 23:49:21 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.2) is C:/Users/lizha/AppData/Local/spark/spark-2.4.3-bin-hadoop2.7/tmp/hive
21/04/09 23:49:21 INFO HiveMetaStore: 0: get_database: default
21/04/09 23:49:21 INFO audit: ugi=lizha	ip=unknown-ip-addr	cmd=get_database: default	
21/04/09 23:49:21 INFO HiveMetaStore: 0: get_database: global_temp
21/04/09 23:49:21 INFO audit: ugi=lizha	ip=unknown-ip-addr	cmd=get_database: global_temp	
21/04/09 23:49:21 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
21/04/09 23:49:21 INFO HiveMetaStore: 0: get_database: default
21/04/09 23:49:21 INFO audit: ugi=lizha	ip=unknown-ip-addr	cmd=get_database: default	
21/04/09 23:49:21 INFO HiveMetaStore: 0: get_database: default
21/04/09 23:49:21 INFO audit: ugi=lizha	ip=unknown-ip-addr	cmd=get_database: default	
21/04/09 23:49:21 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/04/09 23:49:21 INFO audit: ugi=lizha	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/04/09 23:49:22 INFO CodeGenerator: Code generated in 137.1766 ms
21/04/09 23:49:22 INFO CodeGenerator: Code generated in 12.9451 ms
21/04/09 23:49:22 INFO CodeGenerator: Code generated in 8.8586 ms
21/04/09 23:49:22 INFO SparkContext: Starting job: count at utils.scala:135
21/04/09 23:49:22 INFO DAGScheduler: Registering RDD 3 (count at utils.scala:135)
21/04/09 23:49:22 INFO DAGScheduler: Got job 0 (count at utils.scala:135) with 1 output partitions
21/04/09 23:49:22 INFO DAGScheduler: Final stage: ResultStage 1 (count at utils.scala:135)
21/04/09 23:49:22 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
21/04/09 23:49:22 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
21/04/09 23:49:22 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at count at utils.scala:135), which has no missing parents
21/04/09 23:49:22 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 7.9 KB, free 912.3 MB)
21/04/09 23:49:22 INFO ContextCleaner: Cleaned accumulator 1
21/04/09 23:49:22 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.2 KB, free 912.3 MB)
21/04/09 23:49:22 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:54133 (size: 4.2 KB, free: 912.3 MB)
21/04/09 23:49:22 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1161
21/04/09 23:49:22 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/04/09 23:49:22 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
21/04/09 23:49:22 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7882 bytes)
21/04/09 23:49:22 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
21/04/09 23:49:22 INFO Executor: Fetching spark://127.0.0.1:54092/jars/sparklyr-2.4-2.11.jar with timestamp 1618030157221
21/04/09 23:49:22 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:54092 after 14 ms (0 ms spent in bootstraps)
21/04/09 23:49:22 INFO Utils: Fetching spark://127.0.0.1:54092/jars/sparklyr-2.4-2.11.jar to C:\Users\lizha\AppData\Local\spark\spark-2.4.3-bin-hadoop2.7\tmp\local\spark-ef9edac8-d99d-4995-96ab-1358dd1073f1\userFiles-a88c6894-f86a-40ef-a22e-84fe3dd3876d\fetchFileTemp2085791494108516800.tmp
21/04/09 23:49:22 INFO Executor: Adding file:/C:/Users/lizha/AppData/Local/spark/spark-2.4.3-bin-hadoop2.7/tmp/local/spark-ef9edac8-d99d-4995-96ab-1358dd1073f1/userFiles-a88c6894-f86a-40ef-a22e-84fe3dd3876d/sparklyr-2.4-2.11.jar to class loader
21/04/09 23:49:23 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1542 bytes result sent to driver
21/04/09 23:49:23 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 208 ms on localhost (executor driver) (1/1)
21/04/09 23:49:23 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
21/04/09 23:49:23 INFO DAGScheduler: ShuffleMapStage 0 (count at utils.scala:135) finished in 0.389 s
21/04/09 23:49:23 INFO DAGScheduler: looking for newly runnable stages
21/04/09 23:49:23 INFO DAGScheduler: running: Set()
21/04/09 23:49:23 INFO DAGScheduler: waiting: Set(ResultStage 1)
21/04/09 23:49:23 INFO DAGScheduler: failed: Set()
21/04/09 23:49:23 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[6] at count at utils.scala:135), which has no missing parents
21/04/09 23:49:23 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 7.1 KB, free 912.3 MB)
21/04/09 23:49:23 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.3 MB)
21/04/09 23:49:23 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:54133 (size: 3.8 KB, free: 912.3 MB)
21/04/09 23:49:23 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1161
21/04/09 23:49:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/04/09 23:49:23 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
21/04/09 23:49:23 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, ANY, 7767 bytes)
21/04/09 23:49:23 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
21/04/09 23:49:23 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/04/09 23:49:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
21/04/09 23:49:23 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1732 bytes result sent to driver
21/04/09 23:49:23 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 33 ms on localhost (executor driver) (1/1)
21/04/09 23:49:23 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/04/09 23:49:23 INFO DAGScheduler: ResultStage 1 (count at utils.scala:135) finished in 0.041 s
21/04/09 23:49:23 INFO DAGScheduler: Job 0 finished: count at utils.scala:135, took 0.478776 s
21/04/09 23:49:23 INFO HiveMetaStore: 0: get_database: default
21/04/09 23:49:23 INFO audit: ugi=lizha	ip=unknown-ip-addr	cmd=get_database: default	
21/04/09 23:49:23 INFO HiveMetaStore: 0: get_database: default
21/04/09 23:49:23 INFO audit: ugi=lizha	ip=unknown-ip-addr	cmd=get_database: default	
21/04/09 23:49:23 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/04/09 23:49:23 INFO audit: ugi=lizha	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/04/09 23:49:23 INFO SparkContext: Starting job: collect at utils.scala:61
21/04/09 23:49:23 INFO DAGScheduler: Got job 1 (collect at utils.scala:61) with 1 output partitions
21/04/09 23:49:23 INFO DAGScheduler: Final stage: ResultStage 2 (collect at utils.scala:61)
21/04/09 23:49:23 INFO DAGScheduler: Parents of final stage: List()
21/04/09 23:49:23 INFO DAGScheduler: Missing parents: List()
21/04/09 23:49:23 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[11] at map at utils.scala:54), which has no missing parents
21/04/09 23:49:23 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 6.0 KB, free 912.3 MB)
21/04/09 23:49:23 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.4 KB, free 912.3 MB)
21/04/09 23:49:23 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:54133 (size: 3.4 KB, free: 912.3 MB)
21/04/09 23:49:23 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1161
21/04/09 23:49:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[11] at map at utils.scala:54) (first 15 tasks are for partitions Vector(0))
21/04/09 23:49:23 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
21/04/09 23:49:23 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 7893 bytes)
21/04/09 23:49:23 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
21/04/09 23:49:23 INFO CodeGenerator: Code generated in 6.5094 ms
21/04/09 23:49:23 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 884 bytes result sent to driver
21/04/09 23:49:23 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 13 ms on localhost (executor driver) (1/1)
21/04/09 23:49:23 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
21/04/09 23:49:23 INFO DAGScheduler: ResultStage 2 (collect at utils.scala:61) finished in 0.019 s
21/04/09 23:49:23 INFO DAGScheduler: Job 1 finished: collect at utils.scala:61, took 0.020585 s
21/04/09 23:49:23 INFO FileSourceStrategy: Pruning directories with: 
21/04/09 23:49:23 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#26, None)) > 0)
21/04/09 23:49:23 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
21/04/09 23:49:23 INFO FileSourceScanExec: Pushed Filters: 
21/04/09 23:49:23 INFO CodeGenerator: Code generated in 5.8186 ms
21/04/09 23:49:23 INFO CodeGenerator: Code generated in 7.8733 ms
21/04/09 23:49:23 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 286.0 KB, free 912.0 MB)
21/04/09 23:49:23 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 24.2 KB, free 912.0 MB)
21/04/09 23:49:23 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:54133 (size: 24.2 KB, free: 912.3 MB)
21/04/09 23:49:23 INFO SparkContext: Created broadcast 3 from csv at NativeMethodAccessorImpl.java:0
21/04/09 23:49:23 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
21/04/09 23:49:23 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
21/04/09 23:49:23 INFO DAGScheduler: Got job 2 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/04/09 23:49:23 INFO DAGScheduler: Final stage: ResultStage 3 (csv at NativeMethodAccessorImpl.java:0)
21/04/09 23:49:23 INFO DAGScheduler: Parents of final stage: List()
21/04/09 23:49:23 INFO DAGScheduler: Missing parents: List()
21/04/09 23:49:23 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[15] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
21/04/09 23:49:23 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 8.8 KB, free 912.0 MB)
21/04/09 23:49:23 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 4.5 KB, free 912.0 MB)
21/04/09 23:49:23 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:54133 (size: 4.5 KB, free: 912.3 MB)
21/04/09 23:49:23 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1161
21/04/09 23:49:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[15] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/04/09 23:49:23 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
21/04/09 23:49:23 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 8346 bytes)
21/04/09 23:49:23 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
21/04/09 23:49:23 INFO FileScanRDD: Reading File path: file:///E:/OneDrive/WUSTL/Math%20Research/test/data-csv/letters1.csv, range: 0-30, partition values: [empty row]
21/04/09 23:49:23 INFO CodeGenerator: Code generated in 7.7865 ms
21/04/09 23:49:23 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1224 bytes result sent to driver
21/04/09 23:49:23 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 46 ms on localhost (executor driver) (1/1)
21/04/09 23:49:23 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
21/04/09 23:49:23 INFO DAGScheduler: ResultStage 3 (csv at NativeMethodAccessorImpl.java:0) finished in 0.052 s
21/04/09 23:49:23 INFO DAGScheduler: Job 2 finished: csv at NativeMethodAccessorImpl.java:0, took 0.055601 s
21/04/09 23:49:23 INFO FileSourceStrategy: Pruning directories with: 
21/04/09 23:49:23 INFO FileSourceStrategy: Post-Scan Filters: 
21/04/09 23:49:23 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
21/04/09 23:49:23 INFO FileSourceScanExec: Pushed Filters: 
21/04/09 23:49:23 INFO CodeGenerator: Code generated in 3.4885 ms
21/04/09 23:49:23 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 286.0 KB, free 911.7 MB)
21/04/09 23:49:23 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 24.2 KB, free 911.6 MB)
21/04/09 23:49:23 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:54133 (size: 24.2 KB, free: 912.2 MB)
21/04/09 23:49:23 INFO SparkContext: Created broadcast 5 from csv at NativeMethodAccessorImpl.java:0
21/04/09 23:49:23 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
21/04/09 23:49:23 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
21/04/09 23:49:23 INFO DAGScheduler: Got job 3 (csv at NativeMethodAccessorImpl.java:0) with 2 output partitions
21/04/09 23:49:23 INFO DAGScheduler: Final stage: ResultStage 4 (csv at NativeMethodAccessorImpl.java:0)
21/04/09 23:49:23 INFO DAGScheduler: Parents of final stage: List()
21/04/09 23:49:23 INFO DAGScheduler: Missing parents: List()
21/04/09 23:49:23 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[20] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
21/04/09 23:49:23 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 15.0 KB, free 911.6 MB)
21/04/09 23:49:23 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 8.6 KB, free 911.6 MB)
21/04/09 23:49:23 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:54133 (size: 8.6 KB, free: 912.2 MB)
21/04/09 23:49:23 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1161
21/04/09 23:49:23 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 4 (MapPartitionsRDD[20] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
21/04/09 23:49:23 INFO TaskSchedulerImpl: Adding task set 4.0 with 2 tasks
21/04/09 23:49:23 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 8346 bytes)
21/04/09 23:49:23 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 5, localhost, executor driver, partition 1, PROCESS_LOCAL, 8346 bytes)
21/04/09 23:49:23 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
21/04/09 23:49:23 INFO Executor: Running task 1.0 in stage 4.0 (TID 5)
21/04/09 23:49:23 INFO FileScanRDD: Reading File path: file:///E:/OneDrive/WUSTL/Math%20Research/test/data-csv/letters1.csv, range: 0-30, partition values: [empty row]
21/04/09 23:49:23 INFO FileScanRDD: Reading File path: file:///E:/OneDrive/WUSTL/Math%20Research/test/data-csv/letters2.csv, range: 0-30, partition values: [empty row]
21/04/09 23:49:23 INFO Executor: Finished task 1.0 in stage 4.0 (TID 5). 1481 bytes result sent to driver
21/04/09 23:49:23 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1481 bytes result sent to driver
21/04/09 23:49:23 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 5) in 19 ms on localhost (executor driver) (1/2)
21/04/09 23:49:23 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 19 ms on localhost (executor driver) (2/2)
21/04/09 23:49:23 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
21/04/09 23:49:23 INFO DAGScheduler: ResultStage 4 (csv at NativeMethodAccessorImpl.java:0) finished in 0.025 s
21/04/09 23:49:23 INFO DAGScheduler: Job 3 finished: csv at NativeMethodAccessorImpl.java:0, took 0.025959 s
21/04/09 23:49:23 INFO HiveMetaStore: 0: get_database: default
21/04/09 23:49:23 INFO audit: ugi=lizha	ip=unknown-ip-addr	cmd=get_database: default	
21/04/09 23:49:23 INFO HiveMetaStore: 0: get_database: default
21/04/09 23:49:23 INFO audit: ugi=lizha	ip=unknown-ip-addr	cmd=get_database: default	
21/04/09 23:49:23 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/04/09 23:49:23 INFO audit: ugi=lizha	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/04/09 23:49:24 INFO SparkContext: Starting job: count at utils.scala:135
21/04/09 23:49:24 INFO DAGScheduler: Registering RDD 24 (count at utils.scala:135)
21/04/09 23:49:24 INFO DAGScheduler: Got job 4 (count at utils.scala:135) with 1 output partitions
21/04/09 23:49:24 INFO DAGScheduler: Final stage: ResultStage 6 (count at utils.scala:135)
21/04/09 23:49:24 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
21/04/09 23:49:24 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 5)
21/04/09 23:49:24 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[24] at count at utils.scala:135), which has no missing parents
21/04/09 23:49:24 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 7.9 KB, free 911.6 MB)
21/04/09 23:49:24 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 4.2 KB, free 911.6 MB)
21/04/09 23:49:24 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:54133 (size: 4.2 KB, free: 912.2 MB)
21/04/09 23:49:24 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1161
21/04/09 23:49:24 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[24] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/04/09 23:49:24 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
21/04/09 23:49:24 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 6, localhost, executor driver, partition 0, PROCESS_LOCAL, 7882 bytes)
21/04/09 23:49:24 INFO Executor: Running task 0.0 in stage 5.0 (TID 6)
21/04/09 23:49:24 INFO Executor: Finished task 0.0 in stage 5.0 (TID 6). 1413 bytes result sent to driver
21/04/09 23:49:24 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 6) in 5 ms on localhost (executor driver) (1/1)
21/04/09 23:49:24 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
21/04/09 23:49:24 INFO DAGScheduler: ShuffleMapStage 5 (count at utils.scala:135) finished in 0.010 s
21/04/09 23:49:24 INFO DAGScheduler: looking for newly runnable stages
21/04/09 23:49:24 INFO DAGScheduler: running: Set()
21/04/09 23:49:24 INFO DAGScheduler: waiting: Set(ResultStage 6)
21/04/09 23:49:24 INFO DAGScheduler: failed: Set()
21/04/09 23:49:24 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[27] at count at utils.scala:135), which has no missing parents
21/04/09 23:49:24 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 7.1 KB, free 911.6 MB)
21/04/09 23:49:24 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 3.8 KB, free 911.6 MB)
21/04/09 23:49:24 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:54133 (size: 3.8 KB, free: 912.2 MB)
21/04/09 23:49:24 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1161
21/04/09 23:49:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[27] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/04/09 23:49:24 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
21/04/09 23:49:24 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 7, localhost, executor driver, partition 0, ANY, 7767 bytes)
21/04/09 23:49:24 INFO Executor: Running task 0.0 in stage 6.0 (TID 7)
21/04/09 23:49:24 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/04/09 23:49:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/04/09 23:49:24 INFO Executor: Finished task 0.0 in stage 6.0 (TID 7). 1646 bytes result sent to driver
21/04/09 23:49:24 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 7) in 4 ms on localhost (executor driver) (1/1)
21/04/09 23:49:24 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
21/04/09 23:49:24 INFO DAGScheduler: ResultStage 6 (count at utils.scala:135) finished in 0.007 s
21/04/09 23:49:24 INFO DAGScheduler: Job 4 finished: count at utils.scala:135, took 0.019832 s
21/04/09 23:49:24 INFO FileSourceStrategy: Pruning directories with: 
21/04/09 23:49:24 INFO FileSourceStrategy: Post-Scan Filters: 
21/04/09 23:49:24 INFO FileSourceStrategy: Output Data Schema: struct<x: string, y: int>
21/04/09 23:49:24 INFO FileSourceScanExec: Pushed Filters: 
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 79
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 158
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 119
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 139
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 198
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 173
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 92
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 85
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 204
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 161
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 88
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 131
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 67
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 98
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 140
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 123
21/04/09 23:49:24 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 127.0.0.1:54133 in memory (size: 24.2 KB, free: 912.2 MB)
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 147
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 80
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 102
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 73
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 150
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 207
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 154
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 197
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 133
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 191
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 76
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 122
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 166
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 138
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 70
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 87
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 168
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 86
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 83
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 177
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 206
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 82
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 196
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 179
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 69
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 111
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 130
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 155
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 195
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 151
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 91
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 210
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 109
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 107
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 169
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 211
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 77
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 116
21/04/09 23:49:24 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 127.0.0.1:54133 in memory (size: 4.2 KB, free: 912.2 MB)
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 188
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 66
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 218
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 156
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 180
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 185
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 178
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 97
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 208
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 152
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 103
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 106
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 74
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 121
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 108
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 126
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 95
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 125
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 89
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 127
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 205
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 184
21/04/09 23:49:24 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 127.0.0.1:54133 in memory (size: 3.4 KB, free: 912.3 MB)
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 142
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 132
21/04/09 23:49:24 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:54133 in memory (size: 8.6 KB, free: 912.3 MB)
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 187
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 114
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 115
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 214
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 163
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 137
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 164
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 143
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 172
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 75
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 183
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 105
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 165
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 120
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 212
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 110
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 170
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 117
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 68
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 135
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 93
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 194
21/04/09 23:49:24 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 127.0.0.1:54133 in memory (size: 3.8 KB, free: 912.3 MB)
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 167
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 84
21/04/09 23:49:24 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:54133 in memory (size: 4.5 KB, free: 912.3 MB)
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 113
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 174
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 182
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 201
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 99
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 162
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 146
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 160
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 217
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 136
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 118
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 104
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 145
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 153
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 215
21/04/09 23:49:24 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 286.0 KB, free 911.7 MB)
21/04/09 23:49:24 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:54133 in memory (size: 24.2 KB, free: 912.3 MB)
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 181
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 144
21/04/09 23:49:24 INFO ContextCleaner: Cleaned shuffle 1
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 128
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 148
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 96
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 90
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 112
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 209
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 159
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 190
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 124
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 176
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 186
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 216
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 175
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 141
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 100
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 171
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 81
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 94
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 101
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 134
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 199
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 78
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 129
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 203
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 213
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 193
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 149
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 192
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 189
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 72
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 157
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 200
21/04/09 23:49:24 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 127.0.0.1:54133 in memory (size: 3.8 KB, free: 912.3 MB)
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 71
21/04/09 23:49:24 INFO ContextCleaner: Cleaned accumulator 202
21/04/09 23:49:24 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 24.2 KB, free 912.0 MB)
21/04/09 23:49:24 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:54133 (size: 24.2 KB, free: 912.3 MB)
21/04/09 23:49:24 INFO SparkContext: Created broadcast 9 from sql at NativeMethodAccessorImpl.java:0
21/04/09 23:49:24 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
21/04/09 23:49:24 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
21/04/09 23:49:24 INFO DAGScheduler: Registering RDD 35 (sql at NativeMethodAccessorImpl.java:0)
21/04/09 23:49:24 INFO DAGScheduler: Got job 5 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/04/09 23:49:24 INFO DAGScheduler: Final stage: ResultStage 8 (sql at NativeMethodAccessorImpl.java:0)
21/04/09 23:49:24 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
21/04/09 23:49:24 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 7)
21/04/09 23:49:24 INFO DAGScheduler: Submitting ShuffleMapStage 7 (MapPartitionsRDD[35] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
21/04/09 23:49:24 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 20.2 KB, free 912.0 MB)
21/04/09 23:49:24 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 10.4 KB, free 912.0 MB)
21/04/09 23:49:24 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:54133 (size: 10.4 KB, free: 912.3 MB)
21/04/09 23:49:24 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1161
21/04/09 23:49:24 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[35] at sql at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
21/04/09 23:49:24 INFO TaskSchedulerImpl: Adding task set 7.0 with 2 tasks
21/04/09 23:49:24 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 8335 bytes)
21/04/09 23:49:24 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 9, localhost, executor driver, partition 1, PROCESS_LOCAL, 8335 bytes)
21/04/09 23:49:24 INFO Executor: Running task 0.0 in stage 7.0 (TID 8)
21/04/09 23:49:24 INFO Executor: Running task 1.0 in stage 7.0 (TID 9)
21/04/09 23:49:24 INFO FileScanRDD: Reading File path: file:///E:/OneDrive/WUSTL/Math%20Research/test/data-csv/letters2.csv, range: 0-30, partition values: [empty row]
21/04/09 23:49:24 INFO FileScanRDD: Reading File path: file:///E:/OneDrive/WUSTL/Math%20Research/test/data-csv/letters1.csv, range: 0-30, partition values: [empty row]
21/04/09 23:49:24 INFO CodeGenerator: Code generated in 6.0116 ms
21/04/09 23:49:24 INFO MemoryStore: Block rdd_30_0 stored as values in memory (estimated size 424.0 B, free 912.0 MB)
21/04/09 23:49:24 INFO BlockManagerInfo: Added rdd_30_0 in memory on 127.0.0.1:54133 (size: 424.0 B, free: 912.3 MB)
21/04/09 23:49:24 INFO MemoryStore: Block rdd_30_1 stored as values in memory (estimated size 424.0 B, free 912.0 MB)
21/04/09 23:49:24 INFO BlockManagerInfo: Added rdd_30_1 in memory on 127.0.0.1:54133 (size: 424.0 B, free: 912.3 MB)
21/04/09 23:49:24 INFO CodeGenerator: Code generated in 3.5644 ms
21/04/09 23:49:24 INFO CodeGenerator: Code generated in 10.2432 ms
21/04/09 23:49:24 INFO Executor: Finished task 0.0 in stage 7.0 (TID 8). 1785 bytes result sent to driver
21/04/09 23:49:24 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 8) in 83 ms on localhost (executor driver) (1/2)
21/04/09 23:49:24 INFO Executor: Finished task 1.0 in stage 7.0 (TID 9). 1828 bytes result sent to driver
21/04/09 23:49:24 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 9) in 83 ms on localhost (executor driver) (2/2)
21/04/09 23:49:24 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
21/04/09 23:49:24 INFO DAGScheduler: ShuffleMapStage 7 (sql at NativeMethodAccessorImpl.java:0) finished in 0.097 s
21/04/09 23:49:24 INFO DAGScheduler: looking for newly runnable stages
21/04/09 23:49:24 INFO DAGScheduler: running: Set()
21/04/09 23:49:24 INFO DAGScheduler: waiting: Set(ResultStage 8)
21/04/09 23:49:24 INFO DAGScheduler: failed: Set()
21/04/09 23:49:24 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[38] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
21/04/09 23:49:24 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 7.1 KB, free 911.9 MB)
21/04/09 23:49:24 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 3.8 KB, free 911.9 MB)
21/04/09 23:49:24 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:54133 (size: 3.8 KB, free: 912.3 MB)
21/04/09 23:49:24 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1161
21/04/09 23:49:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[38] at sql at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/04/09 23:49:24 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
21/04/09 23:49:24 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 10, localhost, executor driver, partition 0, ANY, 7767 bytes)
21/04/09 23:49:24 INFO Executor: Running task 0.0 in stage 8.0 (TID 10)
21/04/09 23:49:24 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks including 2 local blocks and 0 remote blocks
21/04/09 23:49:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/04/09 23:49:24 INFO Executor: Finished task 0.0 in stage 8.0 (TID 10). 1696 bytes result sent to driver
21/04/09 23:49:24 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 10) in 4 ms on localhost (executor driver) (1/1)
21/04/09 23:49:24 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
21/04/09 23:49:24 INFO DAGScheduler: ResultStage 8 (sql at NativeMethodAccessorImpl.java:0) finished in 0.007 s
21/04/09 23:49:24 INFO DAGScheduler: Job 5 finished: sql at NativeMethodAccessorImpl.java:0, took 0.109499 s
21/04/09 23:49:24 INFO CodeGenerator: Code generated in 4.7879 ms
21/04/09 23:49:24 INFO SparkContext: Starting job: collect at utils.scala:135
21/04/09 23:49:24 INFO DAGScheduler: Registering RDD 43 (collect at utils.scala:135)
21/04/09 23:49:24 INFO DAGScheduler: Got job 6 (collect at utils.scala:135) with 1 output partitions
21/04/09 23:49:24 INFO DAGScheduler: Final stage: ResultStage 10 (collect at utils.scala:135)
21/04/09 23:49:24 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)
21/04/09 23:49:24 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)
21/04/09 23:49:24 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[43] at collect at utils.scala:135), which has no missing parents
21/04/09 23:49:24 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 20.2 KB, free 911.9 MB)
21/04/09 23:49:24 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 10.5 KB, free 911.9 MB)
21/04/09 23:49:24 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:54133 (size: 10.5 KB, free: 912.2 MB)
21/04/09 23:49:24 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1161
21/04/09 23:49:24 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[43] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0, 1))
21/04/09 23:49:24 INFO TaskSchedulerImpl: Adding task set 9.0 with 2 tasks
21/04/09 23:49:24 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 11, localhost, executor driver, partition 0, PROCESS_LOCAL, 8335 bytes)
21/04/09 23:49:24 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 12, localhost, executor driver, partition 1, PROCESS_LOCAL, 8335 bytes)
21/04/09 23:49:24 INFO Executor: Running task 0.0 in stage 9.0 (TID 11)
21/04/09 23:49:24 INFO Executor: Running task 1.0 in stage 9.0 (TID 12)
21/04/09 23:49:24 INFO BlockManager: Found block rdd_30_1 locally
21/04/09 23:49:24 INFO BlockManager: Found block rdd_30_0 locally
21/04/09 23:49:24 INFO Executor: Finished task 1.0 in stage 9.0 (TID 12). 1785 bytes result sent to driver
21/04/09 23:49:24 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 12) in 12 ms on localhost (executor driver) (1/2)
21/04/09 23:49:24 INFO Executor: Finished task 0.0 in stage 9.0 (TID 11). 1785 bytes result sent to driver
21/04/09 23:49:24 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 11) in 14 ms on localhost (executor driver) (2/2)
21/04/09 23:49:24 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
21/04/09 23:49:24 INFO DAGScheduler: ShuffleMapStage 9 (collect at utils.scala:135) finished in 0.024 s
21/04/09 23:49:24 INFO DAGScheduler: looking for newly runnable stages
21/04/09 23:49:24 INFO DAGScheduler: running: Set()
21/04/09 23:49:24 INFO DAGScheduler: waiting: Set(ResultStage 10)
21/04/09 23:49:24 INFO DAGScheduler: failed: Set()
21/04/09 23:49:24 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[46] at collect at utils.scala:135), which has no missing parents
21/04/09 23:49:24 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 7.1 KB, free 911.9 MB)
21/04/09 23:49:24 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 3.8 KB, free 911.9 MB)
21/04/09 23:49:24 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 127.0.0.1:54133 (size: 3.8 KB, free: 912.2 MB)
21/04/09 23:49:24 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1161
21/04/09 23:49:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[46] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/04/09 23:49:24 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
21/04/09 23:49:24 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 13, localhost, executor driver, partition 0, ANY, 7767 bytes)
21/04/09 23:49:24 INFO Executor: Running task 0.0 in stage 10.0 (TID 13)
21/04/09 23:49:24 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks including 2 local blocks and 0 remote blocks
21/04/09 23:49:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/04/09 23:49:24 INFO Executor: Finished task 0.0 in stage 10.0 (TID 13). 1653 bytes result sent to driver
21/04/09 23:49:24 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 13) in 8 ms on localhost (executor driver) (1/1)
21/04/09 23:49:24 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
21/04/09 23:49:24 INFO DAGScheduler: ResultStage 10 (collect at utils.scala:135) finished in 0.013 s
21/04/09 23:49:24 INFO DAGScheduler: Job 6 finished: collect at utils.scala:135, took 0.040928 s
21/04/09 23:49:24 INFO CodeGenerator: Code generated in 12.3743 ms
21/04/09 23:49:24 INFO CodeGenerator: Code generated in 7.9195 ms
21/04/09 23:49:24 INFO SparkContext: Starting job: count at utils.scala:135
21/04/09 23:49:24 INFO DAGScheduler: Registering RDD 51 (count at utils.scala:135)
21/04/09 23:49:24 INFO DAGScheduler: Got job 7 (count at utils.scala:135) with 1 output partitions
21/04/09 23:49:24 INFO DAGScheduler: Final stage: ResultStage 12 (count at utils.scala:135)
21/04/09 23:49:24 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 11)
21/04/09 23:49:24 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 11)
21/04/09 23:49:24 INFO DAGScheduler: Submitting ShuffleMapStage 11 (MapPartitionsRDD[51] at count at utils.scala:135), which has no missing parents
21/04/09 23:49:24 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 19.6 KB, free 911.9 MB)
21/04/09 23:49:24 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 10.2 KB, free 911.9 MB)
21/04/09 23:49:24 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 127.0.0.1:54133 (size: 10.2 KB, free: 912.2 MB)
21/04/09 23:49:24 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1161
21/04/09 23:49:24 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[51] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0, 1))
21/04/09 23:49:24 INFO TaskSchedulerImpl: Adding task set 11.0 with 2 tasks
21/04/09 23:49:24 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 14, localhost, executor driver, partition 0, PROCESS_LOCAL, 8335 bytes)
21/04/09 23:49:24 INFO TaskSetManager: Starting task 1.0 in stage 11.0 (TID 15, localhost, executor driver, partition 1, PROCESS_LOCAL, 8335 bytes)
21/04/09 23:49:24 INFO Executor: Running task 1.0 in stage 11.0 (TID 15)
21/04/09 23:49:24 INFO Executor: Running task 0.0 in stage 11.0 (TID 14)
21/04/09 23:49:24 INFO BlockManager: Found block rdd_30_0 locally
21/04/09 23:49:24 INFO BlockManager: Found block rdd_30_1 locally
21/04/09 23:49:24 INFO Executor: Finished task 0.0 in stage 11.0 (TID 14). 1785 bytes result sent to driver
21/04/09 23:49:24 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 14) in 12 ms on localhost (executor driver) (1/2)
21/04/09 23:49:24 INFO Executor: Finished task 1.0 in stage 11.0 (TID 15). 1785 bytes result sent to driver
21/04/09 23:49:24 INFO TaskSetManager: Finished task 1.0 in stage 11.0 (TID 15) in 13 ms on localhost (executor driver) (2/2)
21/04/09 23:49:24 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
21/04/09 23:49:24 INFO DAGScheduler: ShuffleMapStage 11 (count at utils.scala:135) finished in 0.019 s
21/04/09 23:49:24 INFO DAGScheduler: looking for newly runnable stages
21/04/09 23:49:24 INFO DAGScheduler: running: Set()
21/04/09 23:49:24 INFO DAGScheduler: waiting: Set(ResultStage 12)
21/04/09 23:49:24 INFO DAGScheduler: failed: Set()
21/04/09 23:49:24 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[54] at count at utils.scala:135), which has no missing parents
21/04/09 23:49:24 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 9.1 KB, free 911.9 MB)
21/04/09 23:49:24 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 4.1 KB, free 911.9 MB)
21/04/09 23:49:24 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 127.0.0.1:54133 (size: 4.1 KB, free: 912.2 MB)
21/04/09 23:49:24 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1161
21/04/09 23:49:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[54] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/04/09 23:49:24 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
21/04/09 23:49:24 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 16, localhost, executor driver, partition 0, ANY, 7767 bytes)
21/04/09 23:49:24 INFO Executor: Running task 0.0 in stage 12.0 (TID 16)
21/04/09 23:49:24 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks including 2 local blocks and 0 remote blocks
21/04/09 23:49:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/04/09 23:49:24 INFO Executor: Finished task 0.0 in stage 12.0 (TID 16). 2012 bytes result sent to driver
21/04/09 23:49:24 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 16) in 8 ms on localhost (executor driver) (1/1)
21/04/09 23:49:24 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
21/04/09 23:49:24 INFO DAGScheduler: ResultStage 12 (count at utils.scala:135) finished in 0.014 s
21/04/09 23:49:24 INFO DAGScheduler: Job 7 finished: count at utils.scala:135, took 0.036486 s
21/04/09 23:49:24 INFO CodeGenerator: Code generated in 4.7369 ms
21/04/09 23:49:24 INFO CodeGenerator: Code generated in 5.5109 ms
21/04/09 23:49:24 INFO SparkContext: Starting job: collect at utils.scala:135
21/04/09 23:49:24 INFO DAGScheduler: Got job 8 (collect at utils.scala:135) with 1 output partitions
21/04/09 23:49:24 INFO DAGScheduler: Final stage: ResultStage 13 (collect at utils.scala:135)
21/04/09 23:49:24 INFO DAGScheduler: Parents of final stage: List()
21/04/09 23:49:24 INFO DAGScheduler: Missing parents: List()
21/04/09 23:49:24 INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[58] at collect at utils.scala:135), which has no missing parents
21/04/09 23:49:24 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 6.1 KB, free 911.9 MB)
21/04/09 23:49:24 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 3.2 KB, free 911.9 MB)
21/04/09 23:49:24 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 127.0.0.1:54133 (size: 3.2 KB, free: 912.2 MB)
21/04/09 23:49:24 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1161
21/04/09 23:49:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[58] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/04/09 23:49:24 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
21/04/09 23:49:24 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 17, localhost, executor driver, partition 0, PROCESS_LOCAL, 8080 bytes)
21/04/09 23:49:24 INFO Executor: Running task 0.0 in stage 13.0 (TID 17)
21/04/09 23:49:24 INFO CodeGenerator: Code generated in 4.8234 ms
21/04/09 23:49:24 INFO Executor: Finished task 0.0 in stage 13.0 (TID 17). 1200 bytes result sent to driver
21/04/09 23:49:24 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 17) in 15 ms on localhost (executor driver) (1/1)
21/04/09 23:49:24 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
21/04/09 23:49:24 INFO DAGScheduler: ResultStage 13 (collect at utils.scala:135) finished in 0.019 s
21/04/09 23:49:24 INFO DAGScheduler: Job 8 finished: collect at utils.scala:135, took 0.020366 s
21/04/09 23:49:24 INFO SparkContext: Starting job: count at utils.scala:135
21/04/09 23:49:24 INFO DAGScheduler: Registering RDD 61 (count at utils.scala:135)
21/04/09 23:49:24 INFO DAGScheduler: Got job 9 (count at utils.scala:135) with 1 output partitions
21/04/09 23:49:24 INFO DAGScheduler: Final stage: ResultStage 15 (count at utils.scala:135)
21/04/09 23:49:24 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 14)
21/04/09 23:49:24 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 14)
21/04/09 23:49:24 INFO DAGScheduler: Submitting ShuffleMapStage 14 (MapPartitionsRDD[61] at count at utils.scala:135), which has no missing parents
21/04/09 23:49:24 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 8.4 KB, free 911.8 MB)
21/04/09 23:49:24 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 4.5 KB, free 911.8 MB)
21/04/09 23:49:24 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 127.0.0.1:54133 (size: 4.5 KB, free: 912.2 MB)
21/04/09 23:49:24 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1161
21/04/09 23:49:24 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 14 (MapPartitionsRDD[61] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/04/09 23:49:24 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
21/04/09 23:49:24 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 18, localhost, executor driver, partition 0, PROCESS_LOCAL, 8069 bytes)
21/04/09 23:49:24 INFO Executor: Running task 0.0 in stage 14.0 (TID 18)
21/04/09 23:49:24 INFO Executor: Finished task 0.0 in stage 14.0 (TID 18). 1370 bytes result sent to driver
21/04/09 23:49:24 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 18) in 6 ms on localhost (executor driver) (1/1)
21/04/09 23:49:24 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
21/04/09 23:49:24 INFO DAGScheduler: ShuffleMapStage 14 (count at utils.scala:135) finished in 0.010 s
21/04/09 23:49:24 INFO DAGScheduler: looking for newly runnable stages
21/04/09 23:49:24 INFO DAGScheduler: running: Set()
21/04/09 23:49:24 INFO DAGScheduler: waiting: Set(ResultStage 15)
21/04/09 23:49:24 INFO DAGScheduler: failed: Set()
21/04/09 23:49:24 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[64] at count at utils.scala:135), which has no missing parents
21/04/09 23:49:24 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 7.1 KB, free 911.8 MB)
21/04/09 23:49:24 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 3.8 KB, free 911.8 MB)
21/04/09 23:49:24 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 127.0.0.1:54133 (size: 3.8 KB, free: 912.2 MB)
21/04/09 23:49:24 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1161
21/04/09 23:49:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[64] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/04/09 23:49:24 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks
21/04/09 23:49:24 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 19, localhost, executor driver, partition 0, ANY, 7767 bytes)
21/04/09 23:49:24 INFO Executor: Running task 0.0 in stage 15.0 (TID 19)
21/04/09 23:49:24 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/04/09 23:49:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/04/09 23:49:24 INFO Executor: Finished task 0.0 in stage 15.0 (TID 19). 1739 bytes result sent to driver
21/04/09 23:49:24 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 19) in 5 ms on localhost (executor driver) (1/1)
21/04/09 23:49:24 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
21/04/09 23:49:24 INFO DAGScheduler: ResultStage 15 (count at utils.scala:135) finished in 0.010 s
21/04/09 23:49:24 INFO DAGScheduler: Job 9 finished: count at utils.scala:135, took 0.022686 s
21/04/09 23:49:24 INFO SparkContext: Invoking stop() from shutdown hook
21/04/09 23:49:24 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
21/04/09 23:49:24 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/04/09 23:49:24 INFO MemoryStore: MemoryStore cleared
21/04/09 23:49:24 INFO BlockManager: BlockManager stopped
21/04/09 23:49:24 INFO BlockManagerMaster: BlockManagerMaster stopped
21/04/09 23:49:24 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/04/09 23:49:24 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\lizha\AppData\Local\spark\spark-2.4.3-bin-hadoop2.7\tmp\local\spark-ef9edac8-d99d-4995-96ab-1358dd1073f1\userFiles-a88c6894-f86a-40ef-a22e-84fe3dd3876d
java.io.IOException: Failed to delete: C:\Users\lizha\AppData\Local\spark\spark-2.4.3-bin-hadoop2.7\tmp\local\spark-ef9edac8-d99d-4995-96ab-1358dd1073f1\userFiles-a88c6894-f86a-40ef-a22e-84fe3dd3876d\sparklyr-2.4-2.11.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:144)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:128)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:91)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1062)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:103)
	at org.apache.spark.SparkContext$$anonfun$stop$11.apply$mcV$sp(SparkContext.scala:1974)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1340)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1973)
	at org.apache.spark.SparkContext$$anonfun$2.apply$mcV$sp(SparkContext.scala:575)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1945)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
21/04/09 23:49:24 INFO SparkContext: Successfully stopped SparkContext
21/04/09 23:49:24 INFO ShutdownHookManager: Shutdown hook called
21/04/09 23:49:24 INFO ShutdownHookManager: Deleting directory C:\Users\lizha\AppData\Local\spark\spark-2.4.3-bin-hadoop2.7\tmp\local\spark-ef9edac8-d99d-4995-96ab-1358dd1073f1
21/04/09 23:49:24 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\lizha\AppData\Local\spark\spark-2.4.3-bin-hadoop2.7\tmp\local\spark-ef9edac8-d99d-4995-96ab-1358dd1073f1
java.io.IOException: Failed to delete: C:\Users\lizha\AppData\Local\spark\spark-2.4.3-bin-hadoop2.7\tmp\local\spark-ef9edac8-d99d-4995-96ab-1358dd1073f1\userFiles-a88c6894-f86a-40ef-a22e-84fe3dd3876d\sparklyr-2.4-2.11.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:144)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:128)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:128)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:91)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1062)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1945)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
21/04/09 23:49:24 INFO ShutdownHookManager: Deleting directory C:\Users\lizha\AppData\Local\spark\spark-2.4.3-bin-hadoop2.7\tmp\local\spark-ef9edac8-d99d-4995-96ab-1358dd1073f1\userFiles-a88c6894-f86a-40ef-a22e-84fe3dd3876d
21/04/09 23:49:24 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\lizha\AppData\Local\spark\spark-2.4.3-bin-hadoop2.7\tmp\local\spark-ef9edac8-d99d-4995-96ab-1358dd1073f1\userFiles-a88c6894-f86a-40ef-a22e-84fe3dd3876d
java.io.IOException: Failed to delete: C:\Users\lizha\AppData\Local\spark\spark-2.4.3-bin-hadoop2.7\tmp\local\spark-ef9edac8-d99d-4995-96ab-1358dd1073f1\userFiles-a88c6894-f86a-40ef-a22e-84fe3dd3876d\sparklyr-2.4-2.11.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:144)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:128)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:91)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1062)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1945)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
21/04/09 23:49:24 INFO ShutdownHookManager: Deleting directory C:\Users\lizha\AppData\Local\Temp\spark-79443f32-804b-4463-91b6-7205d9e4a238
21/04/09 23:50:23 INFO SparkContext: Running Spark version 2.4.3
21/04/09 23:50:23 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
21/04/09 23:50:23 INFO SparkContext: Submitted application: sparklyr
21/04/09 23:50:23 INFO SecurityManager: Changing view acls to: lizha
21/04/09 23:50:23 INFO SecurityManager: Changing modify acls to: lizha
21/04/09 23:50:23 INFO SecurityManager: Changing view acls groups to: 
21/04/09 23:50:23 INFO SecurityManager: Changing modify acls groups to: 
21/04/09 23:50:23 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(lizha); groups with view permissions: Set(); users  with modify permissions: Set(lizha); groups with modify permissions: Set()
21/04/09 23:50:23 INFO Utils: Successfully started service 'sparkDriver' on port 54243.
21/04/09 23:50:24 INFO SparkEnv: Registering MapOutputTracker
21/04/09 23:50:24 INFO SparkEnv: Registering BlockManagerMaster
21/04/09 23:50:24 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/04/09 23:50:24 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/04/09 23:50:24 INFO DiskBlockManager: Created local directory at C:\Users\lizha\AppData\Local\spark\spark-2.4.3-bin-hadoop2.7\tmp\local\blockmgr-eca3a009-33de-4428-b897-4546c3d05b47
21/04/09 23:50:24 INFO MemoryStore: MemoryStore started with capacity 912.3 MB
21/04/09 23:50:24 INFO SparkEnv: Registering OutputCommitCoordinator
21/04/09 23:50:24 WARN Utils: The configured local directories are not expected to be URIs; however, got suspicious values [C:/Users/lizha/AppData/Local/spark/spark-2.4.3-bin-hadoop2.7/tmp/local]. Please check your configured local directories.
21/04/09 23:50:24 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/04/09 23:50:24 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
21/04/09 23:50:24 INFO SparkContext: Added JAR file:/E:/OneDrive/Documents/R/win-library/4.0/sparklyr/java/sparklyr-2.4-2.11.jar at spark://127.0.0.1:54243/jars/sparklyr-2.4-2.11.jar with timestamp 1618030224222
21/04/09 23:50:24 INFO Executor: Starting executor ID driver on host localhost
21/04/09 23:50:24 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54288.
21/04/09 23:50:24 INFO NettyBlockTransferService: Server created on 127.0.0.1:54288
21/04/09 23:50:24 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/04/09 23:50:24 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 54288, None)
21/04/09 23:50:24 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:54288 with 912.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 54288, None)
21/04/09 23:50:24 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 54288, None)
21/04/09 23:50:24 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 54288, None)
21/04/09 23:50:24 INFO SharedState: loading hive config file: file:/C:/Users/lizha/AppData/Local/spark/spark-2.4.3-bin-hadoop2.7/conf/hive-site.xml
21/04/09 23:50:24 INFO SharedState: Setting hive.metastore.warehouse.dir ('C:/Users/lizha/AppData/Local/spark/spark-2.4.3-bin-hadoop2.7/tmp/hive') to the value of spark.sql.warehouse.dir ('C:/Users/lizha/AppData/Local/spark/spark-2.4.3-bin-hadoop2.7/tmp/hive').
21/04/09 23:50:24 INFO SharedState: Warehouse path is 'C:/Users/lizha/AppData/Local/spark/spark-2.4.3-bin-hadoop2.7/tmp/hive'.
21/04/09 23:50:24 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
21/04/09 23:50:26 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
21/04/09 23:50:26 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
21/04/09 23:50:26 INFO ObjectStore: ObjectStore, initialize called
21/04/09 23:50:26 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
21/04/09 23:50:26 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
21/04/09 23:50:27 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
21/04/09 23:50:28 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/04/09 23:50:28 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/04/09 23:50:28 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/04/09 23:50:28 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/04/09 23:50:28 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
21/04/09 23:50:28 INFO ObjectStore: Initialized ObjectStore
21/04/09 23:50:28 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
21/04/09 23:50:28 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
21/04/09 23:50:28 INFO HiveMetaStore: Added admin role in metastore
21/04/09 23:50:28 INFO HiveMetaStore: Added public role in metastore
21/04/09 23:50:28 INFO HiveMetaStore: No user is added in admin role, since config is empty
21/04/09 23:50:28 INFO HiveMetaStore: 0: get_all_databases
21/04/09 23:50:28 INFO audit: ugi=lizha	ip=unknown-ip-addr	cmd=get_all_databases	
21/04/09 23:50:28 INFO HiveMetaStore: 0: get_functions: db=default pat=*
21/04/09 23:50:28 INFO audit: ugi=lizha	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
21/04/09 23:50:28 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
21/04/09 23:50:28 INFO SessionState: Created local directory: C:/Users/lizha/AppData/Local/Temp/07ab5d29-8504-40e9-88d9-0760b7d23b6b_resources
21/04/09 23:50:28 INFO SessionState: Created HDFS directory: C:/Users/lizha/AppData/Local/spark/spark-2.4.3-bin-hadoop2.7/tmp/hive/lizha/07ab5d29-8504-40e9-88d9-0760b7d23b6b
21/04/09 23:50:28 INFO SessionState: Created local directory: C:/Users/lizha/AppData/Local/spark/spark-2.4.3-bin-hadoop2.7/tmp/hive/07ab5d29-8504-40e9-88d9-0760b7d23b6b
21/04/09 23:50:28 INFO SessionState: Created HDFS directory: C:/Users/lizha/AppData/Local/spark/spark-2.4.3-bin-hadoop2.7/tmp/hive/lizha/07ab5d29-8504-40e9-88d9-0760b7d23b6b/_tmp_space.db
21/04/09 23:50:28 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.2) is C:/Users/lizha/AppData/Local/spark/spark-2.4.3-bin-hadoop2.7/tmp/hive
21/04/09 23:50:28 INFO HiveMetaStore: 0: get_database: default
21/04/09 23:50:28 INFO audit: ugi=lizha	ip=unknown-ip-addr	cmd=get_database: default	
21/04/09 23:50:28 INFO HiveMetaStore: 0: get_database: global_temp
21/04/09 23:50:28 INFO audit: ugi=lizha	ip=unknown-ip-addr	cmd=get_database: global_temp	
21/04/09 23:50:28 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
21/04/09 23:50:28 INFO HiveMetaStore: 0: get_database: default
21/04/09 23:50:28 INFO audit: ugi=lizha	ip=unknown-ip-addr	cmd=get_database: default	
21/04/09 23:50:28 INFO HiveMetaStore: 0: get_database: default
21/04/09 23:50:28 INFO audit: ugi=lizha	ip=unknown-ip-addr	cmd=get_database: default	
21/04/09 23:50:28 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/04/09 23:50:28 INFO audit: ugi=lizha	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/04/09 23:50:29 INFO CodeGenerator: Code generated in 139.1406 ms
21/04/09 23:50:29 INFO CodeGenerator: Code generated in 14.8696 ms
21/04/09 23:50:29 INFO CodeGenerator: Code generated in 11.2635 ms
21/04/09 23:50:29 INFO SparkContext: Starting job: count at utils.scala:135
21/04/09 23:50:29 INFO DAGScheduler: Registering RDD 3 (count at utils.scala:135)
21/04/09 23:50:29 INFO DAGScheduler: Got job 0 (count at utils.scala:135) with 1 output partitions
21/04/09 23:50:29 INFO DAGScheduler: Final stage: ResultStage 1 (count at utils.scala:135)
21/04/09 23:50:29 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
21/04/09 23:50:29 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
21/04/09 23:50:29 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at count at utils.scala:135), which has no missing parents
21/04/09 23:50:29 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 7.9 KB, free 912.3 MB)
21/04/09 23:50:29 INFO ContextCleaner: Cleaned accumulator 1
21/04/09 23:50:29 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.2 KB, free 912.3 MB)
21/04/09 23:50:29 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:54288 (size: 4.2 KB, free: 912.3 MB)
21/04/09 23:50:29 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1161
21/04/09 23:50:29 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/04/09 23:50:29 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
21/04/09 23:50:29 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7882 bytes)
21/04/09 23:50:29 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
21/04/09 23:50:29 INFO Executor: Fetching spark://127.0.0.1:54243/jars/sparklyr-2.4-2.11.jar with timestamp 1618030224222
21/04/09 23:50:29 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:54243 after 13 ms (0 ms spent in bootstraps)
21/04/09 23:50:29 INFO Utils: Fetching spark://127.0.0.1:54243/jars/sparklyr-2.4-2.11.jar to C:\Users\lizha\AppData\Local\spark\spark-2.4.3-bin-hadoop2.7\tmp\local\spark-fd59562e-417b-44f8-be2b-458c02c3de67\userFiles-cf15b3bb-9f81-4b40-8fd6-98e08b6335ff\fetchFileTemp536023496277337818.tmp
21/04/09 23:50:29 INFO Executor: Adding file:/C:/Users/lizha/AppData/Local/spark/spark-2.4.3-bin-hadoop2.7/tmp/local/spark-fd59562e-417b-44f8-be2b-458c02c3de67/userFiles-cf15b3bb-9f81-4b40-8fd6-98e08b6335ff/sparklyr-2.4-2.11.jar to class loader
21/04/09 23:50:30 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1542 bytes result sent to driver
21/04/09 23:50:30 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 202 ms on localhost (executor driver) (1/1)
21/04/09 23:50:30 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
21/04/09 23:50:30 INFO DAGScheduler: ShuffleMapStage 0 (count at utils.scala:135) finished in 0.380 s
21/04/09 23:50:30 INFO DAGScheduler: looking for newly runnable stages
21/04/09 23:50:30 INFO DAGScheduler: running: Set()
21/04/09 23:50:30 INFO DAGScheduler: waiting: Set(ResultStage 1)
21/04/09 23:50:30 INFO DAGScheduler: failed: Set()
21/04/09 23:50:30 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[6] at count at utils.scala:135), which has no missing parents
21/04/09 23:50:30 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 7.1 KB, free 912.3 MB)
21/04/09 23:50:30 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.3 MB)
21/04/09 23:50:30 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:54288 (size: 3.8 KB, free: 912.3 MB)
21/04/09 23:50:30 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1161
21/04/09 23:50:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/04/09 23:50:30 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
21/04/09 23:50:30 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, ANY, 7767 bytes)
21/04/09 23:50:30 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
21/04/09 23:50:30 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/04/09 23:50:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
21/04/09 23:50:30 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1732 bytes result sent to driver
21/04/09 23:50:30 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 34 ms on localhost (executor driver) (1/1)
21/04/09 23:50:30 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/04/09 23:50:30 INFO DAGScheduler: ResultStage 1 (count at utils.scala:135) finished in 0.041 s
21/04/09 23:50:30 INFO DAGScheduler: Job 0 finished: count at utils.scala:135, took 0.476236 s
